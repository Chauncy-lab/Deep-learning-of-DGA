Using TensorFlow backend.
2017-12-06 12:49:17.174096: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-12-06 12:49:17.174157: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-12-06 12:49:17.174169: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
Train on 4488 samples, validate on 2212 samples
Epoch 1/500
Epoch 00000: val_loss improved from inf to 2.56752, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
3s - loss: 3.2254 - acc: 0.2589 - val_loss: 2.5675 - val_acc: 0.3178
Epoch 2/500
Epoch 00001: val_loss improved from 2.56752 to 2.36166, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 2.4392 - acc: 0.3362 - val_loss: 2.3617 - val_acc: 0.3329
Epoch 3/500
Epoch 00002: val_loss improved from 2.36166 to 2.30654, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 2.2997 - acc: 0.3477 - val_loss: 2.3065 - val_acc: 0.3470
Epoch 4/500
Epoch 00003: val_loss did not improve
2s - loss: 2.2620 - acc: 0.3532 - val_loss: 2.3632 - val_acc: 0.3266
Epoch 5/500
Epoch 00004: val_loss improved from 2.30654 to 2.28005, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 2.2396 - acc: 0.3551 - val_loss: 2.2801 - val_acc: 0.3412
Epoch 6/500
Epoch 00005: val_loss improved from 2.28005 to 2.25949, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 2.2155 - acc: 0.3578 - val_loss: 2.2595 - val_acc: 0.3476
Epoch 7/500
Epoch 00006: val_loss improved from 2.25949 to 2.20705, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
3s - loss: 2.2027 - acc: 0.3595 - val_loss: 2.2070 - val_acc: 0.3633
Epoch 8/500
Epoch 00007: val_loss did not improve
2s - loss: 2.1919 - acc: 0.3636 - val_loss: 2.2155 - val_acc: 0.3581
Epoch 9/500
Epoch 00008: val_loss did not improve
2s - loss: 2.1806 - acc: 0.3687 - val_loss: 2.2550 - val_acc: 0.3588
Epoch 10/500
Epoch 00009: val_loss improved from 2.20705 to 2.18736, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 2.1763 - acc: 0.3740 - val_loss: 2.1874 - val_acc: 0.3739
Epoch 11/500
Epoch 00010: val_loss improved from 2.18736 to 2.13050, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 2.1536 - acc: 0.3794 - val_loss: 2.1305 - val_acc: 0.3888
Epoch 12/500
Epoch 00011: val_loss did not improve
2s - loss: 2.1495 - acc: 0.3827 - val_loss: 2.2020 - val_acc: 0.3741
Epoch 13/500
Epoch 00012: val_loss did not improve
3s - loss: 2.1451 - acc: 0.3837 - val_loss: 2.1518 - val_acc: 0.3887
Epoch 14/500
Epoch 00013: val_loss did not improve
2s - loss: 2.1395 - acc: 0.3853 - val_loss: 2.1434 - val_acc: 0.3900
Epoch 15/500
Epoch 00014: val_loss did not improve
2s - loss: 2.1271 - acc: 0.3867 - val_loss: 2.1469 - val_acc: 0.3885
Epoch 16/500
Epoch 00015: val_loss did not improve
2s - loss: 2.1250 - acc: 0.3881 - val_loss: 2.1369 - val_acc: 0.3890
Epoch 17/500
Epoch 00016: val_loss improved from 2.13050 to 2.09889, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 2.1170 - acc: 0.3870 - val_loss: 2.0989 - val_acc: 0.3928
Epoch 18/500
Epoch 00017: val_loss improved from 2.09889 to 2.09636, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 2.1124 - acc: 0.3889 - val_loss: 2.0964 - val_acc: 0.3939
Epoch 19/500
Epoch 00018: val_loss did not improve
2s - loss: 2.1266 - acc: 0.3877 - val_loss: 2.1178 - val_acc: 0.3932
Epoch 20/500
Epoch 00019: val_loss improved from 2.09636 to 2.08191, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 2.1024 - acc: 0.3919 - val_loss: 2.0819 - val_acc: 0.3946
Epoch 21/500
Epoch 00020: val_loss improved from 2.08191 to 2.07782, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 2.0943 - acc: 0.3914 - val_loss: 2.0778 - val_acc: 0.3943
Epoch 22/500
Epoch 00021: val_loss improved from 2.07782 to 2.07754, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 2.0858 - acc: 0.3937 - val_loss: 2.0775 - val_acc: 0.3934
Epoch 23/500
Epoch 00022: val_loss improved from 2.07754 to 2.05827, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 2.0805 - acc: 0.3932 - val_loss: 2.0583 - val_acc: 0.3935
Epoch 24/500
Epoch 00023: val_loss did not improve
2s - loss: 2.0707 - acc: 0.3932 - val_loss: 2.0793 - val_acc: 0.3897
Epoch 25/500
Epoch 00024: val_loss did not improve
2s - loss: 2.0616 - acc: 0.3940 - val_loss: 2.1317 - val_acc: 0.3770
Epoch 26/500
Epoch 00025: val_loss did not improve
2s - loss: 2.0794 - acc: 0.3917 - val_loss: 2.0647 - val_acc: 0.3946
Epoch 27/500
Epoch 00026: val_loss improved from 2.05827 to 2.03618, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 2.0468 - acc: 0.3969 - val_loss: 2.0362 - val_acc: 0.3964
Epoch 28/500
Epoch 00027: val_loss improved from 2.03618 to 2.01512, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 2.0366 - acc: 0.3979 - val_loss: 2.0151 - val_acc: 0.4004
Epoch 29/500
Epoch 00028: val_loss did not improve
2s - loss: 2.0289 - acc: 0.3990 - val_loss: 2.0614 - val_acc: 0.3919
Epoch 30/500
Epoch 00029: val_loss did not improve
2s - loss: 2.0354 - acc: 0.3985 - val_loss: 2.0392 - val_acc: 0.3984
Epoch 31/500
Epoch 00030: val_loss improved from 2.01512 to 2.01200, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 2.0201 - acc: 0.4008 - val_loss: 2.0120 - val_acc: 0.4013
Epoch 32/500
Epoch 00031: val_loss improved from 2.01200 to 2.00096, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 2.0160 - acc: 0.4026 - val_loss: 2.0010 - val_acc: 0.4058
Epoch 33/500
Epoch 00032: val_loss improved from 2.00096 to 1.98417, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 2.0147 - acc: 0.4017 - val_loss: 1.9842 - val_acc: 0.4072
Epoch 34/500
Epoch 00033: val_loss improved from 1.98417 to 1.97714, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 2.0022 - acc: 0.4051 - val_loss: 1.9771 - val_acc: 0.4088
Epoch 35/500
Epoch 00034: val_loss did not improve
2s - loss: 2.0127 - acc: 0.4043 - val_loss: 1.9970 - val_acc: 0.4046
Epoch 36/500
Epoch 00035: val_loss did not improve
2s - loss: 1.9886 - acc: 0.4078 - val_loss: 1.9776 - val_acc: 0.4077
Epoch 37/500
Epoch 00036: val_loss improved from 1.97714 to 1.95887, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.9799 - acc: 0.4097 - val_loss: 1.9589 - val_acc: 0.4088
Epoch 38/500
Epoch 00037: val_loss improved from 1.95887 to 1.95599, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.9754 - acc: 0.4098 - val_loss: 1.9560 - val_acc: 0.4109
Epoch 39/500
Epoch 00038: val_loss did not improve
2s - loss: 1.9703 - acc: 0.4111 - val_loss: 1.9584 - val_acc: 0.4080
Epoch 40/500
Epoch 00039: val_loss did not improve
2s - loss: 1.9662 - acc: 0.4124 - val_loss: 1.9710 - val_acc: 0.4060
Epoch 41/500
Epoch 00040: val_loss improved from 1.95599 to 1.93426, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.9602 - acc: 0.4129 - val_loss: 1.9343 - val_acc: 0.4188
Epoch 42/500
Epoch 00041: val_loss did not improve
2s - loss: 1.9556 - acc: 0.4129 - val_loss: 1.9487 - val_acc: 0.4102
Epoch 43/500
Epoch 00042: val_loss improved from 1.93426 to 1.91973, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.9471 - acc: 0.4153 - val_loss: 1.9197 - val_acc: 0.4193
Epoch 44/500
Epoch 00043: val_loss did not improve
2s - loss: 1.9401 - acc: 0.4174 - val_loss: 1.9340 - val_acc: 0.4155
Epoch 45/500
Epoch 00044: val_loss did not improve
2s - loss: 1.9400 - acc: 0.4180 - val_loss: 1.9204 - val_acc: 0.4189
Epoch 46/500
Epoch 00045: val_loss improved from 1.91973 to 1.91215, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.9287 - acc: 0.4186 - val_loss: 1.9121 - val_acc: 0.4234
Epoch 47/500
Epoch 00046: val_loss improved from 1.91215 to 1.89556, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.9266 - acc: 0.4209 - val_loss: 1.8956 - val_acc: 0.4241
Epoch 48/500
Epoch 00047: val_loss did not improve
2s - loss: 1.9166 - acc: 0.4225 - val_loss: 1.8980 - val_acc: 0.4272
Epoch 49/500
Epoch 00048: val_loss did not improve
3s - loss: 1.9162 - acc: 0.4228 - val_loss: 1.9121 - val_acc: 0.4204
Epoch 50/500
Epoch 00049: val_loss improved from 1.89556 to 1.87100, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.9042 - acc: 0.4254 - val_loss: 1.8710 - val_acc: 0.4305
Epoch 51/500
Epoch 00050: val_loss improved from 1.87100 to 1.85751, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.9008 - acc: 0.4249 - val_loss: 1.8575 - val_acc: 0.4357
Epoch 52/500
Epoch 00051: val_loss improved from 1.85751 to 1.85607, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.8923 - acc: 0.4292 - val_loss: 1.8561 - val_acc: 0.4369
Epoch 53/500
Epoch 00052: val_loss did not improve
2s - loss: 1.8832 - acc: 0.4328 - val_loss: 1.8681 - val_acc: 0.4300
Epoch 54/500
Epoch 00053: val_loss improved from 1.85607 to 1.85457, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.8812 - acc: 0.4314 - val_loss: 1.8546 - val_acc: 0.4344
Epoch 55/500
Epoch 00054: val_loss improved from 1.85457 to 1.84307, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.8722 - acc: 0.4351 - val_loss: 1.8431 - val_acc: 0.4372
Epoch 56/500
Epoch 00055: val_loss did not improve
3s - loss: 1.8712 - acc: 0.4331 - val_loss: 1.8448 - val_acc: 0.4353
Epoch 57/500
Epoch 00056: val_loss improved from 1.84307 to 1.82339, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.8636 - acc: 0.4364 - val_loss: 1.8234 - val_acc: 0.4438
Epoch 58/500
Epoch 00057: val_loss did not improve
2s - loss: 1.8582 - acc: 0.4378 - val_loss: 1.8424 - val_acc: 0.4399
Epoch 59/500
Epoch 00058: val_loss improved from 1.82339 to 1.80734, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.8468 - acc: 0.4397 - val_loss: 1.8073 - val_acc: 0.4483
Epoch 60/500
Epoch 00059: val_loss did not improve
2s - loss: 1.8391 - acc: 0.4412 - val_loss: 1.8083 - val_acc: 0.4483
Epoch 61/500
Epoch 00060: val_loss improved from 1.80734 to 1.80615, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.8448 - acc: 0.4399 - val_loss: 1.8062 - val_acc: 0.4496
Epoch 62/500
Epoch 00061: val_loss improved from 1.80615 to 1.79263, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
3s - loss: 1.8246 - acc: 0.4455 - val_loss: 1.7926 - val_acc: 0.4536
Epoch 63/500
Epoch 00062: val_loss improved from 1.79263 to 1.78095, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.8201 - acc: 0.4464 - val_loss: 1.7810 - val_acc: 0.4538
Epoch 64/500
Epoch 00063: val_loss did not improve
2s - loss: 1.8197 - acc: 0.4458 - val_loss: 1.7834 - val_acc: 0.4542
Epoch 65/500
Epoch 00064: val_loss did not improve
2s - loss: 1.8089 - acc: 0.4485 - val_loss: 1.7986 - val_acc: 0.4445
Epoch 66/500
Epoch 00065: val_loss improved from 1.78095 to 1.75202, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.7997 - acc: 0.4508 - val_loss: 1.7520 - val_acc: 0.4653
Epoch 67/500
Epoch 00066: val_loss improved from 1.75202 to 1.74327, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.7965 - acc: 0.4514 - val_loss: 1.7433 - val_acc: 0.4670
Epoch 68/500
Epoch 00067: val_loss did not improve
2s - loss: 1.7909 - acc: 0.4524 - val_loss: 1.7571 - val_acc: 0.4587
Epoch 69/500
Epoch 00068: val_loss improved from 1.74327 to 1.73413, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
3s - loss: 1.7831 - acc: 0.4542 - val_loss: 1.7341 - val_acc: 0.4644
Epoch 70/500
Epoch 00069: val_loss improved from 1.73413 to 1.72521, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.7795 - acc: 0.4557 - val_loss: 1.7252 - val_acc: 0.4687
Epoch 71/500
Epoch 00070: val_loss did not improve
2s - loss: 1.7717 - acc: 0.4566 - val_loss: 1.7627 - val_acc: 0.4568
Epoch 72/500
Epoch 00071: val_loss improved from 1.72521 to 1.70543, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.7597 - acc: 0.4609 - val_loss: 1.7054 - val_acc: 0.4753
Epoch 73/500
Epoch 00072: val_loss improved from 1.70543 to 1.70459, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.7499 - acc: 0.4629 - val_loss: 1.7046 - val_acc: 0.4760
Epoch 74/500
Epoch 00073: val_loss improved from 1.70459 to 1.68563, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.7451 - acc: 0.4620 - val_loss: 1.6856 - val_acc: 0.4790
Epoch 75/500
Epoch 00074: val_loss did not improve
3s - loss: 1.7399 - acc: 0.4657 - val_loss: 1.6900 - val_acc: 0.4822
Epoch 76/500
Epoch 00075: val_loss improved from 1.68563 to 1.66795, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.7350 - acc: 0.4634 - val_loss: 1.6679 - val_acc: 0.4850
Epoch 77/500
Epoch 00076: val_loss did not improve
2s - loss: 1.7240 - acc: 0.4706 - val_loss: 1.6716 - val_acc: 0.4859
Epoch 78/500
Epoch 00077: val_loss improved from 1.66795 to 1.64836, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.7191 - acc: 0.4698 - val_loss: 1.6484 - val_acc: 0.4899
Epoch 79/500
Epoch 00078: val_loss did not improve
2s - loss: 1.7101 - acc: 0.4719 - val_loss: 1.6682 - val_acc: 0.4823
Epoch 80/500
Epoch 00079: val_loss did not improve
2s - loss: 1.7102 - acc: 0.4725 - val_loss: 1.6752 - val_acc: 0.4791
Epoch 81/500
Epoch 00080: val_loss improved from 1.64836 to 1.63940, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.7085 - acc: 0.4723 - val_loss: 1.6394 - val_acc: 0.4900
Epoch 82/500
Epoch 00081: val_loss did not improve
3s - loss: 1.6947 - acc: 0.4759 - val_loss: 1.6443 - val_acc: 0.4900
Epoch 83/500
Epoch 00082: val_loss improved from 1.63940 to 1.62418, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.6895 - acc: 0.4781 - val_loss: 1.6242 - val_acc: 0.4966
Epoch 84/500
Epoch 00083: val_loss did not improve
2s - loss: 1.6810 - acc: 0.4788 - val_loss: 1.6277 - val_acc: 0.4932
Epoch 85/500
Epoch 00084: val_loss improved from 1.62418 to 1.61526, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.6841 - acc: 0.4776 - val_loss: 1.6153 - val_acc: 0.4978
Epoch 86/500
Epoch 00085: val_loss improved from 1.61526 to 1.61064, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.6720 - acc: 0.4799 - val_loss: 1.6106 - val_acc: 0.4969
Epoch 87/500
Epoch 00086: val_loss improved from 1.61064 to 1.59213, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.6671 - acc: 0.4829 - val_loss: 1.5921 - val_acc: 0.5038
Epoch 88/500
Epoch 00087: val_loss did not improve
3s - loss: 1.6539 - acc: 0.4871 - val_loss: 1.6131 - val_acc: 0.4956
Epoch 89/500
Epoch 00088: val_loss improved from 1.59213 to 1.56994, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.6493 - acc: 0.4877 - val_loss: 1.5699 - val_acc: 0.5090
Epoch 90/500
Epoch 00089: val_loss did not improve
2s - loss: 1.6472 - acc: 0.4867 - val_loss: 1.5795 - val_acc: 0.5029
Epoch 91/500
Epoch 00090: val_loss did not improve
2s - loss: 1.6397 - acc: 0.4891 - val_loss: 1.5777 - val_acc: 0.5052
Epoch 92/500
Epoch 00091: val_loss improved from 1.56994 to 1.56001, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.6369 - acc: 0.4890 - val_loss: 1.5600 - val_acc: 0.5107
Epoch 93/500
Epoch 00092: val_loss improved from 1.56001 to 1.55612, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.6271 - acc: 0.4906 - val_loss: 1.5561 - val_acc: 0.5120
Epoch 94/500
Epoch 00093: val_loss did not improve
2s - loss: 1.6215 - acc: 0.4941 - val_loss: 1.5565 - val_acc: 0.5100
Epoch 95/500
Epoch 00094: val_loss improved from 1.55612 to 1.54066, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
3s - loss: 1.6204 - acc: 0.4930 - val_loss: 1.5407 - val_acc: 0.5163
Epoch 96/500
Epoch 00095: val_loss did not improve
2s - loss: 1.6128 - acc: 0.4949 - val_loss: 1.5596 - val_acc: 0.5068
Epoch 97/500
Epoch 00096: val_loss improved from 1.54066 to 1.54043, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.6094 - acc: 0.4968 - val_loss: 1.5404 - val_acc: 0.5150
Epoch 98/500
Epoch 00097: val_loss improved from 1.54043 to 1.53597, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.6020 - acc: 0.4974 - val_loss: 1.5360 - val_acc: 0.5170
Epoch 99/500
Epoch 00098: val_loss improved from 1.53597 to 1.52560, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.5954 - acc: 0.5006 - val_loss: 1.5256 - val_acc: 0.5170
Epoch 100/500
Epoch 00099: val_loss improved from 1.52560 to 1.52184, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.5895 - acc: 0.5007 - val_loss: 1.5218 - val_acc: 0.5196
Epoch 101/500
Epoch 00100: val_loss improved from 1.52184 to 1.51961, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
3s - loss: 1.5852 - acc: 0.5016 - val_loss: 1.5196 - val_acc: 0.5185
Epoch 102/500
Epoch 00101: val_loss improved from 1.51961 to 1.50205, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.5865 - acc: 0.5015 - val_loss: 1.5021 - val_acc: 0.5255
Epoch 103/500
Epoch 00102: val_loss improved from 1.50205 to 1.49013, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.5697 - acc: 0.5035 - val_loss: 1.4901 - val_acc: 0.5280
Epoch 104/500
Epoch 00103: val_loss did not improve
2s - loss: 1.5670 - acc: 0.5080 - val_loss: 1.5003 - val_acc: 0.5248
Epoch 105/500
Epoch 00104: val_loss improved from 1.49013 to 1.48479, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.5657 - acc: 0.5072 - val_loss: 1.4848 - val_acc: 0.5303
Epoch 106/500
Epoch 00105: val_loss did not improve
2s - loss: 1.5649 - acc: 0.5067 - val_loss: 1.4859 - val_acc: 0.5292
Epoch 107/500
Epoch 00106: val_loss did not improve
3s - loss: 1.5614 - acc: 0.5066 - val_loss: 1.4870 - val_acc: 0.5278
Epoch 108/500
Epoch 00107: val_loss improved from 1.48479 to 1.47976, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.5516 - acc: 0.5103 - val_loss: 1.4798 - val_acc: 0.5283
Epoch 109/500
Epoch 00108: val_loss did not improve
2s - loss: 1.5517 - acc: 0.5075 - val_loss: 1.4826 - val_acc: 0.5296
Epoch 110/500
Epoch 00109: val_loss improved from 1.47976 to 1.46607, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.5480 - acc: 0.5106 - val_loss: 1.4661 - val_acc: 0.5335
Epoch 111/500
Epoch 00110: val_loss improved from 1.46607 to 1.45904, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.5454 - acc: 0.5122 - val_loss: 1.4590 - val_acc: 0.5351
Epoch 112/500
Epoch 00111: val_loss did not improve
2s - loss: 1.5432 - acc: 0.5113 - val_loss: 1.4601 - val_acc: 0.5365
Epoch 113/500
Epoch 00112: val_loss improved from 1.45904 to 1.45710, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.5342 - acc: 0.5148 - val_loss: 1.4571 - val_acc: 0.5376
Epoch 114/500
Epoch 00113: val_loss improved from 1.45710 to 1.45468, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
3s - loss: 1.5316 - acc: 0.5157 - val_loss: 1.4547 - val_acc: 0.5382
Epoch 115/500
Epoch 00114: val_loss did not improve
2s - loss: 1.5290 - acc: 0.5163 - val_loss: 1.4556 - val_acc: 0.5346
Epoch 116/500
Epoch 00115: val_loss improved from 1.45468 to 1.44748, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.5279 - acc: 0.5148 - val_loss: 1.4475 - val_acc: 0.5382
Epoch 117/500
Epoch 00116: val_loss improved from 1.44748 to 1.44600, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.5251 - acc: 0.5153 - val_loss: 1.4460 - val_acc: 0.5397
Epoch 118/500
Epoch 00117: val_loss improved from 1.44600 to 1.43713, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.5179 - acc: 0.5165 - val_loss: 1.4371 - val_acc: 0.5439
Epoch 119/500
Epoch 00118: val_loss improved from 1.43713 to 1.43301, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.5111 - acc: 0.5206 - val_loss: 1.4330 - val_acc: 0.5451
Epoch 120/500
Epoch 00119: val_loss improved from 1.43301 to 1.42748, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
3s - loss: 1.5078 - acc: 0.5198 - val_loss: 1.4275 - val_acc: 0.5430
Epoch 121/500
Epoch 00120: val_loss improved from 1.42748 to 1.41736, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.5075 - acc: 0.5203 - val_loss: 1.4174 - val_acc: 0.5466
Epoch 122/500
Epoch 00121: val_loss improved from 1.41736 to 1.41217, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.5043 - acc: 0.5198 - val_loss: 1.4122 - val_acc: 0.5443
Epoch 123/500
Epoch 00122: val_loss did not improve
2s - loss: 1.5012 - acc: 0.5227 - val_loss: 1.4135 - val_acc: 0.5473
Epoch 124/500
Epoch 00123: val_loss did not improve
2s - loss: 1.4896 - acc: 0.5258 - val_loss: 1.4473 - val_acc: 0.5339
Epoch 125/500
Epoch 00124: val_loss improved from 1.41217 to 1.40686, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.5023 - acc: 0.5221 - val_loss: 1.4069 - val_acc: 0.5486
Epoch 126/500
Epoch 00125: val_loss did not improve
2s - loss: 1.4934 - acc: 0.5222 - val_loss: 1.4080 - val_acc: 0.5480
Epoch 127/500
Epoch 00126: val_loss improved from 1.40686 to 1.40659, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
3s - loss: 1.4917 - acc: 0.5245 - val_loss: 1.4066 - val_acc: 0.5482
Epoch 128/500
Epoch 00127: val_loss improved from 1.40659 to 1.39526, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.4817 - acc: 0.5282 - val_loss: 1.3953 - val_acc: 0.5512
Epoch 129/500
Epoch 00128: val_loss did not improve
2s - loss: 1.4843 - acc: 0.5258 - val_loss: 1.3955 - val_acc: 0.5500
Epoch 130/500
Epoch 00129: val_loss did not improve
2s - loss: 1.4797 - acc: 0.5281 - val_loss: 1.3959 - val_acc: 0.5505
Epoch 131/500
Epoch 00130: val_loss did not improve
2s - loss: 1.4744 - acc: 0.5300 - val_loss: 1.4019 - val_acc: 0.5501
Epoch 132/500
Epoch 00131: val_loss improved from 1.39526 to 1.38452, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.4702 - acc: 0.5292 - val_loss: 1.3845 - val_acc: 0.5540
Epoch 133/500
Epoch 00132: val_loss improved from 1.38452 to 1.37639, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.4647 - acc: 0.5310 - val_loss: 1.3764 - val_acc: 0.5596
Epoch 134/500
Epoch 00133: val_loss improved from 1.37639 to 1.37152, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.4643 - acc: 0.5313 - val_loss: 1.3715 - val_acc: 0.5601
Epoch 135/500
Epoch 00134: val_loss did not improve
2s - loss: 1.4576 - acc: 0.5331 - val_loss: 1.3816 - val_acc: 0.5574
Epoch 136/500
Epoch 00135: val_loss did not improve
2s - loss: 1.4620 - acc: 0.5314 - val_loss: 1.3721 - val_acc: 0.5580
Epoch 137/500
Epoch 00136: val_loss improved from 1.37152 to 1.37136, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.4565 - acc: 0.5331 - val_loss: 1.3714 - val_acc: 0.5577
Epoch 138/500
Epoch 00137: val_loss did not improve
2s - loss: 1.4559 - acc: 0.5366 - val_loss: 1.3754 - val_acc: 0.5585
Epoch 139/500
Epoch 00138: val_loss improved from 1.37136 to 1.35163, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.4517 - acc: 0.5356 - val_loss: 1.3516 - val_acc: 0.5645
Epoch 140/500
Epoch 00139: val_loss did not improve
2s - loss: 1.4436 - acc: 0.5378 - val_loss: 1.3742 - val_acc: 0.5582
Epoch 141/500
Epoch 00140: val_loss did not improve
2s - loss: 1.4473 - acc: 0.5366 - val_loss: 1.3617 - val_acc: 0.5614
Epoch 142/500
Epoch 00141: val_loss improved from 1.35163 to 1.33754, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.4413 - acc: 0.5396 - val_loss: 1.3375 - val_acc: 0.5658
Epoch 143/500
Epoch 00142: val_loss did not improve
2s - loss: 1.4281 - acc: 0.5407 - val_loss: 1.3387 - val_acc: 0.5689
Epoch 144/500
Epoch 00143: val_loss did not improve
2s - loss: 1.4259 - acc: 0.5417 - val_loss: 1.3469 - val_acc: 0.5650
Epoch 145/500
Epoch 00144: val_loss improved from 1.33754 to 1.32319, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.4218 - acc: 0.5449 - val_loss: 1.3232 - val_acc: 0.5714
Epoch 146/500
Epoch 00145: val_loss improved from 1.32319 to 1.32283, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.4173 - acc: 0.5458 - val_loss: 1.3228 - val_acc: 0.5719
Epoch 147/500
Epoch 00146: val_loss did not improve
2s - loss: 1.4115 - acc: 0.5464 - val_loss: 1.3265 - val_acc: 0.5722
Epoch 148/500
Epoch 00147: val_loss did not improve
2s - loss: 1.4116 - acc: 0.5459 - val_loss: 1.3242 - val_acc: 0.5711
Epoch 149/500
Epoch 00148: val_loss improved from 1.32283 to 1.30031, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.4098 - acc: 0.5455 - val_loss: 1.3003 - val_acc: 0.5780
Epoch 150/500
Epoch 00149: val_loss improved from 1.30031 to 1.30017, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.3968 - acc: 0.5473 - val_loss: 1.3002 - val_acc: 0.5803
Epoch 151/500
Epoch 00150: val_loss improved from 1.30017 to 1.29465, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.4018 - acc: 0.5482 - val_loss: 1.2946 - val_acc: 0.5805
Epoch 152/500
Epoch 00151: val_loss improved from 1.29465 to 1.28673, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.3898 - acc: 0.5521 - val_loss: 1.2867 - val_acc: 0.5806
Epoch 153/500
Epoch 00152: val_loss did not improve
2s - loss: 1.3920 - acc: 0.5502 - val_loss: 1.3036 - val_acc: 0.5734
Epoch 154/500
Epoch 00153: val_loss improved from 1.28673 to 1.28551, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.3919 - acc: 0.5494 - val_loss: 1.2855 - val_acc: 0.5830
Epoch 155/500
Epoch 00154: val_loss improved from 1.28551 to 1.27243, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.3823 - acc: 0.5528 - val_loss: 1.2724 - val_acc: 0.5861
Epoch 156/500
Epoch 00155: val_loss did not improve
2s - loss: 1.3729 - acc: 0.5559 - val_loss: 1.2932 - val_acc: 0.5765
Epoch 157/500
Epoch 00156: val_loss improved from 1.27243 to 1.26673, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.3727 - acc: 0.5562 - val_loss: 1.2667 - val_acc: 0.5891
Epoch 158/500
Epoch 00157: val_loss did not improve
2s - loss: 1.3634 - acc: 0.5594 - val_loss: 1.2676 - val_acc: 0.5882
Epoch 159/500
Epoch 00158: val_loss did not improve
2s - loss: 1.3647 - acc: 0.5585 - val_loss: 1.2790 - val_acc: 0.5799
Epoch 160/500
Epoch 00159: val_loss improved from 1.26673 to 1.25542, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.3636 - acc: 0.5597 - val_loss: 1.2554 - val_acc: 0.5891
Epoch 161/500
Epoch 00160: val_loss did not improve
2s - loss: 1.3563 - acc: 0.5633 - val_loss: 1.2664 - val_acc: 0.5840
Epoch 162/500
Epoch 00161: val_loss improved from 1.25542 to 1.24610, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.3570 - acc: 0.5595 - val_loss: 1.2461 - val_acc: 0.5942
Epoch 163/500
Epoch 00162: val_loss improved from 1.24610 to 1.23488, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.3451 - acc: 0.5643 - val_loss: 1.2349 - val_acc: 0.5993
Epoch 164/500
Epoch 00163: val_loss did not improve
2s - loss: 1.3446 - acc: 0.5636 - val_loss: 1.2448 - val_acc: 0.5927
Epoch 165/500
Epoch 00164: val_loss did not improve
2s - loss: 1.3356 - acc: 0.5668 - val_loss: 1.2450 - val_acc: 0.5935
Epoch 166/500
Epoch 00165: val_loss improved from 1.23488 to 1.22243, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.3364 - acc: 0.5639 - val_loss: 1.2224 - val_acc: 0.6011
Epoch 167/500
Epoch 00166: val_loss did not improve
2s - loss: 1.3364 - acc: 0.5649 - val_loss: 1.2338 - val_acc: 0.5934
Epoch 168/500
Epoch 00167: val_loss did not improve
2s - loss: 1.3382 - acc: 0.5657 - val_loss: 1.2264 - val_acc: 0.5990
Epoch 169/500
Epoch 00168: val_loss improved from 1.22243 to 1.21938, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.3320 - acc: 0.5681 - val_loss: 1.2194 - val_acc: 0.6020
Epoch 170/500
Epoch 00169: val_loss improved from 1.21938 to 1.21778, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.3246 - acc: 0.5699 - val_loss: 1.2178 - val_acc: 0.6012
Epoch 171/500
Epoch 00170: val_loss did not improve
2s - loss: 1.3198 - acc: 0.5710 - val_loss: 1.2352 - val_acc: 0.5915
Epoch 172/500
Epoch 00171: val_loss improved from 1.21778 to 1.21202, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.3202 - acc: 0.5697 - val_loss: 1.2120 - val_acc: 0.6001
Epoch 173/500
Epoch 00172: val_loss improved from 1.21202 to 1.19841, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.3185 - acc: 0.5718 - val_loss: 1.1984 - val_acc: 0.6071
Epoch 174/500
Epoch 00173: val_loss did not improve
2s - loss: 1.3187 - acc: 0.5714 - val_loss: 1.2164 - val_acc: 0.6019
Epoch 175/500
Epoch 00174: val_loss did not improve
2s - loss: 1.3140 - acc: 0.5734 - val_loss: 1.2102 - val_acc: 0.6030
Epoch 176/500
Epoch 00175: val_loss did not improve
2s - loss: 1.3039 - acc: 0.5773 - val_loss: 1.2901 - val_acc: 0.5745
Epoch 177/500
Epoch 00176: val_loss did not improve
2s - loss: 1.3216 - acc: 0.5703 - val_loss: 1.1987 - val_acc: 0.6067
Epoch 178/500
Epoch 00177: val_loss did not improve
2s - loss: 1.3035 - acc: 0.5771 - val_loss: 1.2054 - val_acc: 0.6038
Epoch 179/500
Epoch 00178: val_loss improved from 1.19841 to 1.18215, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.2993 - acc: 0.5769 - val_loss: 1.1821 - val_acc: 0.6112
Epoch 180/500
Epoch 00179: val_loss did not improve
2s - loss: 1.2914 - acc: 0.5791 - val_loss: 1.1824 - val_acc: 0.6120
Epoch 181/500
Epoch 00180: val_loss did not improve
2s - loss: 1.2986 - acc: 0.5768 - val_loss: 1.1838 - val_acc: 0.6084
Epoch 182/500
Epoch 00181: val_loss did not improve
2s - loss: 1.2943 - acc: 0.5779 - val_loss: 1.1846 - val_acc: 0.6104
Epoch 183/500
Epoch 00182: val_loss did not improve
2s - loss: 1.2877 - acc: 0.5796 - val_loss: 1.1896 - val_acc: 0.6095
Epoch 184/500
Epoch 00183: val_loss did not improve
2s - loss: 1.2836 - acc: 0.5821 - val_loss: 1.1912 - val_acc: 0.6079
Epoch 185/500
Epoch 00184: val_loss did not improve
2s - loss: 1.2837 - acc: 0.5806 - val_loss: 1.1844 - val_acc: 0.6097
Epoch 186/500
Epoch 00185: val_loss improved from 1.18215 to 1.16147, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.2853 - acc: 0.5823 - val_loss: 1.1615 - val_acc: 0.6183
Epoch 187/500
Epoch 00186: val_loss did not improve
2s - loss: 1.2756 - acc: 0.5856 - val_loss: 1.1623 - val_acc: 0.6169
Epoch 188/500
Epoch 00187: val_loss did not improve
2s - loss: 1.2676 - acc: 0.5864 - val_loss: 1.1685 - val_acc: 0.6171
Epoch 189/500
Epoch 00188: val_loss did not improve
2s - loss: 1.2692 - acc: 0.5844 - val_loss: 1.1801 - val_acc: 0.6123
Epoch 190/500
Epoch 00189: val_loss improved from 1.16147 to 1.15229, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.2763 - acc: 0.5848 - val_loss: 1.1523 - val_acc: 0.6200
Epoch 191/500
Epoch 00190: val_loss improved from 1.15229 to 1.15203, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.2596 - acc: 0.5881 - val_loss: 1.1520 - val_acc: 0.6190
Epoch 192/500
Epoch 00191: val_loss improved from 1.15203 to 1.14132, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.2686 - acc: 0.5867 - val_loss: 1.1413 - val_acc: 0.6233
Epoch 193/500
Epoch 00192: val_loss did not improve
2s - loss: 1.2613 - acc: 0.5893 - val_loss: 1.1442 - val_acc: 0.6215
Epoch 194/500
Epoch 00193: val_loss did not improve
2s - loss: 1.2599 - acc: 0.5874 - val_loss: 1.1672 - val_acc: 0.6162
Epoch 195/500
Epoch 00194: val_loss improved from 1.14132 to 1.13653, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.2551 - acc: 0.5906 - val_loss: 1.1365 - val_acc: 0.6244
Epoch 196/500
Epoch 00195: val_loss did not improve
2s - loss: 1.2494 - acc: 0.5932 - val_loss: 1.1370 - val_acc: 0.6247
Epoch 197/500
Epoch 00196: val_loss did not improve
2s - loss: 1.2578 - acc: 0.5886 - val_loss: 1.1405 - val_acc: 0.6225
Epoch 198/500
Epoch 00197: val_loss improved from 1.13653 to 1.12930, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.2461 - acc: 0.5935 - val_loss: 1.1293 - val_acc: 0.6285
Epoch 199/500
Epoch 00198: val_loss did not improve
2s - loss: 1.2516 - acc: 0.5898 - val_loss: 1.1334 - val_acc: 0.6267
Epoch 200/500
Epoch 00199: val_loss improved from 1.12930 to 1.12818, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.2427 - acc: 0.5936 - val_loss: 1.1282 - val_acc: 0.6298
Epoch 201/500
Epoch 00200: val_loss did not improve
2s - loss: 1.2390 - acc: 0.5963 - val_loss: 1.1402 - val_acc: 0.6260
Epoch 202/500
Epoch 00201: val_loss improved from 1.12818 to 1.11815, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.2415 - acc: 0.5939 - val_loss: 1.1182 - val_acc: 0.6332
Epoch 203/500
Epoch 00202: val_loss improved from 1.11815 to 1.10937, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.2321 - acc: 0.5980 - val_loss: 1.1094 - val_acc: 0.6354
Epoch 204/500
Epoch 00203: val_loss did not improve
2s - loss: 1.2318 - acc: 0.5981 - val_loss: 1.1193 - val_acc: 0.6317
Epoch 205/500
Epoch 00204: val_loss did not improve
2s - loss: 1.2390 - acc: 0.5950 - val_loss: 1.1308 - val_acc: 0.6281
Epoch 206/500
Epoch 00205: val_loss did not improve
2s - loss: 1.2324 - acc: 0.5982 - val_loss: 1.1190 - val_acc: 0.6336
Epoch 207/500
Epoch 00206: val_loss did not improve
2s - loss: 1.2236 - acc: 0.6002 - val_loss: 1.1401 - val_acc: 0.6210
Epoch 208/500
Epoch 00207: val_loss improved from 1.10937 to 1.09804, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.2263 - acc: 0.5985 - val_loss: 1.0980 - val_acc: 0.6402
Epoch 209/500
Epoch 00208: val_loss improved from 1.09804 to 1.09156, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.2137 - acc: 0.6016 - val_loss: 1.0916 - val_acc: 0.6403
Epoch 210/500
Epoch 00209: val_loss did not improve
2s - loss: 1.2136 - acc: 0.6038 - val_loss: 1.0962 - val_acc: 0.6398
Epoch 211/500
Epoch 00210: val_loss did not improve
2s - loss: 1.2094 - acc: 0.6048 - val_loss: 1.1473 - val_acc: 0.6161
Epoch 212/500
Epoch 00211: val_loss improved from 1.09156 to 1.08801, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.2132 - acc: 0.6023 - val_loss: 1.0880 - val_acc: 0.6414
Epoch 213/500
Epoch 00212: val_loss improved from 1.08801 to 1.08737, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.2035 - acc: 0.6047 - val_loss: 1.0874 - val_acc: 0.6433
Epoch 214/500
Epoch 00213: val_loss improved from 1.08737 to 1.08402, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.2022 - acc: 0.6061 - val_loss: 1.0840 - val_acc: 0.6418
Epoch 215/500
Epoch 00214: val_loss improved from 1.08402 to 1.07166, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.1992 - acc: 0.6079 - val_loss: 1.0717 - val_acc: 0.6471
Epoch 216/500
Epoch 00215: val_loss did not improve
2s - loss: 1.1952 - acc: 0.6089 - val_loss: 1.0743 - val_acc: 0.6457
Epoch 217/500
Epoch 00216: val_loss did not improve
2s - loss: 1.1900 - acc: 0.6092 - val_loss: 1.0762 - val_acc: 0.6472
Epoch 218/500
Epoch 00217: val_loss improved from 1.07166 to 1.06064, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.1900 - acc: 0.6108 - val_loss: 1.0606 - val_acc: 0.6491
Epoch 219/500
Epoch 00218: val_loss did not improve
2s - loss: 1.1905 - acc: 0.6109 - val_loss: 1.0818 - val_acc: 0.6401
Epoch 220/500
Epoch 00219: val_loss did not improve
2s - loss: 1.1931 - acc: 0.6115 - val_loss: 1.0709 - val_acc: 0.6475
Epoch 221/500
Epoch 00220: val_loss improved from 1.06064 to 1.05577, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.1864 - acc: 0.6136 - val_loss: 1.0558 - val_acc: 0.6551
Epoch 222/500
Epoch 00221: val_loss improved from 1.05577 to 1.05169, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.1840 - acc: 0.6115 - val_loss: 1.0517 - val_acc: 0.6523
Epoch 223/500
Epoch 00222: val_loss improved from 1.05169 to 1.05074, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.1748 - acc: 0.6158 - val_loss: 1.0507 - val_acc: 0.6535
Epoch 224/500
Epoch 00223: val_loss did not improve
2s - loss: 1.1731 - acc: 0.6137 - val_loss: 1.0630 - val_acc: 0.6496
Epoch 225/500
Epoch 00224: val_loss improved from 1.05074 to 1.04837, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.1753 - acc: 0.6150 - val_loss: 1.0484 - val_acc: 0.6549
Epoch 226/500
Epoch 00225: val_loss improved from 1.04837 to 1.03199, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.1643 - acc: 0.6193 - val_loss: 1.0320 - val_acc: 0.6591
Epoch 227/500
Epoch 00226: val_loss did not improve
2s - loss: 1.1695 - acc: 0.6160 - val_loss: 1.1159 - val_acc: 0.6260
Epoch 228/500
Epoch 00227: val_loss did not improve
2s - loss: 1.1860 - acc: 0.6140 - val_loss: 1.0418 - val_acc: 0.6545
Epoch 229/500
Epoch 00228: val_loss did not improve
2s - loss: 1.1718 - acc: 0.6157 - val_loss: 1.0444 - val_acc: 0.6567
Epoch 230/500
Epoch 00229: val_loss improved from 1.03199 to 1.02263, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.1623 - acc: 0.6157 - val_loss: 1.0226 - val_acc: 0.6661
Epoch 231/500
Epoch 00230: val_loss did not improve
2s - loss: 1.1657 - acc: 0.6172 - val_loss: 1.0449 - val_acc: 0.6568
Epoch 232/500
Epoch 00231: val_loss did not improve
2s - loss: 1.1577 - acc: 0.6203 - val_loss: 1.0310 - val_acc: 0.6588
Epoch 233/500
Epoch 00232: val_loss did not improve
2s - loss: 1.1570 - acc: 0.6208 - val_loss: 1.0510 - val_acc: 0.6505
Epoch 234/500
Epoch 00233: val_loss did not improve
2s - loss: 1.1562 - acc: 0.6211 - val_loss: 1.0545 - val_acc: 0.6483
Epoch 235/500
Epoch 00234: val_loss did not improve
2s - loss: 1.1558 - acc: 0.6208 - val_loss: 1.0277 - val_acc: 0.6633
Epoch 236/500
Epoch 00235: val_loss improved from 1.02263 to 1.00889, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.1504 - acc: 0.6228 - val_loss: 1.0089 - val_acc: 0.6668
Epoch 237/500
Epoch 00236: val_loss improved from 1.00889 to 0.99784, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.1435 - acc: 0.6250 - val_loss: 0.9978 - val_acc: 0.6701
Epoch 238/500
Epoch 00237: val_loss did not improve
2s - loss: 1.1377 - acc: 0.6269 - val_loss: 1.0045 - val_acc: 0.6693
Epoch 239/500
Epoch 00238: val_loss did not improve
2s - loss: 1.1454 - acc: 0.6245 - val_loss: 1.0180 - val_acc: 0.6637
Epoch 240/500
Epoch 00239: val_loss improved from 0.99784 to 0.99755, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.1341 - acc: 0.6280 - val_loss: 0.9975 - val_acc: 0.6707
Epoch 241/500
Epoch 00240: val_loss did not improve
2s - loss: 1.1351 - acc: 0.6280 - val_loss: 1.0201 - val_acc: 0.6629
Epoch 242/500
Epoch 00241: val_loss improved from 0.99755 to 0.99440, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.1359 - acc: 0.6261 - val_loss: 0.9944 - val_acc: 0.6743
Epoch 243/500
Epoch 00242: val_loss improved from 0.99440 to 0.98765, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.1307 - acc: 0.6281 - val_loss: 0.9876 - val_acc: 0.6754
Epoch 244/500
Epoch 00243: val_loss did not improve
2s - loss: 1.1229 - acc: 0.6311 - val_loss: 0.9899 - val_acc: 0.6722
Epoch 245/500
Epoch 00244: val_loss improved from 0.98765 to 0.98730, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.1219 - acc: 0.6326 - val_loss: 0.9873 - val_acc: 0.6752
Epoch 246/500
Epoch 00245: val_loss improved from 0.98730 to 0.98299, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.1363 - acc: 0.6286 - val_loss: 0.9830 - val_acc: 0.6764
Epoch 247/500
Epoch 00246: val_loss improved from 0.98299 to 0.98275, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.1286 - acc: 0.6308 - val_loss: 0.9828 - val_acc: 0.6772
Epoch 248/500
Epoch 00247: val_loss did not improve
2s - loss: 1.1218 - acc: 0.6316 - val_loss: 0.9937 - val_acc: 0.6771
Epoch 249/500
Epoch 00248: val_loss did not improve
2s - loss: 1.1272 - acc: 0.6297 - val_loss: 0.9859 - val_acc: 0.6756
Epoch 250/500
Epoch 00249: val_loss improved from 0.98275 to 0.96659, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.1218 - acc: 0.6336 - val_loss: 0.9666 - val_acc: 0.6816
Epoch 251/500
Epoch 00250: val_loss improved from 0.96659 to 0.96624, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.1085 - acc: 0.6384 - val_loss: 0.9662 - val_acc: 0.6838
Epoch 252/500
Epoch 00251: val_loss did not improve
2s - loss: 1.1073 - acc: 0.6389 - val_loss: 0.9776 - val_acc: 0.6778
Epoch 253/500
Epoch 00252: val_loss did not improve
2s - loss: 1.1142 - acc: 0.6351 - val_loss: 0.9838 - val_acc: 0.6734
Epoch 254/500
Epoch 00253: val_loss did not improve
2s - loss: 1.1104 - acc: 0.6369 - val_loss: 0.9726 - val_acc: 0.6778
Epoch 255/500
Epoch 00254: val_loss improved from 0.96624 to 0.96216, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.1003 - acc: 0.6414 - val_loss: 0.9622 - val_acc: 0.6819
Epoch 256/500
Epoch 00255: val_loss improved from 0.96216 to 0.94893, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.1021 - acc: 0.6384 - val_loss: 0.9489 - val_acc: 0.6863
Epoch 257/500
Epoch 00256: val_loss did not improve
2s - loss: 1.0952 - acc: 0.6395 - val_loss: 0.9576 - val_acc: 0.6829
Epoch 258/500
Epoch 00257: val_loss improved from 0.94893 to 0.94426, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.0981 - acc: 0.6397 - val_loss: 0.9443 - val_acc: 0.6884
Epoch 259/500
Epoch 00258: val_loss did not improve
2s - loss: 1.0940 - acc: 0.6418 - val_loss: 0.9528 - val_acc: 0.6846
Epoch 260/500
Epoch 00259: val_loss did not improve
2s - loss: 1.0982 - acc: 0.6411 - val_loss: 0.9715 - val_acc: 0.6765
Epoch 261/500
Epoch 00260: val_loss did not improve
2s - loss: 1.0965 - acc: 0.6389 - val_loss: 0.9747 - val_acc: 0.6753
Epoch 262/500
Epoch 00261: val_loss did not improve
2s - loss: 1.0999 - acc: 0.6393 - val_loss: 0.9477 - val_acc: 0.6878
Epoch 263/500
Epoch 00262: val_loss did not improve
2s - loss: 1.0912 - acc: 0.6425 - val_loss: 0.9567 - val_acc: 0.6819
Epoch 264/500
Epoch 00263: val_loss improved from 0.94426 to 0.93530, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.0903 - acc: 0.6432 - val_loss: 0.9353 - val_acc: 0.6917
Epoch 265/500
Epoch 00264: val_loss did not improve
2s - loss: 1.0804 - acc: 0.6459 - val_loss: 1.0018 - val_acc: 0.6639
Epoch 266/500
Epoch 00265: val_loss did not improve
2s - loss: 1.1021 - acc: 0.6404 - val_loss: 0.9416 - val_acc: 0.6898
Epoch 267/500
Epoch 00266: val_loss did not improve
2s - loss: 1.0772 - acc: 0.6469 - val_loss: 0.9378 - val_acc: 0.6907
Epoch 268/500
Epoch 00267: val_loss did not improve
2s - loss: 1.0775 - acc: 0.6460 - val_loss: 0.9425 - val_acc: 0.6859
Epoch 269/500
Epoch 00268: val_loss improved from 0.93530 to 0.93327, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.0729 - acc: 0.6483 - val_loss: 0.9333 - val_acc: 0.6922
Epoch 270/500
Epoch 00269: val_loss did not improve
2s - loss: 1.0835 - acc: 0.6444 - val_loss: 0.9408 - val_acc: 0.6883
Epoch 271/500
Epoch 00270: val_loss improved from 0.93327 to 0.91576, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.0741 - acc: 0.6486 - val_loss: 0.9158 - val_acc: 0.6998
Epoch 272/500
Epoch 00271: val_loss did not improve
2s - loss: 1.0737 - acc: 0.6480 - val_loss: 0.9251 - val_acc: 0.6945
Epoch 273/500
Epoch 00272: val_loss did not improve
2s - loss: 1.0780 - acc: 0.6464 - val_loss: 0.9312 - val_acc: 0.6906
Epoch 274/500
Epoch 00273: val_loss did not improve
2s - loss: 1.0690 - acc: 0.6496 - val_loss: 0.9462 - val_acc: 0.6889
Epoch 275/500
Epoch 00274: val_loss improved from 0.91576 to 0.91415, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.0732 - acc: 0.6490 - val_loss: 0.9142 - val_acc: 0.6986
Epoch 276/500
Epoch 00275: val_loss did not improve
2s - loss: 1.0661 - acc: 0.6510 - val_loss: 0.9418 - val_acc: 0.6888
Epoch 277/500
Epoch 00276: val_loss improved from 0.91415 to 0.90680, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.0638 - acc: 0.6516 - val_loss: 0.9068 - val_acc: 0.7014
Epoch 278/500
Epoch 00277: val_loss did not improve
2s - loss: 1.0648 - acc: 0.6520 - val_loss: 0.9077 - val_acc: 0.6967
Epoch 279/500
Epoch 00278: val_loss did not improve
2s - loss: 1.0550 - acc: 0.6544 - val_loss: 0.9131 - val_acc: 0.6979
Epoch 280/500
Epoch 00279: val_loss improved from 0.90680 to 0.90299, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.0528 - acc: 0.6558 - val_loss: 0.9030 - val_acc: 0.7020
Epoch 281/500
Epoch 00280: val_loss improved from 0.90299 to 0.90105, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.0590 - acc: 0.6518 - val_loss: 0.9011 - val_acc: 0.7022
Epoch 282/500
Epoch 00281: val_loss did not improve
2s - loss: 1.0523 - acc: 0.6556 - val_loss: 0.9085 - val_acc: 0.6985
Epoch 283/500
Epoch 00282: val_loss improved from 0.90105 to 0.88978, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.0514 - acc: 0.6553 - val_loss: 0.8898 - val_acc: 0.7088
Epoch 284/500
Epoch 00283: val_loss did not improve
2s - loss: 1.0469 - acc: 0.6572 - val_loss: 0.8991 - val_acc: 0.7039
Epoch 285/500
Epoch 00284: val_loss did not improve
2s - loss: 1.0515 - acc: 0.6535 - val_loss: 0.9037 - val_acc: 0.6983
Epoch 286/500
Epoch 00285: val_loss did not improve
2s - loss: 1.0484 - acc: 0.6554 - val_loss: 0.8916 - val_acc: 0.7030
Epoch 287/500
Epoch 00286: val_loss did not improve
2s - loss: 1.0445 - acc: 0.6580 - val_loss: 0.9070 - val_acc: 0.6996
Epoch 288/500
Epoch 00287: val_loss improved from 0.88978 to 0.88875, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.0426 - acc: 0.6582 - val_loss: 0.8888 - val_acc: 0.7054
Epoch 289/500
Epoch 00288: val_loss improved from 0.88875 to 0.88373, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.0358 - acc: 0.6603 - val_loss: 0.8837 - val_acc: 0.7073
Epoch 290/500
Epoch 00289: val_loss improved from 0.88373 to 0.88127, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.0383 - acc: 0.6585 - val_loss: 0.8813 - val_acc: 0.7085
Epoch 291/500
Epoch 00290: val_loss did not improve
2s - loss: 1.0353 - acc: 0.6577 - val_loss: 0.9017 - val_acc: 0.7017
Epoch 292/500
Epoch 00291: val_loss did not improve
2s - loss: 1.0427 - acc: 0.6581 - val_loss: 0.8829 - val_acc: 0.7095
Epoch 293/500
Epoch 00292: val_loss did not improve
2s - loss: 1.0326 - acc: 0.6610 - val_loss: 0.9078 - val_acc: 0.6978
Epoch 294/500
Epoch 00293: val_loss did not improve
2s - loss: 1.0411 - acc: 0.6581 - val_loss: 0.8846 - val_acc: 0.7099
Epoch 295/500
Epoch 00294: val_loss improved from 0.88127 to 0.87683, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.0281 - acc: 0.6618 - val_loss: 0.8768 - val_acc: 0.7092
Epoch 296/500
Epoch 00295: val_loss improved from 0.87683 to 0.87270, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.0328 - acc: 0.6600 - val_loss: 0.8727 - val_acc: 0.7099
Epoch 297/500
Epoch 00296: val_loss improved from 0.87270 to 0.86874, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.0296 - acc: 0.6648 - val_loss: 0.8687 - val_acc: 0.7071
Epoch 298/500
Epoch 00297: val_loss did not improve
2s - loss: 1.0254 - acc: 0.6618 - val_loss: 0.8801 - val_acc: 0.7080
Epoch 299/500
Epoch 00298: val_loss did not improve
2s - loss: 1.0276 - acc: 0.6634 - val_loss: 0.8786 - val_acc: 0.7082
Epoch 300/500
Epoch 00299: val_loss improved from 0.86874 to 0.85600, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.0265 - acc: 0.6627 - val_loss: 0.8560 - val_acc: 0.7170
Epoch 301/500
Epoch 00300: val_loss did not improve
2s - loss: 1.0217 - acc: 0.6638 - val_loss: 0.8846 - val_acc: 0.7065
Epoch 302/500
Epoch 00301: val_loss did not improve
2s - loss: 1.0373 - acc: 0.6607 - val_loss: 0.8614 - val_acc: 0.7148
Epoch 303/500
Epoch 00302: val_loss did not improve
2s - loss: 1.0139 - acc: 0.6689 - val_loss: 0.8806 - val_acc: 0.7090
Epoch 304/500
Epoch 00303: val_loss did not improve
2s - loss: 1.0183 - acc: 0.6649 - val_loss: 0.8789 - val_acc: 0.7105
Epoch 305/500
Epoch 00304: val_loss did not improve
2s - loss: 1.0199 - acc: 0.6649 - val_loss: 0.8611 - val_acc: 0.7144
Epoch 306/500
Epoch 00305: val_loss did not improve
2s - loss: 1.0150 - acc: 0.6665 - val_loss: 0.8704 - val_acc: 0.7100
Epoch 307/500
Epoch 00306: val_loss did not improve
2s - loss: 1.0183 - acc: 0.6655 - val_loss: 0.8574 - val_acc: 0.7163
Epoch 308/500
Epoch 00307: val_loss did not improve
2s - loss: 1.0153 - acc: 0.6659 - val_loss: 0.8590 - val_acc: 0.7137
Epoch 309/500
Epoch 00308: val_loss improved from 0.85600 to 0.84536, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.0070 - acc: 0.6703 - val_loss: 0.8454 - val_acc: 0.7222
Epoch 310/500
Epoch 00309: val_loss did not improve
2s - loss: 1.0055 - acc: 0.6693 - val_loss: 0.8479 - val_acc: 0.7208
Epoch 311/500
Epoch 00310: val_loss did not improve
2s - loss: 1.0075 - acc: 0.6696 - val_loss: 0.8554 - val_acc: 0.7160
Epoch 312/500
Epoch 00311: val_loss improved from 0.84536 to 0.84103, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.0047 - acc: 0.6716 - val_loss: 0.8410 - val_acc: 0.7215
Epoch 313/500
Epoch 00312: val_loss did not improve
2s - loss: 1.0021 - acc: 0.6701 - val_loss: 0.8425 - val_acc: 0.7216
Epoch 314/500
Epoch 00313: val_loss did not improve
2s - loss: 0.9985 - acc: 0.6726 - val_loss: 0.8416 - val_acc: 0.7200
Epoch 315/500
Epoch 00314: val_loss did not improve
2s - loss: 0.9997 - acc: 0.6720 - val_loss: 0.8606 - val_acc: 0.7172
Epoch 316/500
Epoch 00315: val_loss did not improve
2s - loss: 1.0058 - acc: 0.6722 - val_loss: 0.8626 - val_acc: 0.7116
Epoch 317/500
Epoch 00316: val_loss did not improve
2s - loss: 1.0003 - acc: 0.6706 - val_loss: 0.8510 - val_acc: 0.7159
Epoch 318/500
Epoch 00317: val_loss improved from 0.84103 to 0.83592, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.0003 - acc: 0.6729 - val_loss: 0.8359 - val_acc: 0.7225
Epoch 319/500
Epoch 00318: val_loss did not improve
2s - loss: 0.9866 - acc: 0.6759 - val_loss: 0.8426 - val_acc: 0.7190
Epoch 320/500
Epoch 00319: val_loss improved from 0.83592 to 0.83211, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 1.0001 - acc: 0.6702 - val_loss: 0.8321 - val_acc: 0.7251
Epoch 321/500
Epoch 00320: val_loss did not improve
2s - loss: 0.9919 - acc: 0.6739 - val_loss: 0.8518 - val_acc: 0.7156
Epoch 322/500
Epoch 00321: val_loss improved from 0.83211 to 0.82020, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 0.9946 - acc: 0.6736 - val_loss: 0.8202 - val_acc: 0.7249
Epoch 323/500
Epoch 00322: val_loss did not improve
2s - loss: 0.9828 - acc: 0.6771 - val_loss: 0.8388 - val_acc: 0.7218
Epoch 324/500
Epoch 00323: val_loss did not improve
2s - loss: 0.9948 - acc: 0.6721 - val_loss: 0.8454 - val_acc: 0.7196
Epoch 325/500
Epoch 00324: val_loss did not improve
2s - loss: 0.9871 - acc: 0.6769 - val_loss: 0.8469 - val_acc: 0.7158
Epoch 326/500
Epoch 00325: val_loss did not improve
2s - loss: 0.9918 - acc: 0.6739 - val_loss: 0.8237 - val_acc: 0.7281
Epoch 327/500
Epoch 00326: val_loss improved from 0.82020 to 0.81704, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 0.9841 - acc: 0.6742 - val_loss: 0.8170 - val_acc: 0.7294
Epoch 328/500
Epoch 00327: val_loss did not improve
2s - loss: 0.9830 - acc: 0.6776 - val_loss: 0.8227 - val_acc: 0.7268
Epoch 329/500
Epoch 00328: val_loss did not improve
2s - loss: 0.9777 - acc: 0.6776 - val_loss: 0.8231 - val_acc: 0.7241
Epoch 330/500
Epoch 00329: val_loss improved from 0.81704 to 0.80876, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 0.9778 - acc: 0.6773 - val_loss: 0.8088 - val_acc: 0.7334
Epoch 331/500
Epoch 00330: val_loss did not improve
2s - loss: 0.9737 - acc: 0.6809 - val_loss: 0.8229 - val_acc: 0.7294
Epoch 332/500
Epoch 00331: val_loss did not improve
2s - loss: 0.9798 - acc: 0.6768 - val_loss: 0.8170 - val_acc: 0.7305
Epoch 333/500
Epoch 00332: val_loss did not improve
2s - loss: 0.9717 - acc: 0.6815 - val_loss: 0.8123 - val_acc: 0.7318
Epoch 334/500
Epoch 00333: val_loss improved from 0.80876 to 0.80119, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
3s - loss: 0.9754 - acc: 0.6815 - val_loss: 0.8012 - val_acc: 0.7348
Epoch 335/500
Epoch 00334: val_loss did not improve
2s - loss: 0.9652 - acc: 0.6812 - val_loss: 0.8082 - val_acc: 0.7349
Epoch 336/500
Epoch 00335: val_loss did not improve
2s - loss: 0.9749 - acc: 0.6793 - val_loss: 0.8065 - val_acc: 0.7346
Epoch 337/500
Epoch 00336: val_loss did not improve
2s - loss: 0.9654 - acc: 0.6811 - val_loss: 0.8736 - val_acc: 0.7068
Epoch 338/500
Epoch 00337: val_loss did not improve
2s - loss: 0.9869 - acc: 0.6749 - val_loss: 0.8245 - val_acc: 0.7301
Epoch 339/500
Epoch 00338: val_loss did not improve
2s - loss: 0.9664 - acc: 0.6822 - val_loss: 0.8023 - val_acc: 0.7344
Epoch 340/500
Epoch 00339: val_loss did not improve
2s - loss: 0.9607 - acc: 0.6836 - val_loss: 0.8150 - val_acc: 0.7307
Epoch 341/500
Epoch 00340: val_loss improved from 0.80119 to 0.79693, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
3s - loss: 0.9753 - acc: 0.6805 - val_loss: 0.7969 - val_acc: 0.7369
Epoch 342/500
Epoch 00341: val_loss did not improve
2s - loss: 0.9649 - acc: 0.6839 - val_loss: 0.8027 - val_acc: 0.7315
Epoch 343/500
Epoch 00342: val_loss improved from 0.79693 to 0.78624, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 0.9592 - acc: 0.6860 - val_loss: 0.7862 - val_acc: 0.7425
Epoch 344/500
Epoch 00343: val_loss did not improve
2s - loss: 0.9476 - acc: 0.6870 - val_loss: 0.8033 - val_acc: 0.7305
Epoch 345/500
Epoch 00344: val_loss did not improve
2s - loss: 0.9596 - acc: 0.6834 - val_loss: 0.8043 - val_acc: 0.7345
Epoch 346/500
Epoch 00345: val_loss did not improve
2s - loss: 0.9612 - acc: 0.6842 - val_loss: 0.8160 - val_acc: 0.7290
Epoch 347/500
Epoch 00346: val_loss improved from 0.78624 to 0.78154, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
3s - loss: 0.9569 - acc: 0.6858 - val_loss: 0.7815 - val_acc: 0.7403
Epoch 348/500
Epoch 00347: val_loss did not improve
2s - loss: 0.9617 - acc: 0.6840 - val_loss: 0.7854 - val_acc: 0.7416
Epoch 349/500
Epoch 00348: val_loss did not improve
2s - loss: 0.9542 - acc: 0.6855 - val_loss: 0.8013 - val_acc: 0.7353
Epoch 350/500
Epoch 00349: val_loss did not improve
2s - loss: 0.9536 - acc: 0.6861 - val_loss: 0.7891 - val_acc: 0.7428
Epoch 351/500
Epoch 00350: val_loss did not improve
2s - loss: 0.9528 - acc: 0.6861 - val_loss: 0.7847 - val_acc: 0.7412
Epoch 352/500
Epoch 00351: val_loss did not improve
2s - loss: 0.9451 - acc: 0.6880 - val_loss: 0.7940 - val_acc: 0.7355
Epoch 353/500
Epoch 00352: val_loss improved from 0.78154 to 0.76480, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 0.9428 - acc: 0.6894 - val_loss: 0.7648 - val_acc: 0.7462
Epoch 354/500
Epoch 00353: val_loss did not improve
3s - loss: 0.9429 - acc: 0.6904 - val_loss: 0.7726 - val_acc: 0.7445
Epoch 355/500
Epoch 00354: val_loss did not improve
2s - loss: 0.9511 - acc: 0.6881 - val_loss: 0.7867 - val_acc: 0.7404
Epoch 356/500
Epoch 00355: val_loss did not improve
2s - loss: 0.9563 - acc: 0.6860 - val_loss: 0.7767 - val_acc: 0.7427
Epoch 357/500
Epoch 00356: val_loss did not improve
2s - loss: 0.9421 - acc: 0.6903 - val_loss: 0.7723 - val_acc: 0.7433
Epoch 358/500
Epoch 00357: val_loss did not improve
2s - loss: 0.9374 - acc: 0.6916 - val_loss: 0.7728 - val_acc: 0.7453
Epoch 359/500
Epoch 00358: val_loss did not improve
2s - loss: 0.9427 - acc: 0.6890 - val_loss: 0.7769 - val_acc: 0.7449
Epoch 360/500
Epoch 00359: val_loss did not improve
2s - loss: 0.9380 - acc: 0.6925 - val_loss: 0.7666 - val_acc: 0.7451
Epoch 361/500
Epoch 00360: val_loss did not improve
3s - loss: 0.9370 - acc: 0.6909 - val_loss: 0.7782 - val_acc: 0.7422
Epoch 362/500
Epoch 00361: val_loss did not improve
2s - loss: 0.9341 - acc: 0.6933 - val_loss: 0.7825 - val_acc: 0.7431
Epoch 363/500
Epoch 00362: val_loss improved from 0.76480 to 0.75833, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 0.9297 - acc: 0.6953 - val_loss: 0.7583 - val_acc: 0.7502
Epoch 364/500
Epoch 00363: val_loss improved from 0.75833 to 0.75510, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 0.9305 - acc: 0.6954 - val_loss: 0.7551 - val_acc: 0.7510
Epoch 365/500
Epoch 00364: val_loss did not improve
2s - loss: 0.9350 - acc: 0.6912 - val_loss: 0.7603 - val_acc: 0.7500
Epoch 366/500
Epoch 00365: val_loss improved from 0.75510 to 0.75159, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 0.9272 - acc: 0.6950 - val_loss: 0.7516 - val_acc: 0.7533
Epoch 367/500
Epoch 00366: val_loss did not improve
3s - loss: 0.9287 - acc: 0.6936 - val_loss: 0.7612 - val_acc: 0.7487
Epoch 368/500
Epoch 00367: val_loss improved from 0.75159 to 0.74182, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 0.9272 - acc: 0.6959 - val_loss: 0.7418 - val_acc: 0.7567
Epoch 369/500
Epoch 00368: val_loss did not improve
2s - loss: 0.9272 - acc: 0.6959 - val_loss: 0.7514 - val_acc: 0.7534
Epoch 370/500
Epoch 00369: val_loss did not improve
2s - loss: 0.9190 - acc: 0.6977 - val_loss: 0.7423 - val_acc: 0.7543
Epoch 371/500
Epoch 00370: val_loss did not improve
2s - loss: 0.9225 - acc: 0.6958 - val_loss: 0.7484 - val_acc: 0.7526
Epoch 372/500
Epoch 00371: val_loss did not improve
2s - loss: 0.9207 - acc: 0.6969 - val_loss: 0.7536 - val_acc: 0.7523
Epoch 373/500
Epoch 00372: val_loss improved from 0.74182 to 0.74089, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
3s - loss: 0.9150 - acc: 0.7003 - val_loss: 0.7409 - val_acc: 0.7538
Epoch 374/500
Epoch 00373: val_loss did not improve
2s - loss: 0.9123 - acc: 0.7005 - val_loss: 0.7490 - val_acc: 0.7507
Epoch 375/500
Epoch 00374: val_loss did not improve
2s - loss: 0.9126 - acc: 0.6993 - val_loss: 0.7450 - val_acc: 0.7521
Epoch 376/500
Epoch 00375: val_loss improved from 0.74089 to 0.72804, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 0.9110 - acc: 0.7005 - val_loss: 0.7280 - val_acc: 0.7591
Epoch 377/500
Epoch 00376: val_loss did not improve
2s - loss: 0.9047 - acc: 0.7025 - val_loss: 0.7517 - val_acc: 0.7500
Epoch 378/500
Epoch 00377: val_loss did not improve
2s - loss: 0.9128 - acc: 0.7003 - val_loss: 0.7367 - val_acc: 0.7545
Epoch 379/500
Epoch 00378: val_loss did not improve
2s - loss: 0.9069 - acc: 0.7006 - val_loss: 0.7498 - val_acc: 0.7535
Epoch 380/500
Epoch 00379: val_loss improved from 0.72804 to 0.72705, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
3s - loss: 0.9070 - acc: 0.7014 - val_loss: 0.7271 - val_acc: 0.7581
Epoch 381/500
Epoch 00380: val_loss improved from 0.72705 to 0.72531, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 0.9058 - acc: 0.7013 - val_loss: 0.7253 - val_acc: 0.7614
Epoch 382/500
Epoch 00381: val_loss did not improve
2s - loss: 0.9049 - acc: 0.7013 - val_loss: 0.7415 - val_acc: 0.7515
Epoch 383/500
Epoch 00382: val_loss improved from 0.72531 to 0.71990, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 0.9057 - acc: 0.7010 - val_loss: 0.7199 - val_acc: 0.7602
Epoch 384/500
Epoch 00383: val_loss did not improve
2s - loss: 0.8916 - acc: 0.7061 - val_loss: 0.7338 - val_acc: 0.7564
Epoch 385/500
Epoch 00384: val_loss did not improve
2s - loss: 0.8963 - acc: 0.7038 - val_loss: 0.7426 - val_acc: 0.7526
Epoch 386/500
Epoch 00385: val_loss did not improve
3s - loss: 0.9026 - acc: 0.7038 - val_loss: 0.7259 - val_acc: 0.7576
Epoch 387/500
Epoch 00386: val_loss did not improve
2s - loss: 0.8969 - acc: 0.7033 - val_loss: 0.7344 - val_acc: 0.7549
Epoch 388/500
Epoch 00387: val_loss did not improve
2s - loss: 0.9046 - acc: 0.7024 - val_loss: 0.7274 - val_acc: 0.7585
Epoch 389/500
Epoch 00388: val_loss did not improve
2s - loss: 0.8932 - acc: 0.7050 - val_loss: 0.7442 - val_acc: 0.7522
Epoch 390/500
Epoch 00389: val_loss improved from 0.71990 to 0.70617, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 0.8996 - acc: 0.7035 - val_loss: 0.7062 - val_acc: 0.7686
Epoch 391/500
Epoch 00390: val_loss did not improve
2s - loss: 0.8844 - acc: 0.7086 - val_loss: 0.7242 - val_acc: 0.7572
Epoch 392/500
Epoch 00391: val_loss did not improve
2s - loss: 0.8996 - acc: 0.7053 - val_loss: 0.7176 - val_acc: 0.7649
Epoch 393/500
Epoch 00392: val_loss improved from 0.70617 to 0.70123, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
3s - loss: 0.8881 - acc: 0.7079 - val_loss: 0.7012 - val_acc: 0.7697
Epoch 394/500
Epoch 00393: val_loss did not improve
2s - loss: 0.8849 - acc: 0.7078 - val_loss: 0.7170 - val_acc: 0.7644
Epoch 395/500
Epoch 00394: val_loss did not improve
2s - loss: 0.8849 - acc: 0.7095 - val_loss: 0.7087 - val_acc: 0.7646
Epoch 396/500
Epoch 00395: val_loss did not improve
2s - loss: 0.8885 - acc: 0.7059 - val_loss: 0.7132 - val_acc: 0.7657
Epoch 397/500
Epoch 00396: val_loss did not improve
2s - loss: 0.8805 - acc: 0.7089 - val_loss: 0.7263 - val_acc: 0.7589
Epoch 398/500
Epoch 00397: val_loss did not improve
2s - loss: 0.8861 - acc: 0.7077 - val_loss: 0.7149 - val_acc: 0.7625
Epoch 399/500
Epoch 00398: val_loss did not improve
3s - loss: 0.8782 - acc: 0.7099 - val_loss: 0.7070 - val_acc: 0.7668
Epoch 400/500
Epoch 00399: val_loss did not improve
2s - loss: 0.8800 - acc: 0.7094 - val_loss: 0.7741 - val_acc: 0.7426
Epoch 401/500
Epoch 00400: val_loss did not improve
2s - loss: 0.8967 - acc: 0.7046 - val_loss: 0.7158 - val_acc: 0.7617
Epoch 402/500
Epoch 00401: val_loss did not improve
2s - loss: 0.8784 - acc: 0.7091 - val_loss: 0.7020 - val_acc: 0.7685
Epoch 403/500
Epoch 00402: val_loss improved from 0.70123 to 0.69040, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 0.8848 - acc: 0.7088 - val_loss: 0.6904 - val_acc: 0.7699
Epoch 404/500
Epoch 00403: val_loss did not improve
2s - loss: 0.8732 - acc: 0.7126 - val_loss: 0.7119 - val_acc: 0.7642
Epoch 405/500
Epoch 00404: val_loss did not improve
2s - loss: 0.8748 - acc: 0.7117 - val_loss: 0.7020 - val_acc: 0.7671
Epoch 406/500
Epoch 00405: val_loss did not improve
3s - loss: 0.8769 - acc: 0.7096 - val_loss: 0.7061 - val_acc: 0.7657
Epoch 407/500
Epoch 00406: val_loss did not improve
2s - loss: 0.8746 - acc: 0.7113 - val_loss: 0.6975 - val_acc: 0.7694
Epoch 408/500
Epoch 00407: val_loss did not improve
2s - loss: 0.8670 - acc: 0.7145 - val_loss: 0.7033 - val_acc: 0.7665
Epoch 409/500
Epoch 00408: val_loss did not improve
2s - loss: 0.8780 - acc: 0.7119 - val_loss: 0.7151 - val_acc: 0.7615
Epoch 410/500
Epoch 00409: val_loss improved from 0.69040 to 0.67822, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 0.8790 - acc: 0.7090 - val_loss: 0.6782 - val_acc: 0.7756
Epoch 411/500
Epoch 00410: val_loss did not improve
2s - loss: 0.8579 - acc: 0.7163 - val_loss: 0.6912 - val_acc: 0.7693
Epoch 412/500
Epoch 00411: val_loss did not improve
3s - loss: 0.8613 - acc: 0.7158 - val_loss: 0.6854 - val_acc: 0.7719
Epoch 413/500
Epoch 00412: val_loss improved from 0.67822 to 0.67776, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 0.8517 - acc: 0.7178 - val_loss: 0.6778 - val_acc: 0.7755
Epoch 414/500
Epoch 00413: val_loss did not improve
2s - loss: 0.8548 - acc: 0.7169 - val_loss: 0.6783 - val_acc: 0.7743
Epoch 415/500
Epoch 00414: val_loss did not improve
2s - loss: 0.8578 - acc: 0.7162 - val_loss: 0.6965 - val_acc: 0.7691
Epoch 416/500
Epoch 00415: val_loss did not improve
2s - loss: 0.8660 - acc: 0.7128 - val_loss: 0.6936 - val_acc: 0.7693
Epoch 417/500
Epoch 00416: val_loss improved from 0.67776 to 0.67056, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 0.8529 - acc: 0.7188 - val_loss: 0.6706 - val_acc: 0.7778
Epoch 418/500
Epoch 00417: val_loss did not improve
2s - loss: 0.8516 - acc: 0.7169 - val_loss: 0.6788 - val_acc: 0.7768
Epoch 419/500
Epoch 00418: val_loss improved from 0.67056 to 0.66466, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 0.8529 - acc: 0.7184 - val_loss: 0.6647 - val_acc: 0.7810
Epoch 420/500
Epoch 00419: val_loss did not improve
2s - loss: 0.8562 - acc: 0.7161 - val_loss: 0.6742 - val_acc: 0.7794
Epoch 421/500
Epoch 00420: val_loss did not improve
2s - loss: 0.8523 - acc: 0.7167 - val_loss: 0.6720 - val_acc: 0.7760
Epoch 422/500
Epoch 00421: val_loss did not improve
2s - loss: 0.8543 - acc: 0.7182 - val_loss: 0.6700 - val_acc: 0.7796
Epoch 423/500
Epoch 00422: val_loss improved from 0.66466 to 0.65886, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 0.8467 - acc: 0.7204 - val_loss: 0.6589 - val_acc: 0.7826
Epoch 424/500
Epoch 00423: val_loss improved from 0.65886 to 0.65560, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 0.8450 - acc: 0.7204 - val_loss: 0.6556 - val_acc: 0.7835
Epoch 425/500
Epoch 00424: val_loss did not improve
2s - loss: 0.8341 - acc: 0.7232 - val_loss: 0.6756 - val_acc: 0.7771
Epoch 426/500
Epoch 00425: val_loss did not improve
2s - loss: 0.8568 - acc: 0.7180 - val_loss: 0.6669 - val_acc: 0.7786
Epoch 427/500
Epoch 00426: val_loss did not improve
2s - loss: 0.8496 - acc: 0.7192 - val_loss: 0.6609 - val_acc: 0.7820
Epoch 428/500
Epoch 00427: val_loss did not improve
2s - loss: 0.8403 - acc: 0.7210 - val_loss: 0.6572 - val_acc: 0.7829
Epoch 429/500
Epoch 00428: val_loss did not improve
2s - loss: 0.8458 - acc: 0.7217 - val_loss: 0.6562 - val_acc: 0.7829
Epoch 430/500
Epoch 00429: val_loss did not improve
2s - loss: 0.8386 - acc: 0.7222 - val_loss: 0.6583 - val_acc: 0.7835
Epoch 431/500
Epoch 00430: val_loss improved from 0.65560 to 0.64907, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 0.8335 - acc: 0.7235 - val_loss: 0.6491 - val_acc: 0.7845
Epoch 432/500
Epoch 00431: val_loss did not improve
2s - loss: 0.8406 - acc: 0.7225 - val_loss: 0.6626 - val_acc: 0.7780
Epoch 433/500
Epoch 00432: val_loss improved from 0.64907 to 0.64791, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 0.8418 - acc: 0.7227 - val_loss: 0.6479 - val_acc: 0.7831
Epoch 434/500
Epoch 00433: val_loss did not improve
2s - loss: 0.8472 - acc: 0.7210 - val_loss: 0.6541 - val_acc: 0.7823
Epoch 435/500
Epoch 00434: val_loss did not improve
2s - loss: 0.8389 - acc: 0.7212 - val_loss: 0.6487 - val_acc: 0.7838
Epoch 436/500
Epoch 00435: val_loss did not improve
2s - loss: 0.8383 - acc: 0.7230 - val_loss: 0.6631 - val_acc: 0.7792
Epoch 437/500
Epoch 00436: val_loss did not improve
2s - loss: 0.8404 - acc: 0.7236 - val_loss: 0.6554 - val_acc: 0.7844
Epoch 438/500
Epoch 00437: val_loss did not improve
2s - loss: 0.8473 - acc: 0.7190 - val_loss: 0.6591 - val_acc: 0.7801
Epoch 439/500
Epoch 00438: val_loss improved from 0.64791 to 0.64361, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 0.8339 - acc: 0.7251 - val_loss: 0.6436 - val_acc: 0.7848
Epoch 440/500
Epoch 00439: val_loss improved from 0.64361 to 0.64095, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 0.8304 - acc: 0.7271 - val_loss: 0.6410 - val_acc: 0.7872
Epoch 441/500
Epoch 00440: val_loss did not improve
2s - loss: 0.8341 - acc: 0.7248 - val_loss: 0.6466 - val_acc: 0.7862
Epoch 442/500
Epoch 00441: val_loss did not improve
2s - loss: 0.8311 - acc: 0.7247 - val_loss: 0.6431 - val_acc: 0.7888
Epoch 443/500
Epoch 00442: val_loss improved from 0.64095 to 0.63887, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 0.8272 - acc: 0.7263 - val_loss: 0.6389 - val_acc: 0.7873
Epoch 444/500
Epoch 00443: val_loss improved from 0.63887 to 0.63391, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 0.8249 - acc: 0.7276 - val_loss: 0.6339 - val_acc: 0.7897
Epoch 445/500
Epoch 00444: val_loss did not improve
2s - loss: 0.8298 - acc: 0.7264 - val_loss: 0.6432 - val_acc: 0.7844
Epoch 446/500
Epoch 00445: val_loss did not improve
2s - loss: 0.8284 - acc: 0.7266 - val_loss: 0.6414 - val_acc: 0.7859
Epoch 447/500
Epoch 00446: val_loss did not improve
2s - loss: 0.8272 - acc: 0.7265 - val_loss: 0.6446 - val_acc: 0.7858
Epoch 448/500
Epoch 00447: val_loss did not improve
2s - loss: 0.8264 - acc: 0.7268 - val_loss: 0.6539 - val_acc: 0.7806
Epoch 449/500
Epoch 00448: val_loss did not improve
2s - loss: 0.8329 - acc: 0.7245 - val_loss: 0.6895 - val_acc: 0.7670
Epoch 450/500
Epoch 00449: val_loss did not improve
2s - loss: 0.8356 - acc: 0.7244 - val_loss: 0.6411 - val_acc: 0.7842
Epoch 451/500
Epoch 00450: val_loss did not improve
2s - loss: 0.8262 - acc: 0.7283 - val_loss: 0.6365 - val_acc: 0.7875
Epoch 452/500
Epoch 00451: val_loss did not improve
2s - loss: 0.8275 - acc: 0.7289 - val_loss: 0.6464 - val_acc: 0.7839
Epoch 453/500
Epoch 00452: val_loss did not improve
2s - loss: 0.8207 - acc: 0.7288 - val_loss: 0.6359 - val_acc: 0.7887
Epoch 454/500
Epoch 00453: val_loss improved from 0.63391 to 0.62176, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 0.8196 - acc: 0.7288 - val_loss: 0.6218 - val_acc: 0.7924
Epoch 455/500
Epoch 00454: val_loss did not improve
2s - loss: 0.8182 - acc: 0.7285 - val_loss: 0.6445 - val_acc: 0.7842
Epoch 456/500
Epoch 00455: val_loss did not improve
2s - loss: 0.8192 - acc: 0.7278 - val_loss: 0.6244 - val_acc: 0.7923
Epoch 457/500
Epoch 00456: val_loss did not improve
2s - loss: 0.8171 - acc: 0.7294 - val_loss: 0.6259 - val_acc: 0.7924
Epoch 458/500
Epoch 00457: val_loss improved from 0.62176 to 0.61955, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 0.8176 - acc: 0.7287 - val_loss: 0.6196 - val_acc: 0.7947
Epoch 459/500
Epoch 00458: val_loss improved from 0.61955 to 0.61114, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 0.8092 - acc: 0.7311 - val_loss: 0.6111 - val_acc: 0.7974
Epoch 460/500
Epoch 00459: val_loss did not improve
2s - loss: 0.8141 - acc: 0.7307 - val_loss: 0.6274 - val_acc: 0.7906
Epoch 461/500
Epoch 00460: val_loss did not improve
2s - loss: 0.8162 - acc: 0.7303 - val_loss: 0.6307 - val_acc: 0.7882
Epoch 462/500
Epoch 00461: val_loss did not improve
2s - loss: 0.8156 - acc: 0.7304 - val_loss: 0.6372 - val_acc: 0.7856
Epoch 463/500
Epoch 00462: val_loss did not improve
2s - loss: 0.8148 - acc: 0.7299 - val_loss: 0.6192 - val_acc: 0.7951
Epoch 464/500
Epoch 00463: val_loss did not improve
2s - loss: 0.8152 - acc: 0.7292 - val_loss: 0.6203 - val_acc: 0.7952
Epoch 465/500
Epoch 00464: val_loss did not improve
2s - loss: 0.8082 - acc: 0.7325 - val_loss: 0.6287 - val_acc: 0.7907
Epoch 466/500
Epoch 00465: val_loss did not improve
2s - loss: 0.8099 - acc: 0.7330 - val_loss: 0.6341 - val_acc: 0.7885
Epoch 467/500
Epoch 00466: val_loss did not improve
2s - loss: 0.8058 - acc: 0.7338 - val_loss: 0.6208 - val_acc: 0.7942
Epoch 468/500
Epoch 00467: val_loss improved from 0.61114 to 0.60692, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 0.8034 - acc: 0.7357 - val_loss: 0.6069 - val_acc: 0.7997
Epoch 469/500
Epoch 00468: val_loss did not improve
2s - loss: 0.7970 - acc: 0.7373 - val_loss: 0.6088 - val_acc: 0.7991
Epoch 470/500
Epoch 00469: val_loss did not improve
2s - loss: 0.8010 - acc: 0.7341 - val_loss: 0.6125 - val_acc: 0.7964
Epoch 471/500
Epoch 00470: val_loss did not improve
2s - loss: 0.8007 - acc: 0.7355 - val_loss: 0.6078 - val_acc: 0.7995
Epoch 472/500
Epoch 00471: val_loss did not improve
2s - loss: 0.8050 - acc: 0.7338 - val_loss: 0.6126 - val_acc: 0.7952
Epoch 473/500
Epoch 00472: val_loss improved from 0.60692 to 0.59830, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 0.8074 - acc: 0.7332 - val_loss: 0.5983 - val_acc: 0.8014
Epoch 474/500
Epoch 00473: val_loss did not improve
2s - loss: 0.7972 - acc: 0.7370 - val_loss: 0.6059 - val_acc: 0.8004
Epoch 475/500
Epoch 00474: val_loss did not improve
2s - loss: 0.8031 - acc: 0.7361 - val_loss: 0.6213 - val_acc: 0.7911
Epoch 476/500
Epoch 00475: val_loss did not improve
2s - loss: 0.8039 - acc: 0.7344 - val_loss: 0.6365 - val_acc: 0.7850
Epoch 477/500
Epoch 00476: val_loss did not improve
2s - loss: 0.8087 - acc: 0.7316 - val_loss: 0.5995 - val_acc: 0.8020
Epoch 478/500
Epoch 00477: val_loss did not improve
2s - loss: 0.7944 - acc: 0.7357 - val_loss: 0.6129 - val_acc: 0.7958
Epoch 479/500
Epoch 00478: val_loss did not improve
2s - loss: 0.8012 - acc: 0.7354 - val_loss: 0.6126 - val_acc: 0.7957
Epoch 480/500
Epoch 00479: val_loss did not improve
2s - loss: 0.8072 - acc: 0.7330 - val_loss: 0.6169 - val_acc: 0.7937
Epoch 481/500
Epoch 00480: val_loss did not improve
2s - loss: 0.7877 - acc: 0.7410 - val_loss: 0.5994 - val_acc: 0.8005
Epoch 482/500
Epoch 00481: val_loss did not improve
2s - loss: 0.7905 - acc: 0.7389 - val_loss: 0.6019 - val_acc: 0.8008
Epoch 483/500
Epoch 00482: val_loss improved from 0.59830 to 0.59473, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 0.7945 - acc: 0.7370 - val_loss: 0.5947 - val_acc: 0.8008
Epoch 484/500
Epoch 00483: val_loss improved from 0.59473 to 0.59467, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 0.7897 - acc: 0.7388 - val_loss: 0.5947 - val_acc: 0.8026
Epoch 485/500
Epoch 00484: val_loss improved from 0.59467 to 0.58778, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 0.7942 - acc: 0.7372 - val_loss: 0.5878 - val_acc: 0.8039
Epoch 486/500
Epoch 00485: val_loss improved from 0.58778 to 0.58748, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 0.7904 - acc: 0.7389 - val_loss: 0.5875 - val_acc: 0.8079
Epoch 487/500
Epoch 00486: val_loss did not improve
2s - loss: 0.7902 alternative_dgagan.py:359: RuntimeWarning: divide by zero encountered in log
  preds = np.log(preds) / temperature
- acc: 0.7372 - val_loss: 0.5994 - val_acc: 0.8025
Epoch 488/500
Epoch 00487: val_loss did not improve
2s - loss: 0.7882 - acc: 0.7393 - val_loss: 0.6187 - val_acc: 0.7900
Epoch 489/500
Epoch 00488: val_loss did not improve
2s - loss: 0.7952 - acc: 0.7373 - val_loss: 0.5877 - val_acc: 0.8043
Epoch 490/500
Epoch 00489: val_loss did not improve
2s - loss: 0.7777 - acc: 0.7425 - val_loss: 0.5897 - val_acc: 0.8028
Epoch 491/500
Epoch 00490: val_loss did not improve
2s - loss: 0.7852 - acc: 0.7400 - val_loss: 0.5963 - val_acc: 0.8012
Epoch 492/500
Epoch 00491: val_loss did not improve
2s - loss: 0.7892 - acc: 0.7374 - val_loss: 0.5915 - val_acc: 0.8044
Epoch 493/500
Epoch 00492: val_loss did not improve
2s - loss: 0.7814 - acc: 0.7428 - val_loss: 0.5943 - val_acc: 0.8013
Epoch 494/500
Epoch 00493: val_loss improved from 0.58748 to 0.58648, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 0.7871 - acc: 0.7392 - val_loss: 0.5865 - val_acc: 0.8061
Epoch 495/500
Epoch 00494: val_loss did not improve
2s - loss: 0.7871 - acc: 0.7414 - val_loss: 0.6047 - val_acc: 0.7969
Epoch 496/500
Epoch 00495: val_loss did not improve
2s - loss: 0.7939 - acc: 0.7361 - val_loss: 0.6130 - val_acc: 0.7972
Epoch 497/500
Epoch 00496: val_loss did not improve
2s - loss: 0.7800 - acc: 0.7426 - val_loss: 0.5910 - val_acc: 0.8014
Epoch 498/500
Epoch 00497: val_loss did not improve
2s - loss: 0.7862 - acc: 0.7394 - val_loss: 0.5924 - val_acc: 0.8013
Epoch 499/500
Epoch 00498: val_loss did not improve
2s - loss: 0.7783 - acc: 0.7429 - val_loss: 0.5987 - val_acc: 0.8005
Epoch 500/500
Epoch 00499: val_loss improved from 0.58648 to 0.58595, saving model to autoencoder_experiments/20171206-124914/weights/autoencoder.h5
2s - loss: 0.7948 - acc: 0.7358 - val_loss: 0.5860 - val_acc: 0.8066
X_test
[[[ 0.  0.  0. ...,  0.  0.  0.]
  [ 0.  0.  0. ...,  0.  0.  0.]
  [ 0.  1.  0. ...,  0.  0.  0.]
  ..., 
  [ 0.  0.  0. ...,  0.  0.  0.]
  [ 0.  0.  0. ...,  0.  0.  0.]
  [ 0.  0.  0. ...,  0.  0.  0.]]

 [[ 1.  0.  0. ...,  0.  0.  0.]
  [ 0.  0.  0. ...,  0.  0.  0.]
  [ 0.  0.  0. ...,  0.  0.  0.]
  ..., 
  [ 0.  0.  0. ...,  0.  0.  0.]
  [ 0.  0.  0. ...,  0.  0.  0.]
  [ 0.  0.  0. ...,  0.  0.  0.]]

 [[ 1.  0.  0. ...,  0.  0.  0.]
  [ 0.  0.  0. ...,  0.  0.  0.]
  [ 0.  0.  0. ...,  0.  0.  0.]
  ..., 
  [ 0.  0.  0. ...,  0.  0.  0.]
  [ 0.  0.  0. ...,  0.  0.  0.]
  [ 0.  0.  0. ...,  0.  0.  0.]]

 ..., 
 [[ 1.  0.  0. ...,  0.  0.  0.]
  [ 1.  0.  0. ...,  0.  0.  0.]
  [ 1.  0.  0. ...,  0.  0.  0.]
  ..., 
  [ 0.  0.  0. ...,  0.  0.  0.]
  [ 0.  0.  0. ...,  0.  0.  0.]
  [ 0.  0.  0. ...,  0.  0.  0.]]

 [[ 0.  0.  0. ...,  0.  0.  0.]
  [ 0.  1.  0. ...,  0.  0.  0.]
  [ 0.  0.  0. ...,  0.  0.  0.]
  ..., 
  [ 0.  0.  0. ...,  0.  0.  0.]
  [ 0.  0.  0. ...,  0.  0.  0.]
  [ 0.  0.  0. ...,  0.  0.  0.]]

 [[ 1.  0.  0. ...,  0.  0.  0.]
  [ 1.  0.  0. ...,  0.  0.  0.]
  [ 1.  0.  0. ...,  0.  0.  0.]
  ..., 
  [ 0.  0.  0. ...,  0.  0.  0.]
  [ 0.  0.  0. ...,  0.  0.  0.]
  [ 0.  0.  0. ...,  0.  0.  0.]]]
results
reekinabaestore
neetiia-forums
wtinttnshtters
thedroner
hincinalottifol
ineeeeinacional
kaamaiosola
dashap2
vianet
lessines
htntolddrncerte
apnastock
bliccirpooumano
fts-sense
ceeiiterl
teehounc-armer
vineyardclup
mofoescorts
zb-gong
sky-bloc
biikplus
certed
nobanca
bllenetfiles
utopolls
monetozados
chaeerrscidcla
aaeetnnaaasters
venturespuare
legnobagno
hivelives
iciinnecilpping
cinteaacsaaert
cflaaartooiodia
huiform
parlaaent
happpschools
eternit
baaanntountrdes
calnndrrio-366
ontaaesettool
seosks
fiatcamper
raziosolie
wcccourner
allansfliwers
bemregroup
wheel-siza
haayangssennhou
psyeess44
