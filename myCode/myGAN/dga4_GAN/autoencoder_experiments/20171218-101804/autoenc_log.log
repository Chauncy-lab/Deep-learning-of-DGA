Using TensorFlow backend.
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
Discriminator_Input (InputLayer) (None, 15, 38)        0                                            
____________________________________________________________________________________________________
discr_conv0 (Conv1D)             (None, 15, 20)        1540        Discriminator_Input[0][0]        
____________________________________________________________________________________________________
discr_conv1 (Conv1D)             (None, 15, 10)        1150        Discriminator_Input[0][0]        
____________________________________________________________________________________________________
batch_normalization_1 (BatchNorm (None, 15, 20)        80          discr_conv0[0][0]                
____________________________________________________________________________________________________
batch_normalization_2 (BatchNorm (None, 15, 10)        40          discr_conv1[0][0]                
____________________________________________________________________________________________________
leaky_re_lu_1 (LeakyReLU)        (None, 15, 20)        0           batch_normalization_1[0][0]      
____________________________________________________________________________________________________
leaky_re_lu_2 (LeakyReLU)        (None, 15, 10)        0           batch_normalization_2[0][0]      
____________________________________________________________________________________________________
discr_dropout0 (Dropout)         (None, 15, 20)        0           leaky_re_lu_1[0][0]              
____________________________________________________________________________________________________
discr_dropout1 (Dropout)         (None, 15, 10)        0           leaky_re_lu_2[0][0]              
____________________________________________________________________________________________________
average_pooling1d_1 (AveragePool (None, 7, 20)         0           discr_dropout0[0][0]             
____________________________________________________________________________________________________
average_pooling1d_2 (AveragePool (None, 7, 10)         0           discr_dropout1[0][0]             
____________________________________________________________________________________________________
concatenate_1 (Concatenate)      (None, 7, 30)         0           average_pooling1d_1[0][0]        
                                                                   average_pooling1d_2[0][0]        
____________________________________________________________________________________________________
lstm_1 (LSTM)                    (None, 20)            4080        concatenate_1[0][0]              
====================================================================================================
Total params: 6,890
Trainable params: 6,830
Non-trainable params: 60
____________________________________________________________________________________________________
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
Generator_Input (InputLayer)     (None, 20)            0                                            
____________________________________________________________________________________________________
gen_repeate_vec (RepeatVector)   (None, 15, 20)        0           Generator_Input[0][0]            
____________________________________________________________________________________________________
gen_LSTM (LSTM)                  (None, 15, 38)        8968        gen_repeate_vec[0][0]            
________________________________________________________________________________________2017-12-18 09:24:52.376902: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-12-18 09:24:52.376970: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-12-18 09:24:52.376984: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
____________
dropout_1 (Dropout)              (None, 15, 38)        0           gen_LSTM[0][0]                   
____________________________________________________________________________________________________
gen_conv0 (Conv1D)               (None, 15, 20)        1540        dropout_1[0][0]                  
____________________________________________________________________________________________________
gen_conv1 (Conv1D)               (None, 15, 10)        1150        dropout_1[0][0]                  
____________________________________________________________________________________________________
leaky_re_lu_3 (LeakyReLU)        (None, 15, 20)        0           gen_conv0[0][0]                  
____________________________________________________________________________________________________
leaky_re_lu_4 (LeakyReLU)        (None, 15, 10)        0           gen_conv1[0][0]                  
____________________________________________________________________________________________________
gen_dropout0 (Dropout)           (None, 15, 20)        0           leaky_re_lu_3[0][0]              
____________________________________________________________________________________________________
gen_dropout1 (Dropout)           (None, 15, 10)        0           leaky_re_lu_4[0][0]              
____________________________________________________________________________________________________
concatenate_2 (Concatenate)      (None, 15, 30)        0           gen_dropout0[0][0]               
                                                                   gen_dropout1[0][0]               
____________________________________________________________________________________________________
decoder_end (TimeDistributed)    (None, 15, 38)        1178        concatenate_2[0][0]              
====================================================================================================
Total params: 12,836
Trainable params: 12,836
Non-trainable params: 0
____________________________________________________________________________________________________
Train on 44889 samples, validate on 22111 samples
Epoch 1/500
Epoch 00000: val_loss improved from inf to 2.14119, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
17s - loss: 2.4503 - acc: 0.3365 - val_loss: 2.1412 - val_acc: 0.3724
Epoch 2/500
Epoch 00001: val_loss improved from 2.14119 to 2.10012, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
17s - loss: 2.1636 - acc: 0.3694 - val_loss: 2.1001 - val_acc: 0.3773
Epoch 3/500
Epoch 00002: val_loss improved from 2.10012 to 2.05675, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 2.1159 - acc: 0.3836 - val_loss: 2.0567 - val_acc: 0.3978
Epoch 4/500
Epoch 00003: val_loss improved from 2.05675 to 2.01598, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
17s - loss: 2.0764 - acc: 0.3963 - val_loss: 2.0160 - val_acc: 0.4066
Epoch 5/500
Epoch 00004: val_loss improved from 2.01598 to 1.99212, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 2.0479 - acc: 0.4019 - val_loss: 1.9921 - val_acc: 0.4110
Epoch 6/500
Epoch 00005: val_loss improved from 1.99212 to 1.95996, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
17s - loss: 2.0234 - acc: 0.4081 - val_loss: 1.9600 - val_acc: 0.4216
Epoch 7/500
Epoch 00006: val_loss improved from 1.95996 to 1.93993, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
17s - loss: 2.0008 - acc: 0.4133 - val_loss: 1.9399 - val_acc: 0.4225
Epoch 8/500
Epoch 00007: val_loss improved from 1.93993 to 1.91866, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.9868 - acc: 0.4146 - val_loss: 1.9187 - val_acc: 0.4272
Epoch 9/500
Epoch 00008: val_loss improved from 1.91866 to 1.89883, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.9684 - acc: 0.4174 - val_loss: 1.8988 - val_acc: 0.4282
Epoch 10/500
Epoch 00009: val_loss improved from 1.89883 to 1.88111, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
17s - loss: 1.9532 - acc: 0.4197 - val_loss: 1.8811 - val_acc: 0.4314
Epoch 11/500
Epoch 00010: val_loss improved from 1.88111 to 1.86569, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.9382 - acc: 0.4211 - val_loss: 1.8657 - val_acc: 0.4331
Epoch 12/500
Epoch 00011: val_loss improved from 1.86569 to 1.83810, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
17s - loss: 1.9226 - acc: 0.4228 - val_loss: 1.8381 - val_acc: 0.4361
Epoch 13/500
Epoch 00012: val_loss improved from 1.83810 to 1.81594, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
17s - loss: 1.9063 - acc: 0.4239 - val_loss: 1.8159 - val_acc: 0.4382
Epoch 14/500
Epoch 00013: val_loss improved from 1.81594 to 1.79981, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
17s - loss: 1.8930 - acc: 0.4252 - val_loss: 1.7998 - val_acc: 0.4417
Epoch 15/500
Epoch 00014: val_loss improved from 1.79981 to 1.77919, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
17s - loss: 1.8765 - acc: 0.4271 - val_loss: 1.7792 - val_acc: 0.4441
Epoch 16/500
Epoch 00015: val_loss improved from 1.77919 to 1.77133, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.8613 - acc: 0.4299 - val_loss: 1.7713 - val_acc: 0.4435
Epoch 17/500
Epoch 00016: val_loss improved from 1.77133 to 1.73362, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
17s - loss: 1.8436 - acc: 0.4320 - val_loss: 1.7336 - val_acc: 0.4535
Epoch 18/500
Epoch 00017: val_loss improved from 1.73362 to 1.72048, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.8288 - acc: 0.4341 - val_loss: 1.7205 - val_acc: 0.4554
Epoch 19/500
Epoch 00018: val_loss improved from 1.72048 to 1.69718, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
17s - loss: 1.8146 - acc: 0.4371 - val_loss: 1.6972 - val_acc: 0.4610
Epoch 20/500
Epoch 00019: val_loss improved from 1.69718 to 1.68682, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.8012 - acc: 0.4397 - val_loss: 1.6868 - val_acc: 0.4622
Epoch 21/500
Epoch 00020: val_loss improved from 1.68682 to 1.66846, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.7882 - acc: 0.4423 - val_loss: 1.6685 - val_acc: 0.4667
Epoch 22/500
Epoch 00021: val_loss improved from 1.66846 to 1.65584, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
17s - loss: 1.7766 - acc: 0.4447 - val_loss: 1.6558 - val_acc: 0.4695
Epoch 23/500
Epoch 00022: val_loss improved from 1.65584 to 1.63367, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
17s - loss: 1.7645 - acc: 0.4478 - val_loss: 1.6337 - val_acc: 0.4771
Epoch 24/500
Epoch 00023: val_loss improved from 1.63367 to 1.61678, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.7532 - acc: 0.4502 - val_loss: 1.6168 - val_acc: 0.4819
Epoch 25/500
Epoch 00024: val_loss improved from 1.61678 to 1.61133, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.7436 - acc: 0.4516 - val_loss: 1.6113 - val_acc: 0.4814
Epoch 26/500
Epoch 00025: val_loss improved from 1.61133 to 1.60978, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
17s - loss: 1.7343 - acc: 0.4541 - val_loss: 1.6098 - val_acc: 0.4824
Epoch 27/500
Epoch 00026: val_loss improved from 1.60978 to 1.57803, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.7238 - acc: 0.4574 - val_loss: 1.5780 - val_acc: 0.4911
Epoch 28/500
Epoch 00027: val_loss improved from 1.57803 to 1.57244, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.7148 - acc: 0.4593 - val_loss: 1.5724 - val_acc: 0.4919
Epoch 29/500
Epoch 00028: val_loss improved from 1.57244 to 1.56524, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.7060 - acc: 0.4616 - val_loss: 1.5652 - val_acc: 0.4962
Epoch 30/500
Epoch 00029: val_loss improved from 1.56524 to 1.55904, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.6989 - acc: 0.4638 - val_loss: 1.5590 - val_acc: 0.4947
Epoch 31/500
Epoch 00030: val_loss improved from 1.55904 to 1.53232, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.6898 - acc: 0.4659 - val_loss: 1.5323 - val_acc: 0.5040
Epoch 32/500
Epoch 00031: val_loss did not improve
16s - loss: 1.6828 - acc: 0.4684 - val_loss: 1.5329 - val_acc: 0.5060
Epoch 33/500
Epoch 00032: val_loss improved from 1.53232 to 1.51373, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.6750 - acc: 0.4706 - val_loss: 1.5137 - val_acc: 0.5124
Epoch 34/500
Epoch 00033: val_loss improved from 1.51373 to 1.50777, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.6658 - acc: 0.4732 - val_loss: 1.5078 - val_acc: 0.5141
Epoch 35/500
Epoch 00034: val_loss improved from 1.50777 to 1.49306, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
17s - loss: 1.6576 - acc: 0.4757 - val_loss: 1.4931 - val_acc: 0.5162
Epoch 36/500
Epoch 00035: val_loss improved from 1.49306 to 1.49129, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.6501 - acc: 0.4778 - val_loss: 1.4913 - val_acc: 0.5168
Epoch 37/500
Epoch 00036: val_loss improved from 1.49129 to 1.47824, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
17s - loss: 1.6430 - acc: 0.4797 - val_loss: 1.4782 - val_acc: 0.5197
Epoch 38/500
Epoch 00037: val_loss improved from 1.47824 to 1.47250, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.6379 - acc: 0.4811 - val_loss: 1.4725 - val_acc: 0.5186
Epoch 39/500
Epoch 00038: val_loss improved from 1.47250 to 1.46516, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
17s - loss: 1.6308 - acc: 0.4824 - val_loss: 1.4652 - val_acc: 0.5208
Epoch 40/500
Epoch 00039: val_loss improved from 1.46516 to 1.44913, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.6235 - acc: 0.4843 - val_loss: 1.4491 - val_acc: 0.5258
Epoch 41/500
Epoch 00040: val_loss improved from 1.44913 to 1.44068, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
17s - loss: 1.6180 - acc: 0.4848 - val_loss: 1.4407 - val_acc: 0.5279
Epoch 42/500
Epoch 00041: val_loss improved from 1.44068 to 1.44016, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.6104 - acc: 0.4863 - val_loss: 1.4402 - val_acc: 0.5275
Epoch 43/500
Epoch 00042: val_loss improved from 1.44016 to 1.42282, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.6035 - acc: 0.4871 - val_loss: 1.4228 - val_acc: 0.5304
Epoch 44/500
Epoch 00043: val_loss improved from 1.42282 to 1.41306, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.5952 - acc: 0.4893 - val_loss: 1.4131 - val_acc: 0.5316
Epoch 45/500
Epoch 00044: val_loss improved from 1.41306 to 1.41295, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
17s - loss: 1.5886 - acc: 0.4903 - val_loss: 1.4129 - val_acc: 0.5302
Epoch 46/500
Epoch 00045: val_loss improved from 1.41295 to 1.40669, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
17s - loss: 1.5845 - acc: 0.4917 - val_loss: 1.4067 - val_acc: 0.5322
Epoch 47/500
Epoch 00046: val_loss improved from 1.40669 to 1.39607, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.5772 - acc: 0.4928 - val_loss: 1.3961 - val_acc: 0.5337
Epoch 48/500
Epoch 00047: val_loss improved from 1.39607 to 1.38668, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.5703 - acc: 0.4945 - val_loss: 1.3867 - val_acc: 0.5370
Epoch 49/500
Epoch 00048: val_loss improved from 1.38668 to 1.38162, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.5652 - acc: 0.4957 - val_loss: 1.3816 - val_acc: 0.5357
Epoch 50/500
Epoch 00049: val_loss improved from 1.38162 to 1.37066, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.5589 - acc: 0.4973 - val_loss: 1.3707 - val_acc: 0.5401
Epoch 51/500
Epoch 00050: val_loss did not improve
16s - loss: 1.5564 - acc: 0.4980 - val_loss: 1.3753 - val_acc: 0.5379
Epoch 52/500
Epoch 00051: val_loss improved from 1.37066 to 1.36638, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.5511 - acc: 0.4990 - val_loss: 1.3664 - val_acc: 0.5404
Epoch 53/500
Epoch 00052: val_loss improved from 1.36638 to 1.36072, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
17s - loss: 1.5469 - acc: 0.4997 - val_loss: 1.3607 - val_acc: 0.5436
Epoch 54/500
Epoch 00053: val_loss did not improve
17s - loss: 1.5432 - acc: 0.5013 - val_loss: 1.3608 - val_acc: 0.5462
Epoch 55/500
Epoch 00054: val_loss improved from 1.36072 to 1.35043, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.5398 - acc: 0.5016 - val_loss: 1.3504 - val_acc: 0.5472
Epoch 56/500
Epoch 00055: val_loss improved from 1.35043 to 1.34089, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.5348 - acc: 0.5024 - val_loss: 1.3409 - val_acc: 0.5478
Epoch 57/500
Epoch 00056: val_loss did not improve
16s - loss: 1.5309 - acc: 0.5034 - val_loss: 1.3460 - val_acc: 0.5481
Epoch 58/500
Epoch 00057: val_loss did not improve
16s - loss: 1.5295 - acc: 0.5041 - val_loss: 1.3422 - val_acc: 0.5466
Epoch 59/500
Epoch 00058: val_loss did not improve
16s - loss: 1.5256 - acc: 0.5050 - val_loss: 1.3446 - val_acc: 0.5479
Epoch 60/500
Epoch 00059: val_loss improved from 1.34089 to 1.33130, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
17s - loss: 1.5223 - acc: 0.5053 - val_loss: 1.3313 - val_acc: 0.5505
Epoch 61/500
Epoch 00060: val_loss did not improve
16s - loss: 1.5187 - acc: 0.5066 - val_loss: 1.3402 - val_acc: 0.5449
Epoch 62/500
Epoch 00061: val_loss improved from 1.33130 to 1.32158, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
17s - loss: 1.5173 - acc: 0.5068 - val_loss: 1.3216 - val_acc: 0.5512
Epoch 63/500
Epoch 00062: val_loss did not improve
16s - loss: 1.5144 - acc: 0.5067 - val_loss: 1.3219 - val_acc: 0.5514
Epoch 64/500
Epoch 00063: val_loss did not improve
16s - loss: 1.5129 - acc: 0.5068 - val_loss: 1.3237 - val_acc: 0.5497
Epoch 65/500
Epoch 00064: val_loss did not improve
16s - loss: 1.5110 - acc: 0.5081 - val_loss: 1.3242 - val_acc: 0.5512
Epoch 66/500
Epoch 00065: val_loss did not improve
16s - loss: 1.5079 - acc: 0.5087 - val_loss: 1.3226 - val_acc: 0.5522
Epoch 67/500
Epoch 00066: val_loss improved from 1.32158 to 1.31215, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.5055 - acc: 0.5094 - val_loss: 1.3122 - val_acc: 0.5543
Epoch 68/500
Epoch 00067: val_loss did not improve
16s - loss: 1.5050 - acc: 0.5092 - val_loss: 1.3247 - val_acc: 0.5502
Epoch 69/500
Epoch 00068: val_loss did not improve
16s - loss: 1.5022 - acc: 0.5094 - val_loss: 1.3168 - val_acc: 0.5531
Epoch 70/500
Epoch 00069: val_loss did not improve
16s - loss: 1.4985 - acc: 0.5105 - val_loss: 1.3206 - val_acc: 0.5522
Epoch 71/500
Epoch 00070: val_loss improved from 1.31215 to 1.30475, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
17s - loss: 1.4967 - acc: 0.5116 - val_loss: 1.3047 - val_acc: 0.5568
Epoch 72/500
Epoch 00071: val_loss did not improve
17s - loss: 1.4963 - acc: 0.5113 - val_loss: 1.3106 - val_acc: 0.5542
Epoch 73/500
Epoch 00072: val_loss did not improve
16s - loss: 1.4938 - acc: 0.5116 - val_loss: 1.3127 - val_acc: 0.5523
Epoch 74/500
Epoch 00073: val_loss did not improve
17s - loss: 1.4926 - acc: 0.5119 - val_loss: 1.3090 - val_acc: 0.5530
Epoch 75/500
Epoch 00074: val_loss improved from 1.30475 to 1.30219, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.4894 - acc: 0.5123 - val_loss: 1.3022 - val_acc: 0.5559
Epoch 76/500
Epoch 00075: val_loss improved from 1.30219 to 1.30075, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.4889 - acc: 0.5131 - val_loss: 1.3007 - val_acc: 0.5558
Epoch 77/500
Epoch 00076: val_loss improved from 1.30075 to 1.29838, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.4889 - acc: 0.5124 - val_loss: 1.2984 - val_acc: 0.5585
Epoch 78/500
Epoch 00077: val_loss improved from 1.29838 to 1.29613, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.4869 - acc: 0.5134 - val_loss: 1.2961 - val_acc: 0.5596
Epoch 79/500
Epoch 00078: val_loss improved from 1.29613 to 1.29338, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.4835 - acc: 0.5139 - val_loss: 1.2934 - val_acc: 0.5573
Epoch 80/500
Epoch 00079: val_loss did not improve
16s - loss: 1.4838 - acc: 0.5139 - val_loss: 1.2939 - val_acc: 0.5558
Epoch 81/500
Epoch 00080: val_loss did not improve
16s - loss: 1.4803 - acc: 0.5144 - val_loss: 1.2965 - val_acc: 0.5565
Epoch 82/500
Epoch 00081: val_loss improved from 1.29338 to 1.29202, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.4804 - acc: 0.5144 - val_loss: 1.2920 - val_acc: 0.5579
Epoch 83/500
Epoch 00082: val_loss did not improve
16s - loss: 1.4800 - acc: 0.5148 - val_loss: 1.2997 - val_acc: 0.5569
Epoch 84/500
Epoch 00083: val_loss did not improve
17s - loss: 1.4771 - acc: 0.5157 - val_loss: 1.2930 - val_acc: 0.5559
Epoch 85/500
Epoch 00084: val_loss improved from 1.29202 to 1.29113, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
17s - loss: 1.4758 - acc: 0.5164 - val_loss: 1.2911 - val_acc: 0.5599
Epoch 86/500
Epoch 00085: val_loss improved from 1.29113 to 1.27944, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
17s - loss: 1.4750 - acc: 0.5159 - val_loss: 1.2794 - val_acc: 0.5616
Epoch 87/500
Epoch 00086: val_loss did not improve
16s - loss: 1.4739 - acc: 0.5161 - val_loss: 1.2840 - val_acc: 0.5621
Epoch 88/500
Epoch 00087: val_loss did not improve
16s - loss: 1.4725 - acc: 0.5166 - val_loss: 1.2808 - val_acc: 0.5636
Epoch 89/500
Epoch 00088: val_loss did not improve
17s - loss: 1.4720 - acc: 0.5167 - val_loss: 1.2868 - val_acc: 0.5594
Epoch 90/500
Epoch 00089: val_loss did not improve
17s - loss: 1.4697 - acc: 0.5171 - val_loss: 1.2795 - val_acc: 0.5610
Epoch 91/500
Epoch 00090: val_loss improved from 1.27944 to 1.27721, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.4676 - acc: 0.5174 - val_loss: 1.2772 - val_acc: 0.5642
Epoch 92/500
Epoch 00091: val_loss did not improve
16s - loss: 1.4649 - acc: 0.5182 - val_loss: 1.2890 - val_acc: 0.5584
Epoch 93/500
Epoch 00092: val_loss improved from 1.27721 to 1.27368, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
17s - loss: 1.4661 - acc: 0.5176 - val_loss: 1.2737 - val_acc: 0.5628
Epoch 94/500
Epoch 00093: val_loss did not improve
16s - loss: 1.4617 - acc: 0.5189 - val_loss: 1.2748 - val_acc: 0.5632
Epoch 95/500
Epoch 00094: val_loss improved from 1.27368 to 1.26967, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
17s - loss: 1.4608 - acc: 0.5192 - val_loss: 1.2697 - val_acc: 0.5623
Epoch 96/500
Epoch 00095: val_loss improved from 1.26967 to 1.26715, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.4626 - acc: 0.5184 - val_loss: 1.2671 - val_acc: 0.5644
Epoch 97/500
Epoch 00096: val_loss improved from 1.26715 to 1.25815, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.4577 - acc: 0.5196 - val_loss: 1.2582 - val_acc: 0.5666
Epoch 98/500
Epoch 00097: val_loss did not improve
16s - loss: 1.4590 - acc: 0.5206 - val_loss: 1.2635 - val_acc: 0.5668
Epoch 99/500
Epoch 00098: val_loss did not improve
16s - loss: 1.4560 - acc: 0.5207 - val_loss: 1.2669 - val_acc: 0.5642
Epoch 100/500
Epoch 00099: val_loss did not improve
17s - loss: 1.4547 - acc: 0.5208 - val_loss: 1.2619 - val_acc: 0.5664
Epoch 101/500
Epoch 00100: val_loss improved from 1.25815 to 1.25699, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.4521 - acc: 0.5215 - val_loss: 1.2570 - val_acc: 0.5657
Epoch 102/500
Epoch 00101: val_loss did not improve
17s - loss: 1.4541 - acc: 0.5213 - val_loss: 1.2734 - val_acc: 0.5608
Epoch 103/500
Epoch 00102: val_loss did not improve
16s - loss: 1.4501 - acc: 0.5221 - val_loss: 1.2682 - val_acc: 0.5652
Epoch 104/500
Epoch 00103: val_loss improved from 1.25699 to 1.25527, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
17s - loss: 1.4496 - acc: 0.5212 - val_loss: 1.2553 - val_acc: 0.5655
Epoch 105/500
Epoch 00104: val_loss did not improve
16s - loss: 1.4490 - acc: 0.5220 - val_loss: 1.2637 - val_acc: 0.5692
Epoch 106/500
Epoch 00105: val_loss did not improve
16s - loss: 1.4483 - acc: 0.5223 - val_loss: 1.2563 - val_acc: 0.5651
Epoch 107/500
Epoch 00106: val_loss did not improve
17s - loss: 1.4477 - acc: 0.5223 - val_loss: 1.2603 - val_acc: 0.5656
Epoch 108/500
Epoch 00107: val_loss did not improve
16s - loss: 1.4456 - acc: 0.5229 - val_loss: 1.2567 - val_acc: 0.5652
Epoch 109/500
Epoch 00108: val_loss improved from 1.25527 to 1.25007, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.4434 - acc: 0.5228 - val_loss: 1.2501 - val_acc: 0.5680
Epoch 110/500
Epoch 00109: val_loss did not improve
16s - loss: 1.4419 - acc: 0.5239 - val_loss: 1.2516 - val_acc: 0.5678
Epoch 111/500
Epoch 00110: val_loss did not improve
17s - loss: 1.4432 - acc: 0.5230 - val_loss: 1.2559 - val_acc: 0.5664
Epoch 112/500
Epoch 00111: val_loss did not improve
16s - loss: 1.4399 - acc: 0.5238 - val_loss: 1.2561 - val_acc: 0.5677
Epoch 113/500
Epoch 00112: val_loss improved from 1.25007 to 1.24960, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.4413 - acc: 0.5233 - val_loss: 1.2496 - val_acc: 0.5708
Epoch 114/500
Epoch 00113: val_loss improved from 1.24960 to 1.24686, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
17s - loss: 1.4373 - acc: 0.5252 - val_loss: 1.2469 - val_acc: 0.5687
Epoch 115/500
Epoch 00114: val_loss did not improve
16s - loss: 1.4390 - acc: 0.5240 - val_loss: 1.2473 - val_acc: 0.5693
Epoch 116/500
Epoch 00115: val_loss did not improve
17s - loss: 1.4376 - acc: 0.5241 - val_loss: 1.2549 - val_acc: 0.5677
Epoch 117/500
Epoch 00116: val_loss improved from 1.24686 to 1.23837, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
17s - loss: 1.4363 - acc: 0.5239 - val_loss: 1.2384 - val_acc: 0.5723
Epoch 118/500
Epoch 00117: val_loss did not improve
16s - loss: 1.4343 - acc: 0.5250 - val_loss: 1.2470 - val_acc: 0.5683
Epoch 119/500
Epoch 00118: val_loss improved from 1.23837 to 1.23010, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.4345 - acc: 0.5255 - val_loss: 1.2301 - val_acc: 0.5758
Epoch 120/500
Epoch 00119: val_loss did not improve
16s - loss: 1.4319 - acc: 0.5257 - val_loss: 1.2404 - val_acc: 0.5711
Epoch 121/500
Epoch 00120: val_loss did not improve
16s - loss: 1.4325 - acc: 0.5257 - val_loss: 1.2377 - val_acc: 0.5739
Epoch 122/500
Epoch 00121: val_loss did not improve
16s - loss: 1.4269 - acc: 0.5271 - val_loss: 1.2368 - val_acc: 0.5722
Epoch 123/500
Epoch 00122: val_loss improved from 1.23010 to 1.22980, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.4263 - acc: 0.5274 - val_loss: 1.2298 - val_acc: 0.5751
Epoch 124/500
Epoch 00123: val_loss improved from 1.22980 to 1.22340, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
17s - loss: 1.4265 - acc: 0.5273 - val_loss: 1.2234 - val_acc: 0.5763
Epoch 125/500
Epoch 00124: val_loss did not improve
17s - loss: 1.4280 - acc: 0.5268 - val_loss: 1.2251 - val_acc: 0.5761
Epoch 126/500
Epoch 00125: val_loss did not improve
16s - loss: 1.4258 - acc: 0.5276 - val_loss: 1.2286 - val_acc: 0.5751
Epoch 127/500
Epoch 00126: val_loss did not improve
16s - loss: 1.4228 - acc: 0.5283 - val_loss: 1.2268 - val_acc: 0.5754
Epoch 128/500
Epoch 00127: val_loss did not improve
16s - loss: 1.4224 - acc: 0.5280 - val_loss: 1.2285 - val_acc: 0.5740
Epoch 129/500
Epoch 00128: val_loss did not improve
16s - loss: 1.4203 - acc: 0.5283 - val_loss: 1.2242 - val_acc: 0.5781
Epoch 130/500
Epoch 00129: val_loss did not improve
16s - loss: 1.4189 - acc: 0.5288 - val_loss: 1.2266 - val_acc: 0.5737
Epoch 131/500
Epoch 00130: val_loss improved from 1.22340 to 1.21829, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.4179 - acc: 0.5290 - val_loss: 1.2183 - val_acc: 0.5768
Epoch 132/500
Epoch 00131: val_loss improved from 1.21829 to 1.20865, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.4162 - acc: 0.5290 - val_loss: 1.2087 - val_acc: 0.5818
Epoch 133/500
Epoch 00132: val_loss did not improve
16s - loss: 1.4151 - acc: 0.5299 - val_loss: 1.2115 - val_acc: 0.5813
Epoch 134/500
Epoch 00133: val_loss did not improve
16s - loss: 1.4144 - acc: 0.5300 - val_loss: 1.2169 - val_acc: 0.5769
Epoch 135/500
Epoch 00134: val_loss improved from 1.20865 to 1.20131, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
17s - loss: 1.4133 - acc: 0.5301 - val_loss: 1.2013 - val_acc: 0.5847
Epoch 136/500
Epoch 00135: val_loss did not improve
16s - loss: 1.4126 - acc: 0.5303 - val_loss: 1.2082 - val_acc: 0.5796
Epoch 137/500
Epoch 00136: val_loss did not improve
16s - loss: 1.4086 - acc: 0.5321 - val_loss: 1.2111 - val_acc: 0.5807
Epoch 138/500
Epoch 00137: val_loss did not improve
16s - loss: 1.4091 - acc: 0.5313 - val_loss: 1.2088 - val_acc: 0.5814
Epoch 139/500
Epoch 00138: val_loss did not improve
16s - loss: 1.4096 - acc: 0.5308 - val_loss: 1.2069 - val_acc: 0.5802
Epoch 140/500
Epoch 00139: val_loss improved from 1.20131 to 1.19812, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.4059 - acc: 0.5321 - val_loss: 1.1981 - val_acc: 0.5830
Epoch 141/500
Epoch 00140: val_loss improved from 1.19812 to 1.19509, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.4050 - acc: 0.5327 - val_loss: 1.1951 - val_acc: 0.5838
Epoch 142/500
Epoch 00141: val_loss did not improve
16s - loss: 1.4059 - acc: 0.5315 - val_loss: 1.2033 - val_acc: 0.5807
Epoch 143/500
Epoch 00142: val_loss did not improve
16s - loss: 1.4019 - acc: 0.5326 - val_loss: 1.1971 - val_acc: 0.5837
Epoch 144/500
Epoch 00143: val_loss did not improve
16s - loss: 1.4020 - acc: 0.5325 - val_loss: 1.1975 - val_acc: 0.5818
Epoch 145/500
Epoch 00144: val_loss did not improve
16s - loss: 1.4000 - acc: 0.5331 - val_loss: 1.2005 - val_acc: 0.5825
Epoch 146/500
Epoch 00145: val_loss improved from 1.19509 to 1.18962, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.3954 - acc: 0.5349 - val_loss: 1.1896 - val_acc: 0.5842
Epoch 147/500
Epoch 00146: val_loss improved from 1.18962 to 1.18663, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.3961 - acc: 0.5351 - val_loss: 1.1866 - val_acc: 0.5879
Epoch 148/500
Epoch 00147: val_loss did not improve
16s - loss: 1.3972 - acc: 0.5342 - val_loss: 1.2082 - val_acc: 0.5784
Epoch 149/500
Epoch 00148: val_loss improved from 1.18663 to 1.18479, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
17s - loss: 1.3959 - acc: 0.5347 - val_loss: 1.1848 - val_acc: 0.5864
Epoch 150/500
Epoch 00149: val_loss did not improve
16s - loss: 1.3933 - acc: 0.5353 - val_loss: 1.1848 - val_acc: 0.5860
Epoch 151/500
Epoch 00150: val_loss did not improve
16s - loss: 1.3956 - acc: 0.5345 - val_loss: 1.1892 - val_acc: 0.5857
Epoch 152/500
Epoch 00151: val_loss did not improve
16s - loss: 1.3939 - acc: 0.5348 - val_loss: 1.1912 - val_acc: 0.5833
Epoch 153/500
Epoch 00152: val_loss did not improve
16s - loss: 1.3933 - acc: 0.5349 - val_loss: 1.1877 - val_acc: 0.5845
Epoch 154/500
Epoch 00153: val_loss improved from 1.18479 to 1.18187, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
17s - loss: 1.3917 - acc: 0.5360 - val_loss: 1.1819 - val_acc: 0.5868
Epoch 155/500
Epoch 00154: val_loss did not improve
17s - loss: 1.3918 - acc: 0.5356 - val_loss: 1.1840 - val_acc: 0.5871
Epoch 156/500
Epoch 00155: val_loss did not improve
17s - loss: 1.3896 - acc: 0.5359 - val_loss: 1.1869 - val_acc: 0.5879
Epoch 157/500
Epoch 00156: val_loss improved from 1.18187 to 1.17905, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
17s - loss: 1.3887 - acc: 0.5362 - val_loss: 1.1790 - val_acc: 0.5863
Epoch 158/500
Epoch 00157: val_loss improved from 1.17905 to 1.17589, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.3878 - acc: 0.5371 - val_loss: 1.1759 - val_acc: 0.5899
Epoch 159/500
Epoch 00158: val_loss did not improve
16s - loss: 1.3892 - acc: 0.5372 - val_loss: 1.1788 - val_acc: 0.5900
Epoch 160/500
Epoch 00159: val_loss improved from 1.17589 to 1.17470, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
17s - loss: 1.3849 - acc: 0.5378 - val_loss: 1.1747 - val_acc: 0.5896
Epoch 161/500
Epoch 00160: val_loss did not improve
16s - loss: 1.3849 - acc: 0.5370 - val_loss: 1.1761 - val_acc: 0.5878
Epoch 162/500
Epoch 00161: val_loss did not improve
16s - loss: 1.3838 - acc: 0.5368 - val_loss: 1.1763 - val_acc: 0.5883
Epoch 163/500
Epoch 00162: val_loss did not improve
16s - loss: 1.3841 - acc: 0.5370 - val_loss: 1.1861 - val_acc: 0.5860
Epoch 164/500
Epoch 00163: val_loss did not improve
16s - loss: 1.3839 - acc: 0.5370 - val_loss: 1.1823 - val_acc: 0.5875
Epoch 165/500
Epoch 00164: val_loss did not improve
16s - loss: 1.3829 - acc: 0.5378 - val_loss: 1.1773 - val_acc: 0.5900
Epoch 166/500
Epoch 00165: val_loss did not improve
16s - loss: 1.3817 - acc: 0.5385 - val_loss: 1.1767 - val_acc: 0.5899
Epoch 167/500
Epoch 00166: val_loss did not improve
16s - loss: 1.3807 - acc: 0.5383 - val_loss: 1.1754 - val_acc: 0.5883
Epoch 168/500
Epoch 00167: val_loss improved from 1.17470 to 1.17309, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.3808 - acc: 0.5395 - val_loss: 1.1731 - val_acc: 0.5908
Epoch 169/500
Epoch 00168: val_loss did not improve
16s - loss: 1.3821 - acc: 0.5379 - val_loss: 1.1737 - val_acc: 0.5887
Epoch 170/500
Epoch 00169: val_loss improved from 1.17309 to 1.17301, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
17s - loss: 1.3789 - acc: 0.5389 - val_loss: 1.1730 - val_acc: 0.5901
Epoch 171/500
Epoch 00170: val_loss improved from 1.17301 to 1.16645, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.3787 - acc: 0.5392 - val_loss: 1.1665 - val_acc: 0.5898
Epoch 172/500
Epoch 00171: val_loss did not improve
16s - loss: 1.3763 - acc: 0.5396 - val_loss: 1.1744 - val_acc: 0.5885
Epoch 173/500
Epoch 00172: val_loss did not improve
16s - loss: 1.3755 - acc: 0.5396 - val_loss: 1.1702 - val_acc: 0.5911
Epoch 174/500
Epoch 00173: val_loss did not improve
16s - loss: 1.3776 - acc: 0.5392 - val_loss: 1.1817 - val_acc: 0.5873
Epoch 175/500
Epoch 00174: val_loss improved from 1.16645 to 1.16426, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.3747 - acc: 0.5406 - val_loss: 1.1643 - val_acc: 0.5922
Epoch 176/500
Epoch 00175: val_loss did not improve
16s - loss: 1.3750 - acc: 0.5394 - val_loss: 1.1690 - val_acc: 0.5879
Epoch 177/500
Epoch 00176: val_loss did not improve
16s - loss: 1.3750 - acc: 0.5404 - val_loss: 1.1733 - val_acc: 0.5890
Epoch 178/500
Epoch 00177: val_loss did not improve
16s - loss: 1.3731 - acc: 0.5403 - val_loss: 1.1673 - val_acc: 0.5897
Epoch 179/500
Epoch 00178: val_loss did not improve
16s - loss: 1.3749 - acc: 0.5400 - val_loss: 1.1681 - val_acc: 0.5896
Epoch 180/500
Epoch 00179: val_loss did not improve
17s - loss: 1.3734 - acc: 0.5403 - val_loss: 1.1673 - val_acc: 0.5914
Epoch 181/500
Epoch 00180: val_loss improved from 1.16426 to 1.16417, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
17s - loss: 1.3713 - acc: 0.5409 - val_loss: 1.1642 - val_acc: 0.5918
Epoch 182/500
Epoch 00181: val_loss improved from 1.16417 to 1.16181, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.3700 - acc: 0.5416 - val_loss: 1.1618 - val_acc: 0.5910
Epoch 183/500
Epoch 00182: val_loss improved from 1.16181 to 1.16151, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.3702 - acc: 0.5416 - val_loss: 1.1615 - val_acc: 0.5927
Epoch 184/500
Epoch 00183: val_loss did not improve
16s - loss: 1.3705 - acc: 0.5416 - val_loss: 1.1621 - val_acc: 0.5930
Epoch 185/500
Epoch 00184: val_loss improved from 1.16151 to 1.15962, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.3694 - acc: 0.5416 - val_loss: 1.1596 - val_acc: 0.5910
Epoch 186/500
Epoch 00185: val_loss did not improve
16s - loss: 1.3693 - acc: 0.5410 - val_loss: 1.1659 - val_acc: 0.5893
Epoch 187/500
Epoch 00186: val_loss improved from 1.15962 to 1.15352, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.3672 - acc: 0.5414 - val_loss: 1.1535 - val_acc: 0.5944
Epoch 188/500
Epoch 00187: val_loss did not improve
16s - loss: 1.3661 - acc: 0.5424 - val_loss: 1.1557 - val_acc: 0.5919
Epoch 189/500
Epoch 00188: val_loss did not improve
16s - loss: 1.3668 - acc: 0.5422 - val_loss: 1.1593 - val_acc: 0.5912
Epoch 190/500
Epoch 00189: val_loss did not improve
16s - loss: 1.3669 - acc: 0.5410 - val_loss: 1.1643 - val_acc: 0.5891
Epoch 191/500
Epoch 00190: val_loss did not improve
17s - loss: 1.3659 - acc: 0.5422 - val_loss: 1.1648 - val_acc: 0.5890
Epoch 192/500
Epoch 00191: val_loss did not improve
16s - loss: 1.3655 - acc: 0.5426 - val_loss: 1.1660 - val_acc: 0.5901
Epoch 193/500
Epoch 00192: val_loss did not improve
16s - loss: 1.3649 - acc: 0.5430 - val_loss: 1.1589 - val_acc: 0.5921
Epoch 194/500
Epoch 00193: val_loss did not improve
16s - loss: 1.3653 - acc: 0.5431 - val_loss: 1.1555 - val_acc: 0.5946
Epoch 195/500
Epoch 00194: val_loss did not improve
16s - loss: 1.3613 - acc: 0.5437 - val_loss: 1.1622 - val_acc: 0.5915
Epoch 196/500
Epoch 00195: val_loss did not improve
16s - loss: 1.3620 - acc: 0.5434 - val_loss: 1.1584 - val_acc: 0.5936
Epoch 197/500
Epoch 00196: val_loss did not improve
16s - loss: 1.3629 - acc: 0.5430 - val_loss: 1.1617 - val_acc: 0.5923
Epoch 198/500
Epoch 00197: val_loss did not improve
16s - loss: 1.3626 - acc: 0.5429 - val_loss: 1.1692 - val_acc: 0.5888
Epoch 199/500
Epoch 00198: val_loss improved from 1.15352 to 1.15070, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.3619 - acc: 0.5435 - val_loss: 1.1507 - val_acc: 0.5945
Epoch 200/500
Epoch 00199: val_loss did not improve
16s - loss: 1.3595 - acc: 0.5441 - val_loss: 1.1640 - val_acc: 0.5902
Epoch 201/500
Epoch 00200: val_loss did not improve
16s - loss: 1.3597 - acc: 0.5440 - val_loss: 1.1574 - val_acc: 0.5911
Epoch 202/500
Epoch 00201: val_loss did not improve
16s - loss: 1.3582 - acc: 0.5443 - val_loss: 1.1548 - val_acc: 0.5940
Epoch 203/500
Epoch 00202: val_loss did not improve
16s - loss: 1.3566 - acc: 0.5442 - val_loss: 1.1540 - val_acc: 0.5938
Epoch 204/500
Epoch 00203: val_loss improved from 1.15070 to 1.14252, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
17s - loss: 1.3570 - acc: 0.5448 - val_loss: 1.1425 - val_acc: 0.5971
Epoch 205/500
Epoch 00204: val_loss improved from 1.14252 to 1.14231, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.3572 - acc: 0.5442 - val_loss: 1.1423 - val_acc: 0.5969
Epoch 206/500
Epoch 00205: val_loss did not improve
16s - loss: 1.3567 - acc: 0.5448 - val_loss: 1.1451 - val_acc: 0.5965
Epoch 207/500
Epoch 00206: val_loss did not improve
16s - loss: 1.3561 - acc: 0.5442 - val_loss: 1.1507 - val_acc: 0.5925
Epoch 208/500
Epoch 00207: val_loss improved from 1.14231 to 1.13893, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
17s - loss: 1.3536 - acc: 0.5447 - val_loss: 1.1389 - val_acc: 0.5977
Epoch 209/500
Epoch 00208: val_loss did not improve
16s - loss: 1.3561 - acc: 0.5444 - val_loss: 1.1451 - val_acc: 0.5952
Epoch 210/500
Epoch 00209: val_loss did not improve
16s - loss: 1.3536 - acc: 0.5450 - val_loss: 1.1552 - val_acc: 0.5936
Epoch 211/500
Epoch 00210: val_loss did not improve
16s - loss: 1.3534 - acc: 0.5452 - val_loss: 1.1412 - val_acc: 0.5985
Epoch 212/500
Epoch 00211: val_loss did not improve
16s - loss: 1.3520 - acc: 0.5458 - val_loss: 1.1603 - val_acc: 0.5909
Epoch 213/500
Epoch 00212: val_loss did not improve
16s - loss: 1.3519 - acc: 0.5457 - val_loss: 1.1440 - val_acc: 0.5968
Epoch 214/500
Epoch 00213: val_loss improved from 1.13893 to 1.13892, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.3500 - acc: 0.5464 - val_loss: 1.1389 - val_acc: 0.6001
Epoch 215/500
Epoch 00214: val_loss did not improve
16s - loss: 1.3500 - acc: 0.5466 - val_loss: 1.1390 - val_acc: 0.5969
Epoch 216/500
Epoch 00215: val_loss improved from 1.13892 to 1.13308, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.3475 - acc: 0.5478 - val_loss: 1.1331 - val_acc: 0.5982
Epoch 217/500
Epoch 00216: val_loss did not improve
16s - loss: 1.3486 - acc: 0.5463 - val_loss: 1.1378 - val_acc: 0.5984
Epoch 218/500
Epoch 00217: val_loss improved from 1.13308 to 1.13250, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.3466 - acc: 0.5474 - val_loss: 1.1325 - val_acc: 0.6004
Epoch 219/500
Epoch 00218: val_loss improved from 1.13250 to 1.13069, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.3473 - acc: 0.5472 - val_loss: 1.1307 - val_acc: 0.5987
Epoch 220/500
Epoch 00219: val_loss did not improve
16s - loss: 1.3465 - acc: 0.5470 - val_loss: 1.1340 - val_acc: 0.5997
Epoch 221/500
Epoch 00220: val_loss improved from 1.13069 to 1.12892, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.3445 - acc: 0.5473 - val_loss: 1.1289 - val_acc: 0.6017
Epoch 222/500
Epoch 00221: val_loss improved from 1.12892 to 1.12849, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
17s - loss: 1.3437 - acc: 0.5479 - val_loss: 1.1285 - val_acc: 0.6022
Epoch 223/500
Epoch 00222: val_loss did not improve
16s - loss: 1.3442 - acc: 0.5479 - val_loss: 1.1292 - val_acc: 0.6017
Epoch 224/500
Epoch 00223: val_loss improved from 1.12849 to 1.12478, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
17s - loss: 1.3426 - acc: 0.5483 - val_loss: 1.1248 - val_acc: 0.6018
Epoch 225/500
Epoch 00224: val_loss improved from 1.12478 to 1.12160, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.3416 - acc: 0.5485 - val_loss: 1.1216 - val_acc: 0.6025
Epoch 226/500
Epoch 00225: val_loss did not improve
16s - loss: 1.3415 - acc: 0.5486 - val_loss: 1.1366 - val_acc: 0.5991
Epoch 227/500
Epoch 00226: val_loss improved from 1.12160 to 1.11945, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.3423 - acc: 0.5487 - val_loss: 1.1194 - val_acc: 0.6035
Epoch 228/500
Epoch 00227: val_loss did not improve
16s - loss: 1.3426 - acc: 0.5483 - val_loss: 1.1248 - val_acc: 0.6019
Epoch 229/500
Epoch 00228: val_loss did not improve
16s - loss: 1.3403 - acc: 0.5490 - val_loss: 1.1307 - val_acc: 0.6003
Epoch 230/500
Epoch 00229: val_loss did not improve
16s - loss: 1.3392 - acc: 0.5490 - val_loss: 1.1339 - val_acc: 0.6017
Epoch 231/500
Epoch 00230: val_loss did not improve
17s - loss: 1.3386 - acc: 0.5488 - val_loss: 1.1291 - val_acc: 0.6013
Epoch 232/500
Epoch 00231: val_loss did not improve
16s - loss: 1.3383 - acc: 0.5487 - val_loss: 1.1405 - val_acc: 0.5984
Epoch 233/500
Epoch 00232: val_loss did not improve
16s - loss: 1.3386 - acc: 0.5489 - val_loss: 1.1284 - val_acc: 0.6016
Epoch 234/500
Epoch 00233: val_loss did not improve
16s - loss: 1.3375 - acc: 0.5502 - val_loss: 1.1317 - val_acc: 0.6011
Epoch 235/500
Epoch 00234: val_loss did not improve
17s - loss: 1.3364 - acc: 0.5499 - val_loss: 1.1212 - val_acc: 0.6028
Epoch 236/500
Epoch 00235: val_loss improved from 1.11945 to 1.11557, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
17s - loss: 1.3371 - acc: 0.5496 - val_loss: 1.1156 - val_acc: 0.6051
Epoch 237/500
Epoch 00236: val_loss did not improve
16s - loss: 1.3362 - acc: 0.5497 - val_loss: 1.1243 - val_acc: 0.6055
Epoch 238/500
Epoch 00237: val_loss did not improve
16s - loss: 1.3354 - acc: 0.5505 - val_loss: 1.1169 - val_acc: 0.6052
Epoch 239/500
Epoch 00238: val_loss did not improve
16s - loss: 1.3348 - acc: 0.5506 - val_loss: 1.1169 - val_acc: 0.6036
Epoch 240/500
Epoch 00239: val_loss did not improve
16s - loss: 1.3345 - acc: 0.5503 - val_loss: 1.1180 - val_acc: 0.6037
Epoch 241/500
Epoch 00240: val_loss did not improve
16s - loss: 1.3332 - acc: 0.5510 - val_loss: 1.1237 - val_acc: 0.6022
Epoch 242/500
Epoch 00241: val_loss did not improve
16s - loss: 1.3324 - acc: 0.5503 - val_loss: 1.1156 - val_acc: 0.6037
Epoch 243/500
Epoch 00242: val_loss did not improve
16s - loss: 1.3329 - acc: 0.5509 - val_loss: 1.1209 - val_acc: 0.6029
Epoch 244/500
Epoch 00243: val_loss did not improve
16s - loss: 1.3345 - acc: 0.5504 - val_loss: 1.1170 - val_acc: 0.6046
Epoch 245/500
Epoch 00244: val_loss improved from 1.11557 to 1.11169, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.3313 - acc: 0.5511 - val_loss: 1.1117 - val_acc: 0.6078
Epoch 246/500
Epoch 00245: val_loss did not improve
16s - loss: 1.3322 - acc: 0.5503 - val_loss: 1.1165 - val_acc: 0.6038
Epoch 247/500
Epoch 00246: val_loss did not improve
16s - loss: 1.3318 - acc: 0.5508 - val_loss: 1.1144 - val_acc: 0.6065
Epoch 248/500
Epoch 00247: val_loss improved from 1.11169 to 1.10910, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.3311 - acc: 0.5512 - val_loss: 1.1091 - val_acc: 0.6075
Epoch 249/500
Epoch 00248: val_loss did not improve
16s - loss: 1.3298 - acc: 0.5514 - val_loss: 1.1150 - val_acc: 0.6072
Epoch 250/500
Epoch 00249: val_loss did not improve
16s - loss: 1.3285 - acc: 0.5516 - val_loss: 1.1117 - val_acc: 0.6060
Epoch 251/500
Epoch 00250: val_loss did not improve
16s - loss: 1.3287 - acc: 0.5514 - val_loss: 1.1112 - val_acc: 0.6075
Epoch 252/500
Epoch 00251: val_loss did not improve
16s - loss: 1.3285 - acc: 0.5519 - val_loss: 1.1167 - val_acc: 0.6040
Epoch 253/500
Epoch 00252: val_loss did not improve
16s - loss: 1.3266 - acc: 0.5521 - val_loss: 1.1107 - val_acc: 0.6075
Epoch 254/500
Epoch 00253: val_loss improved from 1.10910 to 1.10341, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.3271 - acc: 0.5525 - val_loss: 1.1034 - val_acc: 0.6083
Epoch 255/500
Epoch 00254: val_loss did not improve
16s - loss: 1.3257 - acc: 0.5527 - val_loss: 1.1075 - val_acc: 0.6060
Epoch 256/500
Epoch 00255: val_loss did not improve
16s - loss: 1.3270 - acc: 0.5522 - val_loss: 1.1124 - val_acc: 0.6041
Epoch 257/500
Epoch 00256: val_loss did not improve
16s - loss: 1.3257 - acc: 0.5519 - val_loss: 1.1114 - val_acc: 0.6039
Epoch 258/500
Epoch 00257: val_loss did not improve
16s - loss: 1.3248 - acc: 0.5525 - val_loss: 1.1087 - val_acc: 0.6080
Epoch 259/500
Epoch 00258: val_loss did not improve
16s - loss: 1.3244 - acc: 0.5528 - val_loss: 1.1055 - val_acc: 0.6079
Epoch 260/500
Epoch 00259: val_loss did not improve
16s - loss: 1.3230 - acc: 0.5527 - val_loss: 1.1135 - val_acc: 0.6056
Epoch 261/500
Epoch 00260: val_loss did not improve
16s - loss: 1.3229 - acc: 0.5534 - val_loss: 1.1095 - val_acc: 0.6049
Epoch 262/500
Epoch 00261: val_loss improved from 1.10341 to 1.10178, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.3212 - acc: 0.5533 - val_loss: 1.1018 - val_acc: 0.6080
Epoch 263/500
Epoch 00262: val_loss did not improve
16s - loss: 1.3241 - acc: 0.5530 - val_loss: 1.1039 - val_acc: 0.6063
Epoch 264/500
Epoch 00263: val_loss improved from 1.10178 to 1.10144, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.3212 - acc: 0.5527 - val_loss: 1.1014 - val_acc: 0.6083
Epoch 265/500
Epoch 00264: val_loss did not improve
16s - loss: 1.3228 - acc: 0.5525 - val_loss: 1.1024 - val_acc: 0.6064
Epoch 266/500
Epoch 00265: val_loss improved from 1.10144 to 1.09705, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
17s - loss: 1.3218 - acc: 0.5531 - val_loss: 1.0971 - val_acc: 0.6093
Epoch 267/500
Epoch 00266: val_loss did not improve
16s - loss: 1.3210 - acc: 0.5534 - val_loss: 1.1121 - val_acc: 0.6070
Epoch 268/500
Epoch 00267: val_loss did not improve
16s - loss: 1.3203 - acc: 0.5543 - val_loss: 1.1152 - val_acc: 0.6042
Epoch 269/500
Epoch 00268: val_loss did not improve
16s - loss: 1.3192 - acc: 0.5535 - val_loss: 1.1012 - val_acc: 0.6083
Epoch 270/500
Epoch 00269: val_loss did not improve
16s - loss: 1.3211 - acc: 0.5528 - val_loss: 1.1018 - val_acc: 0.6078
Epoch 271/500
Epoch 00270: val_loss improved from 1.09705 to 1.09153, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.3168 - acc: 0.5544 - val_loss: 1.0915 - val_acc: 0.6111
Epoch 272/500
Epoch 00271: val_loss did not improve
16s - loss: 1.3205 - acc: 0.5533 - val_loss: 1.0920 - val_acc: 0.6100
Epoch 273/500
Epoch 00272: val_loss did not improve
16s - loss: 1.3188 - acc: 0.5537 - val_loss: 1.1037 - val_acc: 0.6072
Epoch 274/500
Epoch 00273: val_loss did not improve
16s - loss: 1.3203 - acc: 0.5531 - val_loss: 1.0963 - val_acc: 0.6076
Epoch 275/500
Epoch 00274: val_loss did not improve
16s - loss: 1.3191 - acc: 0.5532 - val_loss: 1.0935 - val_acc: 0.6093
Epoch 276/500
Epoch 00275: val_loss did not improve
16s - loss: 1.3156 - acc: 0.5542 - val_loss: 1.1006 - val_acc: 0.6092
Epoch 277/500
Epoch 00276: val_loss did not improve
16s - loss: 1.3137 - acc: 0.5554 - val_loss: 1.1023 - val_acc: 0.6063
Epoch 278/500
Epoch 00277: val_loss did not improve
16s - loss: 1.3165 - acc: 0.5546 - val_loss: 1.0976 - val_acc: 0.6071
Epoch 279/500
Epoch 00278: val_loss did not improve
16s - loss: 1.3162 - acc: 0.5545 - val_loss: 1.1019 - val_acc: 0.6058
Epoch 280/500
Epoch 00279: val_loss did not improve
16s - loss: 1.3143 - acc: 0.5551 - val_loss: 1.0953 - val_acc: 0.6087
Epoch 281/500
Epoch 00280: val_loss did not improve
16s - loss: 1.3158 - acc: 0.5541 - val_loss: 1.0918 - val_acc: 0.6110
Epoch 282/500
Epoch 00281: val_loss improved from 1.09153 to 1.08766, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.3163 - acc: 0.5551 - val_loss: 1.0877 - val_acc: 0.6097
Epoch 283/500
Epoch 00282: val_loss did not improve
16s - loss: 1.3131 - acc: 0.5553 - val_loss: 1.0894 - val_acc: 0.6105
Epoch 284/500
Epoch 00283: val_loss improved from 1.08766 to 1.08653, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.3135 - acc: 0.5552 - val_loss: 1.0865 - val_acc: 0.6122
Epoch 285/500
Epoch 00284: val_loss did not improve
16s - loss: 1.3142 - acc: 0.5554 - val_loss: 1.0986 - val_acc: 0.6074
Epoch 286/500
Epoch 00285: val_loss did not improve
16s - loss: 1.3145 - acc: 0.5547 - val_loss: 1.1032 - val_acc: 0.6096
Epoch 287/500
Epoch 00286: val_loss did not improve
16s - loss: 1.3133 - acc: 0.5551 - val_loss: 1.0914 - val_acc: 0.6108
Epoch 288/500
Epoch 00287: val_loss did not improve
16s - loss: 1.3131 - acc: 0.5547 - val_loss: 1.0912 - val_acc: 0.6093
Epoch 289/500
Epoch 00288: val_loss did not improve
16s - loss: 1.3130 - acc: 0.5554 - val_loss: 1.0941 - val_acc: 0.6093
Epoch 290/500
Epoch 00289: val_loss did not improve
16s - loss: 1.3119 - acc: 0.5555 - val_loss: 1.0870 - val_acc: 0.6092
Epoch 291/500
Epoch 00290: val_loss did not improve
16s - loss: 1.3102 - acc: 0.5560 - val_loss: 1.0901 - val_acc: 0.6084
Epoch 292/500
Epoch 00291: val_loss improved from 1.08653 to 1.08560, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.3110 - acc: 0.5555 - val_loss: 1.0856 - val_acc: 0.6097
Epoch 293/500
Epoch 00292: val_loss did not improve
16s - loss: 1.3110 - acc: 0.5562 - val_loss: 1.0877 - val_acc: 0.6111
Epoch 294/500
Epoch 00293: val_loss did not improve
16s - loss: 1.3115 - acc: 0.5553 - val_loss: 1.0968 - val_acc: 0.6083
Epoch 295/500
Epoch 00294: val_loss improved from 1.08560 to 1.07967, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
17s - loss: 1.3088 - acc: 0.5562 - val_loss: 1.0797 - val_acc: 0.6138
Epoch 296/500
Epoch 00295: val_loss did not improve
16s - loss: 1.3084 - acc: 0.5566 - val_loss: 1.0856 - val_acc: 0.6114
Epoch 297/500
Epoch 00296: val_loss did not improve
16s - loss: 1.3092 - acc: 0.5559 - val_loss: 1.0850 - val_acc: 0.6111
Epoch 298/500
Epoch 00297: val_loss did not improve
16s - loss: 1.3082 - acc: 0.5562 - val_loss: 1.0914 - val_acc: 0.6101
Epoch 299/500
Epoch 00298: val_loss did not improve
16s - loss: 1.3097 - acc: 0.5556 - val_loss: 1.0842 - val_acc: 0.6098
Epoch 300/500
Epoch 00299: val_loss did not improve
16s - loss: 1.3060 - acc: 0.5565 - val_loss: 1.0857 - val_acc: 0.6112
Epoch 301/500
Epoch 00300: val_loss did not improve
16s - loss: 1.3074 - acc: 0.5569 - val_loss: 1.0897 - val_acc: 0.6113
Epoch 302/500
Epoch 00301: val_loss did not improve
16s - loss: 1.3081 - acc: 0.5564 - val_loss: 1.0961 - val_acc: 0.6082
Epoch 303/500
Epoch 00302: val_loss did not improve
16s - loss: 1.3073 - acc: 0.5560 - val_loss: 1.0866 - val_acc: 0.6104
Epoch 304/500
Epoch 00303: val_loss did not improve
16s - loss: 1.3047 - acc: 0.5560 - val_loss: 1.0869 - val_acc: 0.6112
Epoch 305/500
Epoch 00304: val_loss did not improve
16s - loss: 1.3052 - acc: 0.5564 - val_loss: 1.0849 - val_acc: 0.6107
Epoch 306/500
Epoch 00305: val_loss did not improve
16s - loss: 1.3078 - acc: 0.5562 - val_loss: 1.0835 - val_acc: 0.6119
Epoch 307/500
Epoch 00306: val_loss did not improve
16s - loss: 1.3063 - acc: 0.5564 - val_loss: 1.0831 - val_acc: 0.6114
Epoch 308/500
Epoch 00307: val_loss did not improve
16s - loss: 1.3064 - acc: 0.5562 - val_loss: 1.0836 - val_acc: 0.6098
Epoch 309/500
Epoch 00308: val_loss did not improve
16s - loss: 1.3033 - acc: 0.5568 - val_loss: 1.0804 - val_acc: 0.6122
Epoch 310/500
Epoch 00309: val_loss did not improve
16s - loss: 1.3041 - acc: 0.5570 - val_loss: 1.0892 - val_acc: 0.6105
Epoch 311/500
Epoch 00310: val_loss improved from 1.07967 to 1.07957, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.3028 - acc: 0.5570 - val_loss: 1.0796 - val_acc: 0.6102
Epoch 312/500
Epoch 00311: val_loss improved from 1.07957 to 1.07670, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.3021 - acc: 0.5568 - val_loss: 1.0767 - val_acc: 0.6125
Epoch 313/500
Epoch 00312: val_loss did not improve
16s - loss: 1.3043 - acc: 0.5569 - val_loss: 1.0832 - val_acc: 0.6124
Epoch 314/500
Epoch 00313: val_loss did not improve
16s - loss: 1.3024 - acc: 0.5579 - val_loss: 1.0842 - val_acc: 0.6105
Epoch 315/500
Epoch 00314: val_loss did not improve
16s - loss: 1.3025 - acc: 0.5567 - val_loss: 1.0809 - val_acc: 0.6115
Epoch 316/500
Epoch 00315: val_loss did not improve
16s - loss: 1.3032 - acc: 0.5569 - val_loss: 1.0810 - val_acc: 0.6113
Epoch 317/500
Epoch 00316: val_loss did not improve
16s - loss: 1.3034 - acc: 0.5571 - val_loss: 1.0976 - val_acc: 0.6064
Epoch 318/500
Epoch 00317: val_loss did not improve
16s - loss: 1.3011 - acc: 0.5574 - val_loss: 1.0791 - val_acc: 0.6108
Epoch 319/500
Epoch 00318: val_loss improved from 1.07670 to 1.07592, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.3026 - acc: 0.5561 - val_loss: 1.0759 - val_acc: 0.6125
Epoch 320/500
Epoch 00319: val_loss did not improve
16s - loss: 1.3011 - acc: 0.5566 - val_loss: 1.0831 - val_acc: 0.6080
Epoch 321/500
Epoch 00320: val_loss improved from 1.07592 to 1.07293, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.3002 - acc: 0.5566 - val_loss: 1.0729 - val_acc: 0.6108
Epoch 322/500
Epoch 00321: val_loss did not improve
16s - loss: 1.3020 - acc: 0.5558 - val_loss: 1.0895 - val_acc: 0.6041
Epoch 323/500
Epoch 00322: val_loss did not improve
16s - loss: 1.3020 - acc: 0.5568 - val_loss: 1.0764 - val_acc: 0.6107
Epoch 324/500
Epoch 00323: val_loss did not improve
16s - loss: 1.3002 - acc: 0.5571 - val_loss: 1.0856 - val_acc: 0.6078
Epoch 325/500
Epoch 00324: val_loss did not improve
16s - loss: 1.2972 - acc: 0.5575 - val_loss: 1.0817 - val_acc: 0.6082
Epoch 326/500
Epoch 00325: val_loss improved from 1.07293 to 1.07070, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.2993 - acc: 0.5574 - val_loss: 1.0707 - val_acc: 0.6115
Epoch 327/500
Epoch 00326: val_loss did not improve
16s - loss: 1.2997 - acc: 0.5560 - val_loss: 1.0801 - val_acc: 0.6076
Epoch 328/500
Epoch 00327: val_loss did not improve
16s - loss: 1.2990 - acc: 0.5570 - val_loss: 1.0826 - val_acc: 0.6074
Epoch 329/500
Epoch 00328: val_loss did not improve
16s - loss: 1.2980 - acc: 0.5573 - val_loss: 1.0728 - val_acc: 0.6117
Epoch 330/500
Epoch 00329: val_loss did not improve
16s - loss: 1.2982 - acc: 0.5568 - val_loss: 1.0749 - val_acc: 0.6102
Epoch 331/500
Epoch 00330: val_loss did not improve
16s - loss: 1.2977 - acc: 0.5572 - val_loss: 1.0770 - val_acc: 0.6076
Epoch 332/500
Epoch 00331: val_loss improved from 1.07070 to 1.06813, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.2991 - acc: 0.5566 - val_loss: 1.0681 - val_acc: 0.6119
Epoch 333/500
Epoch 00332: val_loss did not improve
16s - loss: 1.2958 - acc: 0.5573 - val_loss: 1.0771 - val_acc: 0.6082
Epoch 334/500
Epoch 00333: val_loss did not improve
16s - loss: 1.2957 - acc: 0.5573 - val_loss: 1.0842 - val_acc: 0.6077
Epoch 335/500
Epoch 00334: val_loss did not improve
16s - loss: 1.2958 - acc: 0.5577 - val_loss: 1.0860 - val_acc: 0.6072
Epoch 336/500
Epoch 00335: val_loss did not improve
16s - loss: 1.2962 - acc: 0.5574 - val_loss: 1.0744 - val_acc: 0.6093
Epoch 337/500
Epoch 00336: val_loss did not improve
16s - loss: 1.2980 - acc: 0.5565 - val_loss: 1.0725 - val_acc: 0.6088
Epoch 338/500
Epoch 00337: val_loss did not improve
16s - loss: 1.2945 - acc: 0.5573 - val_loss: 1.0796 - val_acc: 0.6069
Epoch 339/500
Epoch 00338: val_loss did not improve
16s - loss: 1.2955 - acc: 0.5570 - val_loss: 1.0820 - val_acc: 0.6037
Epoch 340/500
Epoch 00339: val_loss improved from 1.06813 to 1.06703, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.2950 - acc: 0.5568 - val_loss: 1.0670 - val_acc: 0.6103
Epoch 341/500
Epoch 00340: val_loss did not improve
16s - loss: 1.2943 - acc: 0.5571 - val_loss: 1.0696 - val_acc: 0.6096
Epoch 342/500
Epoch 00341: val_loss did not improve
16s - loss: 1.2938 - acc: 0.5575 - val_loss: 1.0873 - val_acc: 0.6045
Epoch 343/500
Epoch 00342: val_loss improved from 1.06703 to 1.06294, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.2943 - acc: 0.5578 - val_loss: 1.0629 - val_acc: 0.6108
Epoch 344/500
Epoch 00343: val_loss did not improve
16s - loss: 1.2935 - acc: 0.5572 - val_loss: 1.0659 - val_acc: 0.6101
Epoch 345/500
Epoch 00344: val_loss did not improve
16s - loss: 1.2942 - acc: 0.5572 - val_loss: 1.0720 - val_acc: 0.6083
Epoch 346/500
Epoch 00345: val_loss did not improve
16s - loss: 1.2932 - acc: 0.5572 - val_loss: 1.0761 - val_acc: 0.6058
Epoch 347/500
Epoch 00346: val_loss improved from 1.06294 to 1.06012, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.2925 - acc: 0.5576 - val_loss: 1.0601 - val_acc: 0.6121
Epoch 348/500
Epoch 00347: val_loss did not improve
16s - loss: 1.2946 - acc: 0.5573 - val_loss: 1.0658 - val_acc: 0.6102
Epoch 349/500
Epoch 00348: val_loss did not improve
16s - loss: 1.2933 - acc: 0.5572 - val_loss: 1.0673 - val_acc: 0.6073
Epoch 350/500
Epoch 00349: val_loss did not improve
16s - loss: 1.2913 - acc: 0.5580 - val_loss: 1.0738 - val_acc: 0.6048
Epoch 351/500
Epoch 00350: val_loss did not improve
17s - loss: 1.2927 - acc: 0.5579 - val_loss: 1.0668 - val_acc: 0.6079
Epoch 352/500
Epoch 00351: val_loss did not improve
16s - loss: 1.2911 - acc: 0.5572 - val_loss: 1.0752 - val_acc: 0.6089
Epoch 353/500
Epoch 00352: val_loss did not improve
16s - loss: 1.2905 - acc: 0.5575 - val_loss: 1.0725 - val_acc: 0.6070
Epoch 354/500
Epoch 00353: val_loss did not improve
16s - loss: 1.2919 - acc: 0.5572 - val_loss: 1.0685 - val_acc: 0.6079
Epoch 355/500
Epoch 00354: val_loss did not improve
16s - loss: 1.2935 - acc: 0.5567 - val_loss: 1.0681 - val_acc: 0.6073
Epoch 356/500
Epoch 00355: val_loss did not improve
16s - loss: 1.2892 - acc: 0.5572 - val_loss: 1.0638 - val_acc: 0.6090
Epoch 357/500
Epoch 00356: val_loss did not improve
16s - loss: 1.2893 - acc: 0.5576 - val_loss: 1.0742 - val_acc: 0.6051
Epoch 358/500
Epoch 00357: val_loss did not improve
16s - loss: 1.2883 - acc: 0.5573 - val_loss: 1.0661 - val_acc: 0.6073
Epoch 359/500
Epoch 00358: val_loss did not improve
16s - loss: 1.2896 - acc: 0.5574 - val_loss: 1.0800 - val_acc: 0.6037
Epoch 360/500
Epoch 00359: val_loss did not improve
16s - loss: 1.2883 - acc: 0.5578 - val_loss: 1.0719 - val_acc: 0.6075
Epoch 361/500
Epoch 00360: val_loss did not improve
16s - loss: 1.2880 - acc: 0.5582 - val_loss: 1.0735 - val_acc: 0.6057
Epoch 362/500
Epoch 00361: val_loss did not improve
16s - loss: 1.2893 - acc: 0.5577 - val_loss: 1.0663 - val_acc: 0.6053
Epoch 363/500
Epoch 00362: val_loss did not improve
16s - loss: 1.2883 - acc: 0.5570 - val_loss: 1.0741 - val_acc: 0.6050
Epoch 364/500
Epoch 00363: val_loss improved from 1.06012 to 1.05926, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.2885 - acc: 0.5577 - val_loss: 1.0593 - val_acc: 0.6082
Epoch 365/500
Epoch 00364: val_loss did not improve
16s - loss: 1.2851 - acc: 0.5577 - val_loss: 1.0712 - val_acc: 0.6074
Epoch 366/500
Epoch 00365: val_loss improved from 1.05926 to 1.05321, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.2871 - acc: 0.5576 - val_loss: 1.0532 - val_acc: 0.6123
Epoch 367/500
Epoch 00366: val_loss did not improve
16s - loss: 1.2860 - acc: 0.5581 - val_loss: 1.0590 - val_acc: 0.6102
Epoch 368/500
Epoch 00367: val_loss did not improve
16s - loss: 1.2855 - acc: 0.5581 - val_loss: 1.0760 - val_acc: 0.6026
Epoch 369/500
Epoch 00368: val_loss did not improve
16s - loss: 1.2859 - acc: 0.5581 - val_loss: 1.0698 - val_acc: 0.6069
Epoch 370/500
Epoch 00369: val_loss did not improve
16s - loss: 1.2892 - acc: 0.5570 - val_loss: 1.0843 - val_acc: 0.6049
Epoch 371/500
Epoch 00370: val_loss did not improve
16s - loss: 1.2843 - acc: 0.5583 - val_loss: 1.0679 - val_acc: 0.6069
Epoch 372/500
Epoch 00371: val_loss did not improve
17s - loss: 1.2853 - acc: 0.5582 - val_loss: 1.0665 - val_acc: 0.6063
Epoch 373/500
Epoch 00372: val_loss did not improve
16s - loss: 1.2855 - acc: 0.5573 - val_loss: 1.0723 - val_acc: 0.6035
Epoch 374/500
Epoch 00373: val_loss did not improve
16s - loss: 1.2867 - acc: 0.5581 - val_loss: 1.0765 - val_acc: 0.6057
Epoch 375/500
Epoch 00374: val_loss did not improve
16s - loss: 1.2850 - acc: 0.5580 - val_loss: 1.0724 - val_acc: 0.6054
Epoch 376/500
Epoch 00375: val_loss did not improve
16s - loss: 1.2860 - acc: 0.5588 - val_loss: 1.0640 - val_acc: 0.6063
Epoch 377/500
Epoch 00376: val_loss did not improve
16s - loss: 1.2850 - acc: 0.5583 - val_loss: 1.0657 - val_acc: 0.6064
Epoch 378/500
Epoch 00377: val_loss did not improve
16s - loss: 1.2865 - acc: 0.5580 - val_loss: 1.0607 - val_acc: 0.6093
Epoch 379/500
Epoch 00378: val_loss did not improve
16s - loss: 1.2833 - acc: 0.5592 - val_loss: 1.0700 - val_acc: 0.6054
Epoch 380/500
Epoch 00379: val_loss did not improve
16s - loss: 1.2834 - acc: 0.5586 - val_loss: 1.0617 - val_acc: 0.6087
Epoch 381/500
Epoch 00380: val_loss did not improve
16s - loss: 1.2841 - acc: 0.5590 - val_loss: 1.0552 - val_acc: 0.6085
Epoch 382/500
Epoch 00381: val_loss did not improve
16s - loss: 1.2828 - acc: 0.5586 - val_loss: 1.0711 - val_acc: 0.6053
Epoch 383/500
Epoch 00382: val_loss did not improve
16s - loss: 1.2822 - acc: 0.5595 - val_loss: 1.0660 - val_acc: 0.6071
Epoch 384/500
Epoch 00383: val_loss did not improve
16s - loss: 1.2811 - acc: 0.5588 - val_loss: 1.0803 - val_acc: 0.6047
Epoch 385/500
Epoch 00384: val_loss improved from 1.05321 to 1.05064, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.2832 - acc: 0.5583 - val_loss: 1.0506 - val_acc: 0.6098
Epoch 386/500
Epoch 00385: val_loss did not improve
16s - loss: 1.2817 - acc: 0.5591 - val_loss: 1.0630 - val_acc: 0.6073
Epoch 387/500
Epoch 00386: val_loss did not improve
16s - loss: 1.2816 - acc: 0.5590 - val_loss: 1.0575 - val_acc: 0.6075
Epoch 388/500
Epoch 00387: val_loss improved from 1.05064 to 1.05048, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.2818 - acc: 0.5590 - val_loss: 1.0505 - val_acc: 0.6098
Epoch 389/500
Epoch 00388: val_loss did not improve
16s - loss: 1.2827 - acc: 0.5586 - val_loss: 1.0554 - val_acc: 0.6102
Epoch 390/500
Epoch 00389: val_loss did not improve
16s - loss: 1.2798 - acc: 0.5597 - val_loss: 1.0602 - val_acc: 0.6087
Epoch 391/500
Epoch 00390: val_loss did not improve
16s - loss: 1.2822 - acc: 0.5593 - val_loss: 1.0631 - val_acc: 0.6096
Epoch 392/500
Epoch 00391: val_loss did not improve
16s - loss: 1.2789 - acc: 0.5595 - val_loss: 1.0516 - val_acc: 0.6104
Epoch 393/500
Epoch 00392: val_loss did not improve
16s - loss: 1.2797 - acc: 0.5598 - val_loss: 1.0604 - val_acc: 0.6100
Epoch 394/500
Epoch 00393: val_loss did not improve
16s - loss: 1.2784 - acc: 0.5601 - val_loss: 1.0546 - val_acc: 0.6105
Epoch 395/500
Epoch 00394: val_loss did not improve
16s - loss: 1.2797 - acc: 0.5596 - val_loss: 1.0529 - val_acc: 0.6115
Epoch 396/500
Epoch 00395: val_loss improved from 1.05048 to 1.04536, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.2797 - acc: 0.5600 - val_loss: 1.0454 - val_acc: 0.6129
Epoch 397/500
Epoch 00396: val_loss did not improve
16s - loss: 1.2790 - acc: 0.5606 - val_loss: 1.0486 - val_acc: 0.6107
Epoch 398/500
Epoch 00397: val_loss did not improve
16s - loss: 1.2781 - acc: 0.5600 - val_loss: 1.0620 - val_acc: 0.6081
Epoch 399/500
Epoch 00398: val_loss did not improve
16s - loss: 1.2785 - acc: 0.5596 - val_loss: 1.0772 - val_acc: 0.6071
Epoch 400/500
Epoch 00399: val_loss did not improve
16s - loss: 1.2780 - acc: 0.5600 - val_loss: 1.0557 - val_acc: 0.6098
Epoch 401/500
Epoch 00400: val_loss did not improve
16s - loss: 1.2767 - acc: 0.5604 - val_loss: 1.0617 - val_acc: 0.6097
Epoch 402/500
Epoch 00401: val_loss did not improve
16s - loss: 1.2779 - acc: 0.5602 - val_loss: 1.0661 - val_acc: 0.6067
Epoch 403/500
Epoch 00402: val_loss did not improve
16s - loss: 1.2822 - acc: 0.5590 - val_loss: 1.0495 - val_acc: 0.6123
Epoch 404/500
Epoch 00403: val_loss did not improve
16s - loss: 1.2749 - acc: 0.5608 - val_loss: 1.0482 - val_acc: 0.6116
Epoch 405/500
Epoch 00404: val_loss did not improve
16s - loss: 1.2783 - acc: 0.5600 - val_loss: 1.0470 - val_acc: 0.6113
Epoch 406/500
Epoch 00405: val_loss did not improve
16s - loss: 1.2779 - acc: 0.5591 - val_loss: 1.0635 - val_acc: 0.6073
Epoch 407/500
Epoch 00406: val_loss did not improve
16s - loss: 1.2745 - acc: 0.5610 - val_loss: 1.0461 - val_acc: 0.6139
Epoch 408/500
Epoch 00407: val_loss did not improve
16s - loss: 1.2760 - acc: 0.5604 - val_loss: 1.0525 - val_acc: 0.6116
Epoch 409/500
Epoch 00408: val_loss did not improve
16s - loss: 1.2768 - acc: 0.5605 - val_loss: 1.0519 - val_acc: 0.6112
Epoch 410/500
Epoch 00409: val_loss did not improve
16s - loss: 1.2770 - acc: 0.5600 - val_loss: 1.0481 - val_acc: 0.6120
Epoch 411/500
Epoch 00410: val_loss did not improve
16s - loss: 1.2760 - acc: 0.5607 - val_loss: 1.0467 - val_acc: 0.6119
Epoch 412/500
Epoch 00411: val_loss improved from 1.04536 to 1.03941, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.2781 - acc: 0.5597 - val_loss: 1.0394 - val_acc: 0.6140
Epoch 413/500
Epoch 00412: val_loss did not improve
16s - loss: 1.2735 - acc: 0.5612 - val_loss: 1.0479 - val_acc: 0.6134
Epoch 414/500
Epoch 00413: val_loss improved from 1.03941 to 1.03874, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.2762 - acc: 0.5604 - val_loss: 1.0387 - val_acc: 0.6143
Epoch 415/500
Epoch 00414: val_loss did not improve
16s - loss: 1.2745 - acc: 0.5611 - val_loss: 1.0448 - val_acc: 0.6136
Epoch 416/500
Epoch 00415: val_loss did not improve
16s - loss: 1.2773 - acc: 0.5599 - val_loss: 1.0491 - val_acc: 0.6132
Epoch 417/500
Epoch 00416: val_loss improved from 1.03874 to 1.03871, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
17s - loss: 1.2755 - acc: 0.5606 - val_loss: 1.0387 - val_acc: 0.6154
Epoch 418/500
Epoch 00417: val_loss did not improve
16s - loss: 1.2739 - acc: 0.5619 - val_loss: 1.0544 - val_acc: 0.6114
Epoch 419/500
Epoch 00418: val_loss did not improve
16s - loss: 1.2741 - acc: 0.5612 - val_loss: 1.0423 - val_acc: 0.6131
Epoch 420/500
Epoch 00419: val_loss did not improve
16s - loss: 1.2740 - acc: 0.5610 - val_loss: 1.0559 - val_acc: 0.6117
Epoch 421/500
Epoch 00420: val_loss did not improve
16s - loss: 1.2728 - acc: 0.5614 - val_loss: 1.0410 - val_acc: 0.6156
Epoch 422/500
Epoch 00421: val_loss did not improve
16s - loss: 1.2737 - acc: 0.5611 - val_loss: 1.0434 - val_acc: 0.6124
Epoch 423/500
Epoch 00422: val_loss did not improve
16s - loss: 1.2728 - acc: 0.5612 - val_loss: 1.0448 - val_acc: 0.6134
Epoch 424/500
Epoch 00423: val_loss improved from 1.03871 to 1.03441, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.2723 - acc: 0.5612 - val_loss: 1.0344 - val_acc: 0.6152
Epoch 425/500
Epoch 00424: val_loss did not improve
16s - loss: 1.2722 - acc: 0.5611 - val_loss: 1.0474 - val_acc: 0.6134
Epoch 426/500
Epoch 00425: val_loss did not improve
16s - loss: 1.2714 - acc: 0.5614 - val_loss: 1.0539 - val_acc: 0.6114
Epoch 427/500
Epoch 00426: val_loss did not improve
16s - loss: 1.2717 - acc: 0.5614 - val_loss: 1.0368 - val_acc: 0.6157
Epoch 428/500
Epoch 00427: val_loss did not improve
16s - loss: 1.2713 - acc: 0.5608 - val_loss: 1.0479 - val_acc: 0.6118
Epoch 429/500
Epoch 00428: val_loss did not improve
16s - loss: 1.2704 - acc: 0.5618 - val_loss: 1.0445 - val_acc: 0.6134
Epoch 430/500
Epoch 00429: val_loss did not improve
16s - loss: 1.2712 - acc: 0.5617 - val_loss: 1.0409 - val_acc: 0.6130
Epoch 431/500
Epoch 00430: val_loss did not improve
16s - loss: 1.2719 - acc: 0.5612 - val_loss: 1.0388 - val_acc: 0.6146
Epoch 432/500
Epoch 00431: val_loss did not improve
16s - loss: 1.2712 - acc: 0.5617 - val_loss: 1.0478 - val_acc: 0.6128
Epoch 433/500
Epoch 00432: val_loss did not improve
16s - loss: 1.2706 - acc: 0.5620 - val_loss: 1.0352 - val_acc: 0.6155
Epoch 434/500
Epoch 00433: val_loss did not improve
16s - loss: 1.2686 - acc: 0.5623 - val_loss: 1.0345 - val_acc: 0.6146
Epoch 435/500
Epoch 00434: val_loss did not improve
16s - loss: 1.2694 - acc: 0.5621 - val_loss: 1.0412 - val_acc: 0.6144
Epoch 436/500
Epoch 00435: val_loss did not improve
16s - loss: 1.2700 - acc: 0.5622 - val_loss: 1.0642 - val_acc: 0.6100
Epoch 437/500
Epoch 00436: val_loss did not improve
16s - loss: 1.2705 - acc: 0.5627 - val_loss: 1.0389 - val_acc: 0.6152
Epoch 438/500
Epoch 00437: val_loss did not improve
16s - loss: 1.2710 - acc: 0.5621 - val_loss: 1.0456 - val_acc: 0.6127
Epoch 439/500
Epoch 00438: val_loss did not improve
17s - loss: 1.2698 - acc: 0.5624 - val_loss: 1.0407 - val_acc: 0.6147
Epoch 440/500
Epoch 00439: val_loss did not improve
16s - loss: 1.2691 - acc: 0.5626 - val_loss: 1.0600 - val_acc: 0.6103
Epoch 441/500
Epoch 00440: val_loss did not improve
16s - loss: 1.2695 - acc: 0.5617 - val_loss: 1.0468 - val_acc: 0.6136
Epoch 442/500
Epoch 00441: val_loss did not improve
16s - loss: 1.2678 - acc: 0.5620 - val_loss: 1.0382 - val_acc: 0.6150
Epoch 443/500
Epoch 00442: val_loss did not improve
16s - loss: 1.2702 - acc: 0.5620 - val_loss: 1.0413 - val_acc: 0.6147
Epoch 444/500
Epoch 00443: val_loss did not improve
16s - loss: 1.2682 - acc: 0.5621 - val_loss: 1.0413 - val_acc: 0.6143
Epoch 445/500
Epoch 00444: val_loss did not improve
16s - loss: 1.2696 - acc: 0.5617 - val_loss: 1.0446 - val_acc: 0.6120
Epoch 446/500
Epoch 00445: val_loss did not improve
16s - loss: 1.2689 - acc: 0.5621 - val_loss: 1.0363 - val_acc: 0.6143
Epoch 447/500
Epoch 00446: val_loss did not improve
16s - loss: 1.2674 - acc: 0.5628 - val_loss: 1.0407 - val_acc: 0.6131
Epoch 448/500
Epoch 00447: val_loss did not improve
16s - loss: 1.2660 - acc: 0.5624 - val_loss: 1.0500 - val_acc: 0.6122
Epoch 449/500
Epoch 00448: val_loss did not improve
16s - loss: 1.2674 - acc: 0.5621 - val_loss: 1.0363 - val_acc: 0.6139
Epoch 450/500
Epoch 00449: val_loss did not improve
16s - loss: 1.2686 - acc: 0.5623 - val_loss: 1.0461 - val_acc: 0.6119
Epoch 451/500
Epoch 00450: val_loss improved from 1.03441 to 1.03281, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.2683 - acc: 0.5624 - val_loss: 1.0328 - val_acc: 0.6148
Epoch 452/500
Epoch 00451: val_loss did not improve
16s - loss: 1.2672 - acc: 0.5625 - val_loss: 1.0352 - val_acc: 0.6169
Epoch 453/500
Epoch 00452: val_loss did not improve
16s - loss: 1.2670 - acc: 0.5630 - val_loss: 1.0361 - val_acc: 0.6132
Epoch 454/500
Epoch 00453: val_loss did not improve
16s - loss: 1.2663 - acc: 0.5628 - val_loss: 1.0395 - val_acc: 0.6152
Epoch 455/500
Epoch 00454: val_loss improved from 1.03281 to 1.03107, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.2689 - acc: 0.5626 - val_loss: 1.0311 - val_acc: 0.6174
Epoch 456/500
Epoch 00455: val_loss improved from 1.03107 to 1.03005, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
17s - loss: 1.2640 - acc: 0.5633 - val_loss: 1.0301 - val_acc: 0.6163
Epoch 457/500
Epoch 00456: val_loss did not improve
17s - loss: 1.2664 - acc: 0.5624 - val_loss: 1.0448 - val_acc: 0.6137
Epoch 458/500
Epoch 00457: val_loss did not improve
16s - loss: 1.2643 - acc: 0.5636 - val_loss: 1.0521 - val_acc: 0.6110
Epoch 459/500
Epoch 00458: val_loss did not improve
16s - loss: 1.2677 - acc: 0.5626 - val_loss: 1.0331 - val_acc: 0.6155
Epoch 460/500
Epoch 00459: val_loss improved from 1.03005 to 1.02953, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.2652 - acc: 0.5631 - val_loss: 1.0295 - val_acc: 0.6159
Epoch 461/500
Epoch 00460: val_loss did not improve
16s - loss: 1.2685 - acc: 0.5623 - val_loss: 1.0298 - val_acc: 0.6157
Epoch 462/500
Epoch 00461: val_loss did not improve
16s - loss: 1.2645 - acc: 0.5634 - val_loss: 1.0426 - val_acc: 0.6164
Epoch 463/500
Epoch 00462: val_loss did not improve
16s - loss: 1.2648 - acc: 0.5639 - val_loss: 1.0474 - val_acc: 0.6122
Epoch 464/500
Epoch 00463: val_loss did not improve
16s - loss: 1.2646 - acc: 0.5628 - val_loss: 1.0458 - val_acc: 0.6137
Epoch 465/500
Epoch 00464: val_loss did not improve
16s - loss: 1.2628 - acc: 0.5636 - val_loss: 1.0305 - val_acc: 0.6179
Epoch 466/500
Epoch 00465: val_loss did not improve
16s - loss: 1.2639 - acc: 0.5638 - val_loss: 1.0358 - val_acc: 0.6162
Epoch 467/500
Epoch 00466: val_loss did not improve
16s - loss: 1.2628 - acc: 0.5641 - val_loss: 1.0378 - val_acc: 0.6153
Epoch 468/500
Epoch 00467: val_loss improved from 1.02953 to 1.02913, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
17s - loss: 1.2640 - acc: 0.5633 - val_loss: 1.0291 - val_acc: 0.6161
Epoch 469/500
Epoch 00468: val_loss did not improve
16s - loss: 1.2656 - acc: 0.5633 - val_loss: 1.0325 - val_acc: 0.6170
Epoch 470/500
Epoch 00469: val_loss improved from 1.02913 to 1.02259, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.2633 - acc: 0.5637 - val_loss: 1.0226 - val_acc: 0.6206
Epoch 471/500
Epoch 00470: val_loss did not improve
16s - loss: 1.2624 - acc: 0.5638 - val_loss: 1.0246 - val_acc: 0.6197
Epoch 472/500
Epoch 00471: val_loss did not improve
16s - loss: 1.2646 - acc: 0.5634 - val_loss: 1.0399 - val_acc: 0.6152
Epoch 473/500
Epoch 00472: val_loss did not improve
16s - loss: 1.2631 - acc: 0.5640 - val_loss: 1.0317 - val_acc: 0.6171
Epoch 474/500
Epoch 00473: val_loss did not improve
16s - loss: 1.2640 - acc: 0.5631 - val_loss: 1.0258 - val_acc: 0.6187
Epoch 475/500
Epoch 00474: val_loss did not improve
16s - loss: 1.2614 - acc: 0.5636 - val_loss: 1.0361 - val_acc: 0.6157
Epoch 476/500
Epoch 00475: val_loss did not improve
16s - loss: 1.2627 - acc: 0.5632 - val_loss: 1.0347 - val_acc: 0.6166
Epoch 477/500
Epoch 00476: val_loss did not improve
16s - loss: 1.2625 - acc: 0.5639 - val_loss: 1.0327 - val_acc: 0.6164
Epoch 478/500
Epoch 00477: val_loss did not improve
16s - loss: 1.2625 - acc: 0.5639 - val_loss: 1.0244 - val_acc: 0.6166
Epoch 479/500
Epoch 00478: val_loss did not improve
16s - loss: 1.2618 - acc: 0.5638 - val_loss: 1.0362 - val_acc: 0.6153
Epoch 480/500
Epoch 00479: val_loss did not improve
16s - loss: 1.2637 - acc: 0.5642 - val_loss: 1.0375 - val_acc: 0.6147
Epoch 481/500
Epoch 00480: val_loss did not improve
16s - loss: 1.2629 - acc: 0.5637 - val_loss: 1.0265 - val_acc: 0.6188
Epoch 482/500
Epoch 00481: val_loss did not improve
16s - loss: 1.2632 - acc: 0.5631 - val_loss: 1.0259 - val_acc: 0.6204
Epoch 483/500
Epoch 00482: val_loss did not improve
16s - loss: 1.2623 - acc: 0.5636 - val_loss: 1.0228 - val_acc: 0.6178
Epoch 484/500
Epoch 00483: val_loss did not improve
16s - loss: 1.2622 - acc: 0.5638 - val_loss: 1.0354 - val_acc: 0.6173
Epoch 485/500
Epoch 00484: val_loss did not improve
16s - loss: 1.2612 - acc: 0.5639 - val_loss: 1.0275 - val_acc: 0.6181
Epoch 486/500
Epoch 00485: val_loss did not improve
16s - loss: 1.2595 - acc: 0.5646 - val_loss: 1.0235 - val_acc: 0.6199
Epoch 487/500
Epoch 00486: val_loss did not improve
16s - loss: 1.2626 - acc: 0.5643 - val_loss: 1.0252 - val_acc: 0.6180
Epoch 488/500
Epoch 00487: val_loss improved from 1.02259 to 1.02221, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.2598 - acc: 0.5644 - val_loss: 1.0222 - val_acc: 0.6212
Epoch 489/500
Epoch 00488: val_loss did not improve
16s - loss: 1.2613 - acc: 0.5640 - val_loss: 1.0387 - val_acc: 0.6144
Epoch 490/500
Epoch 00489: val_loss did not improve
16s - loss: 1.2582 - acc: 0.5645 - val_loss: 1.0428 - val_acc: 0.6156
Epoch 491/500
Epoch 00490: val_loss did not improve
16s - loss: 1.2601 - acc: 0.5646 - val_loss: 1.0259 - val_acc: 0.6195
Epoch 492/500
Epoch 00491: val_loss improved from 1.02221 to 1.01641, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
16s - loss: 1.2574 - acc: 0.5654 - val_loss: 1.0164 - val_acc: 0.6193
Epoch 493/500
Epoch 00492: val_loss did not improve
16s - loss: 1.2583 - acc: 0.5648 - val_loss: 1.0284 - val_acc: 0.6182
Epoch 494/500
Epoch 00493: val_loss did not improve
16s - loss: 1.2580 - acc: 0.5652 - val_loss: 1.0319 - val_acc: 0.6177
Epoch 495/500
Epoch 00494: val_loss improved from 1.01641 to 1.01485, saving model to autoencoder_experiments/20171218-092448/weights/autoencoder.h5
17s - loss: 1.2613 - acc: 0.5644 - val_loss: 1.0149 - val_acc: 0.6210
Epoch 496/500
Epoch 00495: val_loss did not improve
16s - loss: 1.2573 - acc: 0.5659 - val_loss: 1.0424 - val_acc: 0.6176
Epoch 497/500
Epoch 00496: val_loss did not improve
16s - loss: 1.2573 - acc: 0.5650 - val_loss: 1.0284 - val_acc: 0.6170
Epoch 498/500
Epoch 00497: val_loss did not improve
16s - loss: 1.2575 - acc: 0.5652 - val_loss: 1.0188 - val_acc: 0.6219
Epoch 499/500
Epoch 00498: val_loss did not improve
16s - loss: 1.2595 - acc: 0.5649 - val_loss: 1.0292 - val_acc: 0.6176
Epoch 500/500
Epoch 00499: val_loss did not improve
16s - loss: 1.2584 - acc: 0.5646 - val_loss: 1.0220 - val_acc: 0.6189
X_test
Traceback (most recent call last):
  File "dga_gan.py", line 501, in <module>
    train_autoencoder()
  File "dga_gan.py", line 347, in train_autoencoder
    print(data_dict['X_test'].shape())
TypeError: 'tuple' object is not callable
