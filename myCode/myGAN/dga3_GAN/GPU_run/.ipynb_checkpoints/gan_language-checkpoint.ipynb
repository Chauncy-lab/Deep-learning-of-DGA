{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import language_helpers\n",
    "import tflib as lib\n",
    "import tflib.ops.linear\n",
    "import tflib.ops.conv1d\n",
    "import tflib.plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Download Google Billion Word at http://www.statmt.org/lm-benchmark/ and\n",
    "# fill in the path to the extracted files here!\n",
    "DATA_DIR = '../Dataset/AlexaTop1M_NoSeparate'\n",
    "if len(DATA_DIR) == 0:\n",
    "    raise Exception(\"Please specify path to data directory in gan_language.py!\")\n",
    "\n",
    "BATCH_SIZE = 64 # Batch size\n",
    "# How many iterations to train for, min value is 1000, Please increase the number of iteration in 1000 units\n",
    "ITERS = 30000 \n",
    "SEQ_LEN = 32 # Sequence length in characters\n",
    "DIM = 512 # Model dimensionality. This is fairly slow and overfits, even on\n",
    "          # Billion Word. Consider decreasing for smaller datasets.\n",
    "CRITIC_ITERS = 10 # How many critic iterations per generator iteration. We\n",
    "                  # use 10 for the results in the paper, but 5 should work fine\n",
    "                  # as well.\n",
    "LAMBDA = 10 # Gradient penalty lambda hyperparameter.\n",
    "MAX_N_EXAMPLES = 100000 # Max number of data examples to load. If data loading\n",
    "                          # is too slow or takes too much RAM, you can decrease\n",
    "                          # this (at the expense of having less training data). default value is 10000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uppercase local vars:\n",
      "\tBATCH_SIZE: 64\n",
      "\tCRITIC_ITERS: 10\n",
      "\tDATA_DIR: ../Dataset/AlexaTop1M_NoSeparate\n",
      "\tDIM: 512\n",
      "\tITERS: 30000\n",
      "\tLAMBDA: 10\n",
      "\tMAX_N_EXAMPLES: 100000\n",
      "\tSEQ_LEN: 32\n",
      "loading dataset...\n",
      "('w', 'e', 'b', 'n', 'o', 'd', 'e', '.', 'm', 'x', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('g', 'r', 'n', 'b', 'a', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('v', 'i', 'e', '-', 'p', 'u', 'b', 'l', 'i', 'q', 'u', 'e', '.', 'f', 'r', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('s', 'a', 'n', 'd', 'i', 'e', 'g', 'o', 'u', 'n', 'i', 'o', 'n', 't', 'r', 'i', 'b', 'u', 'n', 'e', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('r', 'o', 'a', 'm', 'a', 'n', 's', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('c', 'i', 't', 'a', 'd', 'o', 'r', '.', 'p', 't', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('f', 'a', 'r', 's', 'a', 'r', 'a', 'n', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('o', 'z', 'd', 'i', 'c', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('s', 't', 'a', 'n', 'd', 'a', 'r', 'd', 'b', 'a', 'n', 'k', '.', 'c', 'o', '.', 'z', 'a', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('k', 'u', 'c', 'o', 'u', 'r', 's', 'e', 's', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('l', 'a', 'n', 'a', 's', 'b', 'i', 'g', 'b', 'o', 'o', 'b', 's', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('c', 'o', 'n', 'n', 'e', 'x', 'i', 't', 'y', '.', 'n', 'e', 't', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('s', 'a', 'f', 'e', 'r', 'p', 'a', 'y', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('s', 'e', 'r', 'v', 'e', 'g', 'a', 'm', 'e', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('b', 'u', 'y', 'p', 'r', 'o', 'd', 'u', 'c', 't', 'r', 'e', 'v', 'i', 'e', 'w', 's', '.', 'i', 'n', 'f', 'o', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('f', 'r', 'e', 'e', 's', 'w', 'i', 't', 'c', 'h', '.', 'o', 'r', 'g', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('c', 'o', 'e', 'd', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('3', 'd', 'h', 'u', 'b', 's', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('m', 't', 'n', '.', 'c', 'o', '.', 'k', 'r', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('a', 'd', 'm', 'e', 't', 'a', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('b', 'a', 'l', 't', 'i', 'm', 'o', 'r', 'e', 'c', 'i', 't', 'y', '.', 'g', 'o', 'v', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('m', 'o', 'o', 's', 'e', 'n', 'd', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('g', 'e', 'e', 'k', 't', 'u', 't', 'o', 'r', 'i', 'a', 'l', 'e', 's', '.', 'n', 'e', 't', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('p', 'r', 'e', 'z', 'z', 'y', 'b', 'o', 'x', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('b', 'a', 'm', 'b', 'e', 'r', 'g', 'e', 'r', 'k', 'e', 'n', 'n', 'a', 'n', 'c', 'h', 'i', 't', 'i', 'n', 'o', 'u', 's', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ')\n",
      "('p', 'o', 'l', 'i', 's', 'h', 't', 'r', 'a', 'c', 'k', 'e', 'r', '.', 'n', 'e', 't', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('j', 'u', 's', 't', 's', 'k', 'i', 'n', 's', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('g', 'e', 'e', 't', 'm', 'a', 'n', 'j', 'u', 's', 'h', 'a', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('s', 'h', 'o', 'p', 's', 'k', 'e', 'e', 'p', 'e', 'r', 's', '.', 't', 'k', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('n', 'c', 'k', 'u', '.', 'e', 'd', 'u', '.', 't', 'w', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('r', 'o', 's', 's', 'm', 'a', 'n', 'n', '.', 'd', 'e', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('r', 'o', 'b', 'e', 'r', 't', 'o', 's', 'c', 'o', 'n', 'o', 'c', 'c', 'h', 'i', 'n', 'i', '.', 'i', 't', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('c', 'y', 'b', 'e', 'r', 'c', 'o', 'o', 'k', '.', 'c', 'o', 'm', '.', 'b', 'r', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('w', 'e', 'd', 'd', 'i', 'x', '.', 'd', 'e', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('g', 'o', 'l', 'd', 'e', 'n', '-', 't', 'e', 'a', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('e', 'd', 'i', 'b', 'l', 'e', 'a', 'r', 'r', 'a', 'n', 'g', 'e', 'm', 'e', 'n', 't', 's', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('n', 'e', 'd', 'p', 'o', 'r', 'n', 'o', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('m', 'o', 'e', 'x', '.', 'g', 'o', 'v', '.', 't', 'w', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('9', 'y', 'e', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('m', 'c', 'a', '.', 'g', 'o', 'v', '.', 'c', 'n', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('g', 'a', 'm', 'e', 'm', 'i', 'n', 'e', 'r', '.', 'n', 'e', 't', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('h', 'a', 't', 'a', 'l', 'i', 'k', 'e', '.', 'j', 'p', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('h', 'y', 'i', 'p', 'f', 'r', 'i', 'e', 'n', 'd', '.', 'n', 'e', 't', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('p', 'u', 'm', 'p', 'y', 't', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('m', 'a', 'n', 'u', 'l', 'i', 'f', 'e', 'b', 'a', 'n', 'k', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('w', 'e', 'b', 's', 'u', 'p', 'p', 'o', 'r', 't', '.', 's', 'k', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('j', 'o', 'b', 't', 'h', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('w', 'e', 'b', 'u', 'y', 'a', 'n', 'y', 'c', 'a', 'r', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('s', 't', 'a', 'r', 'h', 'e', 'a', 'l', 't', 'h', '.', 'i', 'n', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('c', 'o', 'l', 'c', 'o', 'n', 'e', 'c', 't', 'a', 'd', 'a', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('a', 'u', 'd', 'i', 'e', 'n', 'c', 'e', 'i', 'n', 's', 'i', 'g', 'h', 't', 's', '.', 'n', 'e', 't', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('l', 'e', 'b', 'e', 'n', 's', 'l', 'a', 'u', 'f', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('w', 'h', 'e', 'r', 'e', 'i', 'n', 'm', 'y', 'c', 'i', 't', 'y', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('t', 'i', 'v', 'i', 'x', '.', 'n', 'e', 't', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('p', 'j', 'n', '.', 'g', 'o', 'v', '.', 'a', 'r', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('m', 'a', 'r', 'v', 'e', 'l', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('p', 'h', 'u', 'n', 'u', 'k', 'i', 'e', 'u', 'v', 'i', 'e', 't', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('s', 't', 'r', 'e', 'a', 'm', 'r', 'a', 'i', 'l', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('i', 'h', 'a', 'r', 'a', 'r', 'e', '.', 'c', 'o', '.', 'z', 'w', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('m', 'o', 'v', 'i', 'l', 'e', 's', 'd', 'u', 'a', 'l', 's', 'i', 'm', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('v', 'i', 's', 'i', 't', 'o', 'r', 'l', 'a', 'n', 'd', 'o', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('s', 't', 's', '.', 'p', 'l', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('i', 's', 'i', 'g', 'o', 'o', 'd', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('i', 'n', 'd', 'i', 'a', 's', 'i', 'a', 'n', '.', 'c', 'o', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('g', 'e', 'o', 'm', 'e', 'd', 'i', 'a', 'n', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('s', 'o', 'n', 'i', 'c', '.', 'n', 'e', 't', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('t', 'h', 'e', 'b', 'e', 'a', 'u', 't', 'y', 'd', 'e', 'p', 'a', 'r', 't', 'm', 'e', 'n', 't', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('a', 'v', 'a', 't', 'e', 'c', 'h', '.', 'i', 'r', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('c', 'r', 'a', 'i', 'g', 's', 'l', 'i', 's', 't', '.', 'h', 'k', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('w', 'h', 'o', 'l', 'e', 's', 'a', 'l', 'e', 'r', 'e', 'p', 'u', 'b', 'l', 'i', 'c', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('t', 'o', 'p', '3', 'd', 'o', 'w', 'n', 'l', 'o', 'a', 'd', '.', 'i', 'r', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('h', 'a', 'm', 'i', 'l', 't', 'o', 'n', 'b', 'r', 'o', 'a', 'd', 'w', 'a', 'y', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('s', 'h', 'u', 'a', 'i', 'j', 'i', 'a', 'o', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('s', 'o', 'u', 'l', 'a', 'd', 'y', '.', 'n', 'e', 't', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('s', 'a', 'l', 'e', 'l', 'i', 's', 't', '.', 'c', 'o', '.', 'u', 'k', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('s', 'c', 'h', 'e', 'd', '.', 'o', 'r', 'g', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('e', 'v', 'e', 'r', 'n', 'o', 't', 'e', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('n', 'i', 's', 'w', 'h', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('a', 'g', 'r', 'o', 's', 'e', 'r', 'v', 'e', 'r', '.', 'r', 'u', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('d', 'u', 'b', 'a', 'i', 'd', 'e', 'd', '.', 'g', 'o', 'v', '.', 'a', 'e', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('m', 'a', 'k', 'e', 'r', 'b', 'o', 't', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('o', 'm', 'e', 'g', 'a', 't', 'r', 'a', 'v', 'e', 'l', 'e', 'r', '.', 'i', 'n', 'f', 'o', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('m', 'y', 'l', 'i', 'k', 'e', 's', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('c', 'i', 'p', 'd', '.', 'c', 'o', '.', 'u', 'k', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('y', 'a', 'l', 'w', 'a', '.', 'i', 'n', 'f', 'o', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('s', 'h', 'i', 'x', 'i', 'a', 'n', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('a', 's', 'k', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('o', 'p', 'e', 'l', '.', 'd', 'e', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('p', 'e', 'k', 'a', 'o', 'b', 'i', 'z', 'n', 'e', 's', '2', '4', '.', 'p', 'l', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('m', 'e', 'm', 'l', 'e', 'k', 'e', 't', 't', 'e', 'n', 'g', 'e', 'l', 's', 'i', 'n', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('s', 'i', 'd', 'e', 'r', 'e', 'e', 'l', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('c', 'o', 'o', 'l', 's', 'h', 'e', 'l', 'l', '.', 'c', 'n', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('p', 'a', 'y', 'l', 'e', 's', 's', 'c', 'a', 'r', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('t', 'i', 'c', 'k', 'e', 't', 's', 'f', 'o', 'r', 'f', 'u', 'n', '.', 'c', 'o', 'm', '.', 'b', 'r', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('t', 'e', 'a', 'v', 'a', 'n', 'a', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('p', 's', 'i', 'c', 'o', 'l', 'o', 'g', 'i', 'a', 'y', 'm', 'e', 'n', 't', 'e', '.', 'n', 'e', 't', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('v', 'i', 's', 'e', 'g', 'a', 'm', 'e', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('g', 'e', 'n', 'o', 'm', 'e', '.', 'g', 'o', 'v', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('g', 'a', 'm', 'e', 'c', 'a', 's', 't', '-', 'b', 'l', 'o', 'g', '.', 'c', 'o', 'm', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "('d', 'o', 'o', 'm', 'o', '.', 'b', 'i', 'z', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ')\n",
      "loaded 100000 lines in dataset\n"
     ]
    }
   ],
   "source": [
    "lib.print_model_settings(locals().copy())\n",
    "\n",
    "lines, charmap, inv_charmap = language_helpers.load_dataset(\n",
    "    max_length=SEQ_LEN,\n",
    "    max_n_examples=MAX_N_EXAMPLES,\n",
    "    data_dir=DATA_DIR\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(logits):\n",
    "    return tf.reshape(\n",
    "        tf.nn.softmax(\n",
    "            tf.reshape(logits, [-1, len(charmap)])\n",
    "        ),\n",
    "        tf.shape(logits)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_noise(shape):\n",
    "    return tf.random_normal(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ResBlock(name, inputs):\n",
    "    output = inputs\n",
    "    output = tf.nn.relu(output)\n",
    "    output = lib.ops.conv1d.Conv1D(name+'.1', DIM, DIM, 5, output)\n",
    "    output = tf.nn.relu(output)\n",
    "    output = lib.ops.conv1d.Conv1D(name+'.2', DIM, DIM, 5, output)\n",
    "    return inputs + (0.3*output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Generator(n_samples, prev_outputs=None):\n",
    "    output = make_noise(shape=[n_samples, 128])\n",
    "    output = lib.ops.linear.Linear('Generator.Input', 128, SEQ_LEN*DIM, output)\n",
    "    output = tf.reshape(output, [-1, DIM, SEQ_LEN])\n",
    "    output = ResBlock('Generator.1', output)\n",
    "    output = ResBlock('Generator.2', output)\n",
    "    output = ResBlock('Generator.3', output)\n",
    "    output = ResBlock('Generator.4', output)\n",
    "    output = ResBlock('Generator.5', output)\n",
    "    output = lib.ops.conv1d.Conv1D('Generator.Output', DIM, len(charmap), 1, output)\n",
    "    output = tf.transpose(output, [0, 2, 1])\n",
    "    output = softmax(output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Discriminator(inputs):\n",
    "    output = tf.transpose(inputs, [0,2,1])\n",
    "    output = lib.ops.conv1d.Conv1D('Discriminator.Input', len(charmap), DIM, 1, output)\n",
    "    output = ResBlock('Discriminator.1', output)\n",
    "    output = ResBlock('Discriminator.2', output)\n",
    "    output = ResBlock('Discriminator.3', output)\n",
    "    output = ResBlock('Discriminator.4', output)\n",
    "    output = ResBlock('Discriminator.5', output)\n",
    "    output = tf.reshape(output, [-1, SEQ_LEN*DIM])\n",
    "    output = lib.ops.linear.Linear('Discriminator.Output', SEQ_LEN*DIM, 1, output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "real_inputs_discrete = tf.placeholder(tf.int32, shape=[BATCH_SIZE, SEQ_LEN])\n",
    "real_inputs = tf.one_hot(real_inputs_discrete, len(charmap))\n",
    "fake_inputs = Generator(BATCH_SIZE)\n",
    "fake_inputs_discrete = tf.argmax(fake_inputs, fake_inputs.get_shape().ndims-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "disc_real = Discriminator(real_inputs) \n",
    "disc_fake = Discriminator(fake_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "disc_cost = tf.reduce_mean(disc_fake) - tf.reduce_mean(disc_real)\n",
    "gen_cost = -tf.reduce_mean(disc_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# WGAN lipschitz-penalty\n",
    "alpha = tf.random_uniform(\n",
    "    shape=[BATCH_SIZE,1,1], \n",
    "    minval=0.,\n",
    "    maxval=1.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "differences = fake_inputs - real_inputs\n",
    "interpolates = real_inputs + (alpha*differences)\n",
    "gradients = tf.gradients(Discriminator(interpolates), [interpolates])[0]\n",
    "slopes = tf.sqrt(tf.reduce_sum(tf.square(gradients), reduction_indices=[1,2]))\n",
    "gradient_penalty = tf.reduce_mean((slopes-1.)**2)\n",
    "disc_cost += LAMBDA*gradient_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen_params = lib.params_with_name('Generator')\n",
    "disc_params = lib.params_with_name('Discriminator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen_train_op = tf.train.AdamOptimizer(learning_rate=1e-4, beta1=0.5, beta2=0.999).minimize(gen_cost, var_list=gen_params)\n",
    "disc_train_op = tf.train.AdamOptimizer(learning_rate=1e-4, beta1=0.5, beta2=0.999).minimize(disc_cost, var_list=disc_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dataset iterator\n",
    "def inf_train_gen():\n",
    "    while True:\n",
    "        np.random.shuffle(lines)\n",
    "        for i in range(0, len(lines)-BATCH_SIZE+1, BATCH_SIZE):\n",
    "            yield np.array(\n",
    "                [[charmap[c] for c in l] for l in lines[i:i+BATCH_SIZE]], \n",
    "                dtype='int32'\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation set JSD for n=1: 0.00027936546409873796\n",
      "validation set JSD for n=2: 0.010836911775376186\n",
      "validation set JSD for n=3: 0.07873450820936567\n",
      "validation set JSD for n=4: 0.17761502240792434\n"
     ]
    }
   ],
   "source": [
    "# During training we monitor JS divergence between the true & generated ngram\n",
    "# distributions for n=1,2,3,4. To get an idea of the optimal values, we\n",
    "# evaluate these statistics on a held-out set first.\n",
    "\n",
    "true_char_ngram_lms = [language_helpers.NgramLanguageModel(i+1, lines[10*BATCH_SIZE:], tokenize=False) for i in range(4)]\n",
    "validation_char_ngram_lms = [language_helpers.NgramLanguageModel(i+1, lines[:10*BATCH_SIZE], tokenize=False) for i in range(4)]\n",
    "for i in range(4):\n",
    "    print ( \"validation set JSD for n={}: {}\".format(i+1, true_char_ngram_lms[i].js_with(validation_char_ngram_lms[i])) )\n",
    "true_char_ngram_lms = [language_helpers.NgramLanguageModel(i+1, lines, tokenize=False) for i in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Start]\n",
      "    1% Done! [Iteration]:        300 [300x iterations time   ]:     566.80 secs [SUM]:     566.80 secs\n",
      "iter 299\ttime\t1.8895049985249837\ttrain disc cost\t-3.2085421085357666\tjs4\t0.3005426714280313\tjs1\t0.05353855370632886\tjs3\t0.24334272073455124\tjs2\t0.15205331299283434\n",
      "    2% Done! [Iteration]:        600 [300x iterations time   ]:     566.49 secs [SUM]:    1133.30 secs\n",
      "iter 599\ttime\t1.883965076605479\ttrain disc cost\t-2.2452640533447266\tjs4\t0.26750123846770124\tjs1\t0.04038219597254436\tjs3\t0.18579508335213948\tjs2\t0.09881305600986917\n",
      "    3% Done! [Iteration]:        900 [300x iterations time   ]:     567.00 secs [SUM]:    1700.30 secs\n",
      "iter 899\ttime\t1.8852486324310302\ttrain disc cost\t-2.231243371963501\tjs4\t0.2682883167928958\tjs1\t0.029520641462756986\tjs3\t0.17459163315501575\tjs2\t0.08233977516286375\n",
      "    4% Done! [Iteration]:       1200 [300x iterations time   ]:     566.74 secs [SUM]:    2267.04 secs\n",
      "iter 1199\ttime\t1.8849411582946778\ttrain disc cost\t-2.221461772918701\tjs4\t0.26452788888548856\tjs1\t0.03065620522307954\tjs3\t0.16705794655195652\tjs2\t0.07884906879266274\n",
      "    5% Done! [Iteration]:       1500 [300x iterations time   ]:     567.85 secs [SUM]:    2834.88 secs\n",
      "iter 1499\ttime\t1.8885989928245543\ttrain disc cost\t-2.1998250484466553\tjs4\t0.262104688731239\tjs1\t0.02315976808921816\tjs3\t0.1580316206629405\tjs2\t0.0655750585341461\n",
      "    6% Done! [Iteration]:       1800 [300x iterations time   ]:     566.85 secs [SUM]:    3401.74 secs\n",
      "iter 1799\ttime\t1.8851020201047262\ttrain disc cost\t-2.0514609813690186\tjs4\t0.2620837843825501\tjs1\t0.021956535391484178\tjs3\t0.16082262957818705\tjs2\t0.06621539470776858\n",
      "    7% Done! [Iteration]:       2100 [300x iterations time   ]:     565.87 secs [SUM]:    3967.60 secs\n",
      "iter 2099\ttime\t1.8819326106707255\ttrain disc cost\t-2.0292184352874756\tjs4\t0.2550349140428753\tjs1\t0.02133869484221171\tjs3\t0.159690045228832\tjs2\t0.06445989750889067\n",
      "    8% Done! [Iteration]:       2400 [300x iterations time   ]:     566.96 secs [SUM]:    4534.56 secs\n",
      "iter 2399\ttime\t1.884921346505483\ttrain disc cost\t-1.9400562047958374\tjs4\t0.26334167011310067\tjs1\t0.020777031012121243\tjs3\t0.15986352708618265\tjs2\t0.062381147581865755\n",
      "    9% Done! [Iteration]:       2700 [300x iterations time   ]:     566.79 secs [SUM]:    5101.35 secs\n",
      "iter 2699\ttime\t1.8850921805699665\ttrain disc cost\t-1.9670205116271973\tjs4\t0.25720551015326076\tjs1\t0.014847818311640826\tjs3\t0.1471116322166609\tjs2\t0.05351112166630565\n",
      "   10% Done! [Iteration]:       3000 [300x iterations time   ]:     565.56 secs [SUM]:    5666.91 secs\n",
      "iter 2999\ttime\t1.8809215466181437\ttrain disc cost\t-1.994740605354309\tjs4\t0.24448017023880791\tjs1\t0.012637715378618493\tjs3\t0.13022495079632676\tjs2\t0.04118285429693225\n",
      "   11% Done! [Iteration]:       3300 [300x iterations time   ]:     567.75 secs [SUM]:    6234.66 secs\n",
      "iter 3299\ttime\t1.8881254227956137\ttrain disc cost\t-2.012868642807007\tjs4\t0.23813034910301722\tjs1\t0.013200161820087764\tjs3\t0.13166568720535968\tjs2\t0.043568352189816625\n",
      "   12% Done! [Iteration]:       3600 [300x iterations time   ]:     566.88 secs [SUM]:    6801.53 secs\n",
      "iter 3599\ttime\t1.8847145183881124\ttrain disc cost\t-2.0029900074005127\tjs4\t0.2524484742226261\tjs1\t0.013144739464359038\tjs3\t0.13752959255826833\tjs2\t0.045324724417875585\n",
      "   13% Done! [Iteration]:       3900 [300x iterations time   ]:     565.68 secs [SUM]:    7367.22 secs\n",
      "iter 3899\ttime\t1.8812076020240784\ttrain disc cost\t-1.9445916414260864\tjs4\t0.2536922959540735\tjs1\t0.011641124249821912\tjs3\t0.13769784199881258\tjs2\t0.04291862629440551\n",
      "   14% Done! [Iteration]:       4200 [300x iterations time   ]:     565.76 secs [SUM]:    7932.97 secs\n",
      "iter 4199\ttime\t1.881371405919393\ttrain disc cost\t-1.9616117477416992\tjs4\t0.23664054191168307\tjs1\t0.010655140444547096\tjs3\t0.1294164169089698\tjs2\t0.0393018493902183\n",
      "   15% Done! [Iteration]:       4500 [300x iterations time   ]:     565.66 secs [SUM]:    8498.64 secs\n",
      "iter 4499\ttime\t1.8812250955899557\ttrain disc cost\t-1.9375947713851929\tjs4\t0.25189856013580786\tjs1\t0.013839083344905813\tjs3\t0.14032472099425888\tjs2\t0.04642789735428797\n",
      "   16% Done! [Iteration]:       4800 [300x iterations time   ]:     566.91 secs [SUM]:    9065.55 secs\n",
      "iter 4799\ttime\t1.8849144570032756\ttrain disc cost\t-1.9414457082748413\tjs4\t0.24650332839072106\tjs1\t0.009681437593462267\tjs3\t0.13163708727646692\tjs2\t0.0392533143573329\n",
      "   17% Done! [Iteration]:       5100 [300x iterations time   ]:     566.32 secs [SUM]:    9631.86 secs\n",
      "iter 5099\ttime\t1.8834264055887857\ttrain disc cost\t-1.9366204738616943\tjs4\t0.26289068406649285\tjs1\t0.01374096442218254\tjs3\t0.14423007677102426\tjs2\t0.0474213305754915\n",
      "   18% Done! [Iteration]:       5400 [300x iterations time   ]:     566.73 secs [SUM]:   10198.59 secs\n",
      "iter 5399\ttime\t1.884643142223358\ttrain disc cost\t-1.9581016302108765\tjs4\t0.23710730646226183\tjs1\t0.010132302991655334\tjs3\t0.12448620246038668\tjs2\t0.0379476261730138\n",
      "   19% Done! [Iteration]:       5700 [300x iterations time   ]:     567.86 secs [SUM]:   10766.46 secs\n",
      "iter 5699\ttime\t1.8880792800585429\ttrain disc cost\t-1.9603385925292969\tjs4\t0.238570642443255\tjs1\t0.011462761653848672\tjs3\t0.13378997610758753\tjs2\t0.04138629145549792\n",
      "   20% Done! [Iteration]:       6000 [300x iterations time   ]:     567.69 secs [SUM]:   11334.14 secs\n",
      "iter 5999\ttime\t1.8880104152361552\ttrain disc cost\t-1.9430890083312988\tjs4\t0.25054854726555104\tjs1\t0.011052089146639264\tjs3\t0.13287891161124937\tjs2\t0.039859721978860924\n",
      "   21% Done! [Iteration]:       6300 [300x iterations time   ]:     567.68 secs [SUM]:   11901.82 secs\n",
      "iter 6299\ttime\t1.8878596758842467\ttrain disc cost\t-1.9603503942489624\tjs4\t0.2320600031876999\tjs1\t0.009838928097720679\tjs3\t0.12592058366757022\tjs2\t0.03775073657415328\n",
      "   22% Done! [Iteration]:       6600 [300x iterations time   ]:     566.80 secs [SUM]:   12468.62 secs\n",
      "iter 6599\ttime\t1.8849537881215412\ttrain disc cost\t-1.9768249988555908\tjs4\t0.24560532154714323\tjs1\t0.009259520036305112\tjs3\t0.1292610964328701\tjs2\t0.0376251924021071\n",
      "   23% Done! [Iteration]:       6900 [300x iterations time   ]:     566.76 secs [SUM]:   13035.38 secs\n",
      "iter 6899\ttime\t1.8847717022895814\ttrain disc cost\t-1.956571102142334\tjs4\t0.240853117205633\tjs1\t0.008379363300904575\tjs3\t0.12692226338266463\tjs2\t0.03575036622573614\n",
      "   24% Done! [Iteration]:       7200 [300x iterations time   ]:     567.31 secs [SUM]:   13602.69 secs\n",
      "iter 7199\ttime\t1.8859117078781127\ttrain disc cost\t-1.969669222831726\tjs4\t0.2443129075015296\tjs1\t0.008745047343877444\tjs3\t0.13025331994955602\tjs2\t0.03792114699415923\n",
      "   25% Done! [Iteration]:       7500 [300x iterations time   ]:     567.71 secs [SUM]:   14170.40 secs\n",
      "iter 7499\ttime\t1.8879027660687764\ttrain disc cost\t-1.969081997871399\tjs4\t0.23743437891806027\tjs1\t0.0084042059939298\tjs3\t0.12220574799671152\tjs2\t0.0338798356045389\n",
      "   26% Done! [Iteration]:       7800 [300x iterations time   ]:     567.83 secs [SUM]:   14738.23 secs\n",
      "iter 7799\ttime\t1.888250884215037\ttrain disc cost\t-1.9787678718566895\tjs4\t0.2406671140996027\tjs1\t0.008453606731420015\tjs3\t0.12461951698070484\tjs2\t0.03619253419756057\n",
      "   27% Done! [Iteration]:       8100 [300x iterations time   ]:     567.75 secs [SUM]:   15305.98 secs\n",
      "iter 8099\ttime\t1.8879370419184367\ttrain disc cost\t-1.998779535293579\tjs4\t0.2401850355609737\tjs1\t0.008207476268197924\tjs3\t0.12331400766843367\tjs2\t0.03478086097350468\n",
      "   28% Done! [Iteration]:       8400 [300x iterations time   ]:     566.00 secs [SUM]:   15871.98 secs\n",
      "iter 8399\ttime\t1.8815450930595399\ttrain disc cost\t-1.982917070388794\tjs4\t0.23828379639601768\tjs1\t0.008254390962960925\tjs3\t0.1252080713371666\tjs2\t0.03462977514237037\n",
      "   29% Done! [Iteration]:       8700 [300x iterations time   ]:     566.82 secs [SUM]:   16438.80 secs\n",
      "iter 8699\ttime\t1.8849602031707764\ttrain disc cost\t-1.9493436813354492\tjs4\t0.23708264641129084\tjs1\t0.008700236179174436\tjs3\t0.12266635785526532\tjs2\t0.03346395361219184\n",
      "   30% Done! [Iteration]:       9000 [300x iterations time   ]:     566.78 secs [SUM]:   17005.58 secs\n",
      "iter 8999\ttime\t1.8847454086939495\ttrain disc cost\t-2.01292085647583\tjs4\t0.23531941815915253\tjs1\t0.008996493984123083\tjs3\t0.1203634517126612\tjs2\t0.034001587325560655\n",
      "   31% Done! [Iteration]:       9300 [300x iterations time   ]:     567.94 secs [SUM]:   17573.52 secs\n",
      "iter 9299\ttime\t1.8887126231193543\ttrain disc cost\t-1.9892692565917969\tjs4\t0.2381516033516386\tjs1\t0.008639205474274313\tjs3\t0.12944261790536804\tjs2\t0.039509059597068436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   32% Done! [Iteration]:       9600 [300x iterations time   ]:     568.19 secs [SUM]:   18141.70 secs\n",
      "iter 9599\ttime\t1.888822271823883\ttrain disc cost\t-1.9706798791885376\tjs4\t0.23524880424201156\tjs1\t0.009239794725699017\tjs3\t0.12214669738301491\tjs2\t0.03459486916339452\n",
      "   33% Done! [Iteration]:       9900 [300x iterations time   ]:     566.88 secs [SUM]:   18708.58 secs\n",
      "iter 9899\ttime\t1.8851279338200888\ttrain disc cost\t-1.9929325580596924\tjs4\t0.22276778317016566\tjs1\t0.007863665087276752\tjs3\t0.11607918862243737\tjs2\t0.03331419574462237\n",
      "   34% Done! [Iteration]:      10200 [300x iterations time   ]:     567.89 secs [SUM]:   19276.47 secs\n",
      "iter 10199\ttime\t1.8884719928105673\ttrain disc cost\t-1.9794217348098755\tjs4\t0.23263020686800545\tjs1\t0.0077800413155102496\tjs3\t0.11816443143209188\tjs2\t0.032641573457465316\n",
      "   35% Done! [Iteration]:      10500 [300x iterations time   ]:     567.82 secs [SUM]:   19844.29 secs\n",
      "iter 10499\ttime\t1.888150963783264\ttrain disc cost\t-1.9581587314605713\tjs4\t0.23438001194656868\tjs1\t0.008618532603354673\tjs3\t0.1217011205645134\tjs2\t0.03423120947397959\n",
      "   36% Done! [Iteration]:      10800 [300x iterations time   ]:     567.78 secs [SUM]:   20412.07 secs\n",
      "iter 10799\ttime\t1.8875163610776264\ttrain disc cost\t-1.959536075592041\tjs4\t0.23304415437144332\tjs1\t0.00808158918231698\tjs3\t0.11798824302553908\tjs2\t0.032041304156349974\n",
      "   37% Done! [Iteration]:      11100 [300x iterations time   ]:     568.00 secs [SUM]:   20980.07 secs\n",
      "iter 11099\ttime\t1.888841872215271\ttrain disc cost\t-1.941293716430664\tjs4\t0.22347302878715689\tjs1\t0.008120903690295953\tjs3\t0.1145214779140459\tjs2\t0.030814910573603953\n",
      "   38% Done! [Iteration]:      11400 [300x iterations time   ]:     567.92 secs [SUM]:   21547.98 secs\n",
      "iter 11399\ttime\t1.888580028216044\ttrain disc cost\t-1.9907195568084717\tjs4\t0.22119821421822863\tjs1\t0.009069951435359613\tjs3\t0.11719297658096717\tjs2\t0.03356845146352799\n",
      "   39% Done! [Iteration]:      11700 [300x iterations time   ]:     567.90 secs [SUM]:   22115.88 secs\n",
      "iter 11699\ttime\t1.8884436440467836\ttrain disc cost\t-1.9590623378753662\tjs4\t0.23342068699809007\tjs1\t0.002281047379514812\tjs3\t0.11968013311354975\tjs2\t0.028389026458809013\n",
      "   40% Done! [Iteration]:      12000 [300x iterations time   ]:     568.04 secs [SUM]:   22683.92 secs\n",
      "iter 11999\ttime\t1.888319328625997\ttrain disc cost\t-1.8753831386566162\tjs4\t0.2296849720568427\tjs1\t0.0032529395547815526\tjs3\t0.11595042383887656\tjs2\t0.025264409966933715\n",
      "   41% Done! [Iteration]:      12300 [300x iterations time   ]:     567.89 secs [SUM]:   23251.81 secs\n",
      "iter 12299\ttime\t1.8882249307632446\ttrain disc cost\t-1.8259211778640747\tjs4\t0.23169181511022657\tjs1\t0.00243978274774238\tjs3\t0.11654753519783208\tjs2\t0.023892990652688406\n",
      "   42% Done! [Iteration]:      12600 [300x iterations time   ]:     567.82 secs [SUM]:   23819.64 secs\n",
      "iter 12599\ttime\t1.8880475370089214\ttrain disc cost\t-1.8302010297775269\tjs4\t0.22448029907335795\tjs1\t0.002517277502281119\tjs3\t0.11087979983322839\tjs2\t0.024721394715717115\n",
      "   43% Done! [Iteration]:      12900 [300x iterations time   ]:     569.46 secs [SUM]:   24389.10 secs\n",
      "iter 12899\ttime\t1.8927791547775268\ttrain disc cost\t-1.8013769388198853\tjs4\t0.22635669259239533\tjs1\t0.0031566915318255954\tjs3\t0.11578904830625363\tjs2\t0.024991714532605448\n",
      "   44% Done! [Iteration]:      13200 [300x iterations time   ]:     569.58 secs [SUM]:   24958.68 secs\n",
      "iter 13199\ttime\t1.8937094537417094\ttrain disc cost\t-1.8452801704406738\tjs4\t0.24098681019607804\tjs1\t0.0019057852886086185\tjs3\t0.11754031184396783\tjs2\t0.022611369604563954\n",
      "   45% Done! [Iteration]:      13500 [300x iterations time   ]:     569.62 secs [SUM]:   25528.30 secs\n",
      "iter 13499\ttime\t1.8938948400815327\ttrain disc cost\t-1.8442708253860474\tjs4\t0.23661794744292594\tjs1\t0.0027175487035648125\tjs3\t0.1127203718577934\tjs2\t0.02101178243169283\n",
      "   46% Done! [Iteration]:      13800 [300x iterations time   ]:     569.77 secs [SUM]:   26098.07 secs\n",
      "iter 13799\ttime\t1.8944578949610393\ttrain disc cost\t-1.830862045288086\tjs4\t0.22521770574660524\tjs1\t0.0019320471029217728\tjs3\t0.11184374925298463\tjs2\t0.020904458197249877\n",
      "   47% Done! [Iteration]:      14100 [300x iterations time   ]:     570.29 secs [SUM]:   26668.36 secs\n",
      "iter 14099\ttime\t1.8962732028961182\ttrain disc cost\t-1.8108073472976685\tjs4\t0.22418590344954548\tjs1\t0.0035183587356298653\tjs3\t0.11132719660007966\tjs2\t0.02448687831473194\n",
      "   48% Done! [Iteration]:      14400 [300x iterations time   ]:     570.00 secs [SUM]:   27238.36 secs\n",
      "iter 14399\ttime\t1.8947716999053954\ttrain disc cost\t-1.8367332220077515\tjs4\t0.2414074323878647\tjs1\t0.002384349402236934\tjs3\t0.11931763579031424\tjs2\t0.023782157428546103\n",
      "   49% Done! [Iteration]:      14700 [300x iterations time   ]:     567.96 secs [SUM]:   27806.32 secs\n",
      "iter 14699\ttime\t1.8885066628456115\ttrain disc cost\t-1.8784037828445435\tjs4\t0.23717898781961497\tjs1\t0.0028319851783126754\tjs3\t0.11727245505792992\tjs2\t0.02541607987958823\n",
      "   50% Done! [Iteration]:      15000 [300x iterations time   ]:     568.48 secs [SUM]:   28374.80 secs\n",
      "iter 14999\ttime\t1.8900618600845336\ttrain disc cost\t-1.850145697593689\tjs4\t0.2214383474128984\tjs1\t0.002831930878377134\tjs3\t0.112581960236041\tjs2\t0.02430287960655549\n",
      "   51% Done! [Iteration]:      15300 [300x iterations time   ]:     568.96 secs [SUM]:   28943.76 secs\n",
      "iter 15299\ttime\t1.8918387953440348\ttrain disc cost\t-1.8288966417312622\tjs4\t0.22790368466230654\tjs1\t0.0024330852119759986\tjs3\t0.11075886090837685\tjs2\t0.02059602929686783\n",
      "   52% Done! [Iteration]:      15600 [300x iterations time   ]:     566.30 secs [SUM]:   29510.06 secs\n",
      "iter 15599\ttime\t1.8822923342386881\ttrain disc cost\t-1.869890570640564\tjs4\t0.22255499062553402\tjs1\t0.002585366198768956\tjs3\t0.10844456630927814\tjs2\t0.021817219966134123\n",
      "   53% Done! [Iteration]:      15900 [300x iterations time   ]:     565.88 secs [SUM]:   30075.94 secs\n",
      "iter 15899\ttime\t1.8814080119132996\ttrain disc cost\t-1.8441976308822632\tjs4\t0.22578034774084293\tjs1\t0.0013989152224640868\tjs3\t0.1103197822296673\tjs2\t0.01822355556273704\n",
      "   54% Done! [Iteration]:      16200 [300x iterations time   ]:     564.65 secs [SUM]:   30640.59 secs\n",
      "iter 16199\ttime\t1.8773288416862488\ttrain disc cost\t-1.847347378730774\tjs4\t0.22178522593817965\tjs1\t0.0029010690957274837\tjs3\t0.10871357818820268\tjs2\t0.0229008191173353\n",
      "   55% Done! [Iteration]:      16500 [300x iterations time   ]:     568.70 secs [SUM]:   31209.29 secs\n",
      "iter 16499\ttime\t1.8902027376492818\ttrain disc cost\t-1.8806239366531372\tjs4\t0.22164810077381733\tjs1\t0.0033057182897387703\tjs3\t0.10956054822930522\tjs2\t0.023266144416601284\n",
      "   56% Done! [Iteration]:      16800 [300x iterations time   ]:     565.50 secs [SUM]:   31774.79 secs\n",
      "iter 16799\ttime\t1.8802347532908121\ttrain disc cost\t-1.8877506256103516\tjs4\t0.220860589689053\tjs1\t0.001696621903592672\tjs3\t0.10663162625708843\tjs2\t0.020415184241022958\n",
      "   57% Done! [Iteration]:      17100 [300x iterations time   ]:     567.67 secs [SUM]:   32342.46 secs\n",
      "iter 17099\ttime\t1.8871452927589416\ttrain disc cost\t-1.8625929355621338\tjs4\t0.22271603153833094\tjs1\t0.002524962117585004\tjs3\t0.11133233686915754\tjs2\t0.020282519743999507\n",
      "   58% Done! [Iteration]:      17400 [300x iterations time   ]:     575.36 secs [SUM]:   32917.82 secs\n",
      "iter 17399\ttime\t1.912734982172648\ttrain disc cost\t-1.87834632396698\tjs4\t0.21909033001281225\tjs1\t0.002423639630663546\tjs3\t0.10815539864710078\tjs2\t0.021601796468818005\n",
      "   59% Done! [Iteration]:      17700 [300x iterations time   ]:     567.94 secs [SUM]:   33485.75 secs\n",
      "iter 17699\ttime\t1.8876543211936951\ttrain disc cost\t-1.9100321531295776\tjs4\t0.22530768828002792\tjs1\t0.0018634101792765459\tjs3\t0.11009555511927115\tjs2\t0.020489217746721754\n",
      "   60% Done! [Iteration]:      18000 [300x iterations time   ]:     564.51 secs [SUM]:   34050.26 secs\n",
      "iter 17999\ttime\t1.8769143303235372\ttrain disc cost\t-1.9262408018112183\tjs4\t0.23040434857293818\tjs1\t0.0015557874210209547\tjs3\t0.1111570431159734\tjs2\t0.019290182639651012\n",
      "   61% Done! [Iteration]:      18300 [300x iterations time   ]:     561.62 secs [SUM]:   34611.88 secs\n",
      "iter 18299\ttime\t1.8669428682327271\ttrain disc cost\t-1.8722689151763916\tjs4\t0.22915372031682543\tjs1\t0.0016625984170533007\tjs3\t0.1135631761835623\tjs2\t0.019388327482251076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   62% Done! [Iteration]:      18600 [300x iterations time   ]:     561.60 secs [SUM]:   35173.48 secs\n",
      "iter 18599\ttime\t1.8665335512161254\ttrain disc cost\t-1.8593308925628662\tjs4\t0.21912634098410577\tjs1\t0.0023417088396010042\tjs3\t0.10997494362090515\tjs2\t0.02141970559494583\n",
      "   63% Done! [Iteration]:      18900 [300x iterations time   ]:     562.83 secs [SUM]:   35736.32 secs\n",
      "iter 18899\ttime\t1.8711238582928975\ttrain disc cost\t-1.886386752128601\tjs4\t0.224328827405853\tjs1\t0.0015831316341393565\tjs3\t0.10761587780202928\tjs2\t0.020737756365115212\n",
      "   64% Done! [Iteration]:      19200 [300x iterations time   ]:     565.18 secs [SUM]:   36301.49 secs\n",
      "iter 19199\ttime\t1.8790230083465576\ttrain disc cost\t-1.8732694387435913\tjs4\t0.22008417191014043\tjs1\t0.0027565838183244507\tjs3\t0.11083962291594321\tjs2\t0.02197502651863635\n",
      "   65% Done! [Iteration]:      19500 [300x iterations time   ]:     565.38 secs [SUM]:   36866.88 secs\n",
      "iter 19499\ttime\t1.8791134985287985\ttrain disc cost\t-1.8736333847045898\tjs4\t0.22156870801864784\tjs1\t0.002487853113726686\tjs3\t0.10639953130320867\tjs2\t0.019908600037515697\n",
      "   66% Done! [Iteration]:      19800 [300x iterations time   ]:     562.70 secs [SUM]:   37429.57 secs\n",
      "iter 19799\ttime\t1.8706649462382\ttrain disc cost\t-1.821305751800537\tjs4\t0.2240063835479649\tjs1\t0.0016335583212232863\tjs3\t0.10471808355993115\tjs2\t0.01894264591181326\n",
      "   67% Done! [Iteration]:      20100 [300x iterations time   ]:     564.13 secs [SUM]:   37993.70 secs\n",
      "iter 20099\ttime\t1.8754589931170145\ttrain disc cost\t-1.9165271520614624\tjs4\t0.23220800520774978\tjs1\t0.0014304173006092157\tjs3\t0.1112654512382112\tjs2\t0.021249672698109883\n",
      "   68% Done! [Iteration]:      20400 [300x iterations time   ]:     567.84 secs [SUM]:   38561.54 secs\n",
      "iter 20399\ttime\t1.8879616785049438\ttrain disc cost\t-1.9248631000518799\tjs4\t0.22870462689272314\tjs1\t0.0027056290238248563\tjs3\t0.11017039350568178\tjs2\t0.022325857275073604\n",
      "   69% Done! [Iteration]:      20700 [300x iterations time   ]:     571.35 secs [SUM]:   39132.89 secs\n",
      "iter 20699\ttime\t1.8993027194341023\ttrain disc cost\t-1.92133629322052\tjs4\t0.22619667917300937\tjs1\t0.001125871354030274\tjs3\t0.10700822310564495\tjs2\t0.017846838844444175\n",
      "   70% Done! [Iteration]:      21000 [300x iterations time   ]:     568.50 secs [SUM]:   39701.39 secs\n",
      "iter 20999\ttime\t1.8892891613642375\ttrain disc cost\t-1.8964918851852417\tjs4\t0.22907625622172695\tjs1\t0.002061579327063004\tjs3\t0.10927534788862454\tjs2\t0.0203015895513811\n",
      "   71% Done! [Iteration]:      21300 [300x iterations time   ]:     568.07 secs [SUM]:   40269.46 secs\n",
      "iter 21299\ttime\t1.8887158584594728\ttrain disc cost\t-1.9519740343093872\tjs4\t0.21365253668493744\tjs1\t0.0018739113312133326\tjs3\t0.10576103626379878\tjs2\t0.019709320516846332\n",
      "   72% Done! [Iteration]:      21600 [300x iterations time   ]:     574.31 secs [SUM]:   40843.77 secs\n",
      "iter 21599\ttime\t1.9094390726089479\ttrain disc cost\t-1.9367624521255493\tjs4\t0.21368936733716967\tjs1\t0.004066904610218625\tjs3\t0.10801291893893153\tjs2\t0.022087709478503754\n",
      "   73% Done! [Iteration]:      21900 [300x iterations time   ]:     570.59 secs [SUM]:   41414.36 secs\n",
      "iter 21899\ttime\t1.8967699734369914\ttrain disc cost\t-1.906891107559204\tjs4\t0.21519135988769061\tjs1\t0.00277492009326093\tjs3\t0.10466805674791654\tjs2\t0.02065838267939668\n",
      "   74% Done! [Iteration]:      22200 [300x iterations time   ]:     575.47 secs [SUM]:   41989.82 secs\n",
      "iter 22199\ttime\t1.9125798225402832\ttrain disc cost\t-1.9086389541625977\tjs4\t0.21811418903820726\tjs1\t0.002164145353861995\tjs3\t0.10563037397232333\tjs2\t0.020494170722099792\n",
      "   75% Done! [Iteration]:      22500 [300x iterations time   ]:     569.71 secs [SUM]:   42559.54 secs\n",
      "iter 22499\ttime\t1.8937065569559732\ttrain disc cost\t-1.906006097793579\tjs4\t0.22249286417266328\tjs1\t0.0017310787900662809\tjs3\t0.1072487382872002\tjs2\t0.019700344758410048\n",
      "   76% Done! [Iteration]:      22800 [300x iterations time   ]:     567.11 secs [SUM]:   43126.64 secs\n",
      "iter 22799\ttime\t1.8855107442537944\ttrain disc cost\t-1.8760713338851929\tjs4\t0.21726819751678453\tjs1\t0.0024462387728926287\tjs3\t0.11063096888699857\tjs2\t0.02134439267682249\n",
      "   77% Done! [Iteration]:      23100 [300x iterations time   ]:     566.87 secs [SUM]:   43693.51 secs\n",
      "iter 23099\ttime\t1.8846414510409037\ttrain disc cost\t-1.8894836902618408\tjs4\t0.2276479477661029\tjs1\t0.0021356026417397966\tjs3\t0.1108561876786265\tjs2\t0.021646764364962025\n",
      "   78% Done! [Iteration]:      23400 [300x iterations time   ]:     571.65 secs [SUM]:   44265.16 secs\n",
      "iter 23399\ttime\t1.9001702086130778\ttrain disc cost\t-1.9265429973602295\tjs4\t0.2105039330192148\tjs1\t0.0032665346753901403\tjs3\t0.10723302202641938\tjs2\t0.02299995500103827\n",
      "   79% Done! [Iteration]:      23700 [300x iterations time   ]:     571.00 secs [SUM]:   44836.16 secs\n",
      "iter 23699\ttime\t1.8976227935155232\ttrain disc cost\t-1.9052242040634155\tjs4\t0.22252275948703445\tjs1\t0.002254360532961997\tjs3\t0.10966347041826933\tjs2\t0.02044161608082375\n",
      "   80% Done! [Iteration]:      24000 [300x iterations time   ]:     568.50 secs [SUM]:   45404.66 secs\n",
      "iter 23999\ttime\t1.8899841936429342\ttrain disc cost\t-1.9750850200653076\tjs4\t0.21596036315041697\tjs1\t0.0022743805812016657\tjs3\t0.1045624419234655\tjs2\t0.019747784021028853\n",
      "   81% Done! [Iteration]:      24300 [300x iterations time   ]:     568.27 secs [SUM]:   45972.93 secs\n",
      "iter 24299\ttime\t1.8892473626136779\ttrain disc cost\t-1.9206805229187012\tjs4\t0.22685213213147193\tjs1\t0.0014722024869464685\tjs3\t0.1088300602535262\tjs2\t0.02081697753198067\n",
      "   82% Done! [Iteration]:      24600 [300x iterations time   ]:     568.45 secs [SUM]:   46541.38 secs\n",
      "iter 24599\ttime\t1.889822396437327\ttrain disc cost\t-1.9545103311538696\tjs4\t0.21103157054483995\tjs1\t0.0038118660087018627\tjs3\t0.10779567704170302\tjs2\t0.02071362961561134\n",
      "   83% Done! [Iteration]:      24900 [300x iterations time   ]:     568.12 secs [SUM]:   47109.50 secs\n",
      "iter 24899\ttime\t1.8879431597391765\ttrain disc cost\t-1.9827604293823242\tjs4\t0.2210204774259847\tjs1\t0.00260249809152139\tjs3\t0.10968131976767345\tjs2\t0.02178578401335328\n",
      "   84% Done! [Iteration]:      25200 [300x iterations time   ]:     567.67 secs [SUM]:   47677.17 secs\n",
      "iter 25199\ttime\t1.8873244937260945\ttrain disc cost\t-1.9738584756851196\tjs4\t0.22519922766788802\tjs1\t0.004663411672656562\tjs3\t0.11116861440371642\tjs2\t0.02393849285565347\n",
      "   85% Done! [Iteration]:      25500 [300x iterations time   ]:     565.43 secs [SUM]:   48242.60 secs\n",
      "iter 25499\ttime\t1.8796494714419048\ttrain disc cost\t-1.9470003843307495\tjs4\t0.21666926890837626\tjs1\t0.002039859710757212\tjs3\t0.10737473798799914\tjs2\t0.020996370302747036\n",
      "   86% Done! [Iteration]:      25800 [300x iterations time   ]:     565.34 secs [SUM]:   48807.94 secs\n",
      "iter 25799\ttime\t1.8794035911560059\ttrain disc cost\t-1.929152011871338\tjs4\t0.20627087231389954\tjs1\t0.0031900678956495185\tjs3\t0.1016027028867671\tjs2\t0.020619048828464433\n",
      "   87% Done! [Iteration]:      26100 [300x iterations time   ]:     568.06 secs [SUM]:   49376.01 secs\n",
      "iter 26099\ttime\t1.8876839780807495\ttrain disc cost\t-2.004251718521118\tjs4\t0.22913894544091287\tjs1\t0.0019691720659768216\tjs3\t0.11055482810941505\tjs2\t0.020908694427596252\n",
      "   88% Done! [Iteration]:      26400 [300x iterations time   ]:     566.53 secs [SUM]:   49942.54 secs\n",
      "iter 26399\ttime\t1.8832230424880982\ttrain disc cost\t-1.9480841159820557\tjs4\t0.2322851904894242\tjs1\t0.0015185942877221689\tjs3\t0.111504108719263\tjs2\t0.020742741131404608\n",
      "   89% Done! [Iteration]:      26700 [300x iterations time   ]:     566.48 secs [SUM]:   50509.02 secs\n",
      "iter 26699\ttime\t1.8829546491305034\ttrain disc cost\t-1.9253162145614624\tjs4\t0.22812974973581848\tjs1\t0.0017158330413040216\tjs3\t0.11031469255388306\tjs2\t0.020165933040574235\n",
      "   90% Done! [Iteration]:      27000 [300x iterations time   ]:     566.60 secs [SUM]:   51075.62 secs\n",
      "iter 26999\ttime\t1.8834455196062725\ttrain disc cost\t-1.9527673721313477\tjs4\t0.22828522966589004\tjs1\t0.002245492236821443\tjs3\t0.1072184913606417\tjs2\t0.02018786767220426\n",
      "   91% Done! [Iteration]:      27300 [300x iterations time   ]:     567.06 secs [SUM]:   51642.68 secs\n",
      "iter 27299\ttime\t1.8846829446156819\ttrain disc cost\t-1.9340698719024658\tjs4\t0.2285082576909426\tjs1\t0.0019133112210280466\tjs3\t0.11170930186842402\tjs2\t0.021724109546955656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   92% Done! [Iteration]:      27600 [300x iterations time   ]:     565.42 secs [SUM]:   52208.10 secs\n",
      "iter 27599\ttime\t1.8797983407974244\ttrain disc cost\t-1.9536648988723755\tjs4\t0.205516585052811\tjs1\t0.0032686760255140543\tjs3\t0.10207294073844463\tjs2\t0.01969721271798594\n",
      "   93% Done! [Iteration]:      27900 [300x iterations time   ]:     565.43 secs [SUM]:   52773.54 secs\n",
      "iter 27899\ttime\t1.8798721877733866\ttrain disc cost\t-2.0101776123046875\tjs4\t0.21980122831367932\tjs1\t0.0025924738054587493\tjs3\t0.10687673619358266\tjs2\t0.020099105662982154\n",
      "   94% Done! [Iteration]:      28200 [300x iterations time   ]:     565.43 secs [SUM]:   53338.96 secs\n",
      "iter 28199\ttime\t1.879719336827596\ttrain disc cost\t-1.8762109279632568\tjs4\t0.21404229209555412\tjs1\t0.0014710055281318365\tjs3\t0.10309127250619757\tjs2\t0.018209947708532705\n",
      "   95% Done! [Iteration]:      28500 [300x iterations time   ]:     565.53 secs [SUM]:   53904.49 secs\n",
      "iter 28499\ttime\t1.8794899733861288\ttrain disc cost\t-1.9469316005706787\tjs4\t0.21015276645011846\tjs1\t0.0020610388858867687\tjs3\t0.10220720130293966\tjs2\t0.019599221777766174\n",
      "   96% Done! [Iteration]:      28800 [300x iterations time   ]:     565.44 secs [SUM]:   54469.94 secs\n",
      "iter 28799\ttime\t1.8799249561627707\ttrain disc cost\t-1.964819073677063\tjs4\t0.22837424358112657\tjs1\t0.0017444996573786802\tjs3\t0.10990360545911151\tjs2\t0.01993556663691675\n",
      "   97% Done! [Iteration]:      29100 [300x iterations time   ]:     565.51 secs [SUM]:   55035.45 secs\n",
      "iter 29099\ttime\t1.879984564781189\ttrain disc cost\t-1.9557394981384277\tjs4\t0.21513644258233605\tjs1\t0.0019011915592758906\tjs3\t0.10434982936073148\tjs2\t0.01944563306904262\n",
      "   98% Done! [Iteration]:      29400 [300x iterations time   ]:     565.39 secs [SUM]:   55600.84 secs\n",
      "iter 29399\ttime\t1.8796075789133708\ttrain disc cost\t-1.9748508930206299\tjs4\t0.22770497027801698\tjs1\t0.0016017923779871532\tjs3\t0.10809790861443756\tjs2\t0.018067865868412192\n",
      "   99% Done! [Iteration]:      29700 [300x iterations time   ]:     566.69 secs [SUM]:   56167.53 secs\n",
      "iter 29699\ttime\t1.8833969855308532\ttrain disc cost\t-1.9637349843978882\tjs4\t0.2358500879691516\tjs1\t0.0024393063199177655\tjs3\t0.1081849016112298\tjs2\t0.019410896957139042\n",
      "  100% Done! [Iteration]:      30000 [300x iterations time   ]:     565.37 secs [SUM]:   56732.91 secs\n",
      "iter 29999\ttime\t1.8794870297114055\ttrain disc cost\t-1.917027235031128\tjs4\t0.21322475105201655\tjs1\t0.0014710190537584908\tjs3\t0.10292273375670181\tjs2\t0.017963092377403032\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "\n",
    "    session.run(tf.global_variables_initializer())\n",
    "\n",
    "    def generate_samples():\n",
    "        samples = session.run(fake_inputs)\n",
    "        samples = np.argmax(samples, axis=2)\n",
    "        decoded_samples = []\n",
    "        for i in range(len(samples)):\n",
    "            decoded = []\n",
    "            for j in range(len(samples[i])):\n",
    "                decoded.append(inv_charmap[samples[i][j]])\n",
    "            decoded_samples.append(tuple(decoded))\n",
    "        return decoded_samples\n",
    "\n",
    "    gen = inf_train_gen()\n",
    "\n",
    "    sum_time = 0.\n",
    "    line_time = 0. \n",
    "    loading_str = \"*\"\n",
    "    for iteration in range(ITERS):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        if (iteration == 0):\n",
    "            now_time = time.clock()\n",
    "            print(\"[Start]\")\n",
    "\n",
    "        # Train generator\n",
    "        if iteration > 0:\n",
    "            _ = session.run(gen_train_op)\n",
    "\n",
    "        # Train critic\n",
    "        for i in range(CRITIC_ITERS):\n",
    "            _data = gen.__next__()\n",
    "            _disc_cost, _ = session.run(\n",
    "                [disc_cost, disc_train_op],\n",
    "                feed_dict={real_inputs_discrete:_data}\n",
    "            )\n",
    "            \n",
    "            #print(\"_disc_cost \"+str(_disc_cost))\n",
    "            #print(\"_ \"+str(_))\n",
    "            #print(\"_data \"+str(_data))\n",
    "            #print(\"gen_cost \"+str(gen_cost))\n",
    "            #print(\"disc_cost\"+str(disc_cost))\n",
    "\n",
    "        # How many iterations to change line \n",
    "        change_line=int(ITERS/1000)\n",
    "        \n",
    "        after_time=time.clock() - now_time\n",
    "        sum_time+=after_time\n",
    "        eta_time = (ITERS-iteration)*(after_time)\n",
    "        \n",
    "        print(\"[{1:10}] [Iteration]: {0:10} [Unit iteration time    ]: {2:10.2f} secs [ETA]: {3:10.2f} secs\".format( (iteration+1), loading_str, after_time, eta_time) , end=\"\\r\")\n",
    "        now_time = time.clock()\n",
    "        if iteration % change_line == (change_line-1):\n",
    "            loading_str += \"*\"\n",
    "            if iteration % (10*change_line) == (10*change_line-1):            \n",
    "                print(\"{5:5.0f}{0:7} [Iteration]: {1:10} [{2:23}]: {3:10.2f} secs [SUM]: {4:10.2f}\".format(\"% Done!\", (iteration+1), (str(10*change_line)+\"x iterations time\"), (sum_time-line_time), sum_time, (100*iteration/ITERS) ) )\n",
    "                loading_str = \"*\"\n",
    "                line_time = sum_time\n",
    "        \n",
    "        lib.plot.plot('time', time.time() - start_time)\n",
    "        lib.plot.plot('train disc cost', _disc_cost)        \n",
    "\n",
    "        if iteration % (10*change_line) == (10*change_line-1):\n",
    "            #print(\"checkpintB\"+str(iteration+1))\n",
    "            samples = []\n",
    "            for i in range(10):\n",
    "                samples.extend(generate_samples())\n",
    "\n",
    "            for i in range(4):\n",
    "                lm = language_helpers.NgramLanguageModel(i+1, samples, tokenize=False)\n",
    "                lib.plot.plot('js{}'.format(i+1), lm.js_with(true_char_ngram_lms[i]))\n",
    "\n",
    "            with open('output_data/samples_{}.txt'.format(str(iteration+1).zfill(7)), 'w',encoding = 'utf8') as f:\n",
    "                for s in samples:\n",
    "                    s = \"\".join(s)\n",
    "                    s = language_helpers.checkDNSFrom(s)\n",
    "                    f.write(str(s) + \"\\n\")\n",
    "\n",
    "        if iteration % (10*change_line) == (10*change_line-1):\n",
    "            #print(iteration)\n",
    "            lib.plot.flush()\n",
    "        \n",
    "        lib.plot.tick()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
